map(~ process_batch(.x))
imena <- bind_rows(results)
filtered_imena <- imena %>%
filter(str_detect(full_text, pattern_imena))
View(imena)
View(dt)
dt <- read_excel("D:/LUKA/Academic/HKS/Projekti/Dezinformacije/Data/generalno.xlsx")
View(dt)
imena <- c("Stepinac","Stojić","Markić", "Mandurić", "Košić" ,"Bajruši", "Bešker","Tomić","Pofuk",  "Lasić", "Marjanović","Bozanić", "Abramović", "Pilsel") %>% tolower()
pattern_imena <- str_c("\\b(", str_c(imena, collapse = "|"), ")\\b")
# Define the batch size
batch_size <- 1000
# Split your data into batches
batches <- split(dt, ceiling(seq_along(dt[[1]])/batch_size))
# Function to process each batch
process_batch <- function(batch) {
batch %>%
as_tibble() %>%
mutate(
full_text = tolower(FULL_TEXT),
match = str_c(imena, collapse = '|'),
key_word = str_extract_all(full_text, match)
) %>%
filter(lengths(key_word) > 0) %>%
unnest(key_word) %>%
distinct(V1, .keep_all = TRUE)
}
# Process each batch
results <- batches %>%
map(~ process_batch(.x))
imena <- bind_rows(results)
filtered_imena <- imena %>%
filter(str_detect(full_text, pattern_imena))
View(filtered_imena)
fraze <- c("pedofilija", "klečavci", "kaptolaši", "popovi", "lopovi", "zatucani" , "fanatici", "fašisti", "katolibani","crkvenjak", "ekstremni")
fraze_root <- sapply(fraze, write_tokens)
fraze_root <- sapply(strsplit(fraze_root, "\t"), `[`, 2)
fraze <- enframe(fraze_root, name = "name", value = "root")
pattern_fraze <- str_c("\\b(", str_c(fraze$root, collapse = "|"), ")\\b")
pattern_fraze <- str_c("\\b(", str_c(fraze, collapse = "|"), ")\\b")
# Define the batch size
batch_size <- 1000
# Split your data into batches
batches <- split(dt, ceiling(seq_along(dt[[1]])/batch_size))
# Function to process each batch
process_batch <- function(batch) {
batch %>%
as_tibble() %>%
mutate(
full_text = tolower(FULL_TEXT),
match = str_c(fraze, collapse = '|'),
key_word = str_extract_all(full_text, match)
) %>%
filter(lengths(key_word) > 0) %>%
unnest(key_word) %>%
distinct(V1, .keep_all = TRUE)
}
# Process each batch
results <- batches %>%
map(~ process_batch(.x))
fraze <- bind_rows(results)
fraze <- c("pedofilija", "klečavci", "kaptolaši", "popovi", "lopovi", "zatucani" , "fanatici", "fašisti", "katolibani","crkvenjak", "ekstremni")
words_vector <- str_c("\\b(", str_c(fraze, collapse = "|"), ")\\b")
# Assuming all is a data.table
setDT(dt)
# Vectorized function to check for matches
check_matches <- function(text, words_vector) {
any(stri_detect_fixed(text, words_vector, negate = FALSE))
}
check_matches <- function(text, words_vector) {
# Create a pattern with a word boundary only before the word
patterns <- paste0("\\b", words_vector)
any(stri_detect_regex(text, patterns))
}
# Loop through each batch
for (i in 1:num_batches) {
start_time <- Sys.time()
# Calculate the start and end row indices for the current batch
start_idx <- (i - 1) * batch_size + 1
end_idx <- min(i * batch_size, nrow(dt))
# Print the current batch number and row indices
cat(sprintf("Processing batch %d (rows %d to %d)...\n", i, start_idx, end_idx))
# Subset the data table for the current batch and apply the operations
dt[start_idx:end_idx, `:=` (
has_match = sapply(FULL_TEXT, check_matches, words_vector),
matched_words = sapply(FULL_TEXT, function(x) paste(words_vector[stri_detect_fixed(x, words_vector)], collapse=", "))
)]
batch_data <- dt[start_idx:end_idx]
end_time <- Sys.time()
duration <- end_time - start_time
# Print the duration for the current batch
cat(sprintf("Batch %d processed in %f seconds.\n", i, duration))
# ... [rest of your loop code for saving etc.] ...
}
fraze <- dt[has_match==T,]
View(fraze)
pravno <- c("vatikanski", "ugovori", "plaćanje", "blagoslova","sakramenata", "nekretnine", "imovina")
pattern_pravno <- str_c("\\b(", str_c(pravno, collapse = "|"), ")\\b")
# Define the batch size
batch_size <- 1000
# Split your data into batches
batches <- split(dt, ceiling(seq_along(dt[[1]])/batch_size))
# Function to process each batch
process_batch <- function(batch) {
batch %>%
as_tibble()  %>%
mutate(
full_text = tolower(FULL_TEXT),
match = str_c(pattern_pravno, collapse = '|'),
key_word = str_extract_all(full_text, match)
) %>%
filter(lengths(key_word) > 0) %>%
unnest(key_word) %>%
distinct(V1, .keep_all = TRUE)
}
# Process each batch
results <- batches %>%
map(~ process_batch(.x))
pravno <- bind_rows(results)
View(pravno)
imena <- c("Stepinac","Stojić","Markić", "Mandurić", "Košić" ,"Bajruši", "Bešker","Tomić","Pofuk",  "Lasić", "Marjanović","Bozanić", "Abramović", "Pilsel") %>% tolower()
words_vector <- str_c("\\b(", str_c(imena, collapse = "|"), ")\\b")
words_vector
# Assuming all is a data.table
setDT(dt)
# Vectorized function to check for matches
check_matches <- function(text, words_vector) {
any(stri_detect_fixed(text, words_vector, negate = FALSE))
}
dt
dt[, FULL_TEXT := tolower(FULL_TEXT)]
View(dt)
# Vectorized function to check for matches
check_matches <- function(text, words_vector) {
any(stri_detect_fixed(text, words_vector, negate = FALSE))
}
batch_size <- 1000
# Calculate the number of batches
num_batches <- ceiling(nrow(dt) / batch_size)
# Loop through each batch
for (i in 1:num_batches) {
start_time <- Sys.time()
# Calculate the start and end row indices for the current batch
start_idx <- (i - 1) * batch_size + 1
end_idx <- min(i * batch_size, nrow(dt))
# Print the current batch number and row indices
cat(sprintf("Processing batch %d (rows %d to %d)...\n", i, start_idx, end_idx))
# Subset the data table for the current batch and apply the operations
dt[start_idx:end_idx, `:=` (
has_match = sapply(FULL_TEXT, check_matches, words_vector),
matched_words = sapply(FULL_TEXT, function(x) paste(words_vector[stri_detect_fixed(x, words_vector)], collapse=", "))
)]
batch_data <- dt[start_idx:end_idx]
end_time <- Sys.time()
duration <- end_time - start_time
# Print the duration for the current batch
cat(sprintf("Batch %d processed in %f seconds.\n", i, duration))
# ... [rest of your loop code for saving etc.] ...
}
imena <- dt[has_match==T,]
words_vector
# Assuming all is a data.table
setDT(dt)
dt[, FULL_TEXT := tolower(FULL_TEXT)]
# Vectorized function to check for matches
check_matches <- function(text, words_vector) {
any(stri_detect_regex(text, words_vector, negate = FALSE))
}
batch_size <- 1000
# Calculate the number of batches
num_batches <- ceiling(nrow(dt) / batch_size)
# Loop through each batch
for (i in 1:num_batches) {
start_time <- Sys.time()
# Calculate the start and end row indices for the current batch
start_idx <- (i - 1) * batch_size + 1
end_idx <- min(i * batch_size, nrow(dt))
# Print the current batch number and row indices
cat(sprintf("Processing batch %d (rows %d to %d)...\n", i, start_idx, end_idx))
# Subset the data table for the current batch and apply the operations
dt[start_idx:end_idx, `:=` (
has_match = sapply(FULL_TEXT, check_matches, words_vector),
matched_words = sapply(FULL_TEXT, function(x) paste(unlist(str_extract_all(x, words_vector)), collapse=", "))
)]
batch_data <- dt[start_idx:end_idx]
end_time <- Sys.time()
duration <- end_time - start_time
# Print the duration for the current batch
cat(sprintf("Batch %d processed in %f seconds.\n", i, duration))
# ... [rest of your loop code for saving etc.] ...
}
imena <- dt[has_match==T,]
# Loop through each batch
for (i in 1:num_batches) {
# ... existing code ...
# Correct calculation of matched_words
dt[start_idx:end_idx, `:=` (
has_match = sapply(FULL_TEXT, check_matches, words_vector),
matched_words = sapply(FULL_TEXT, function(x) paste(unlist(str_extract_all(x, words_vector)), collapse=", "))
)]
# ... existing code ...
}
imena <- dt[has_match==TRUE,]
imena <- dt[has_match==T,]
# Vectorized function to check for matches
check_matches <- function(text, words_vector) {
any(stri_detect_regex(text, words_vector, negate = FALSE))
}
batch_size <- 1000
# Calculate the number of batches
num_batches <- ceiling(nrow(dt) / batch_size)
# Loop through each batch
for (i in 1:num_batches) {
start_time <- Sys.time()
# Calculate the start and end row indices for the current batch
start_idx <- (i - 1) * batch_size + 1
end_idx <- min(i * batch_size, nrow(dt))
# Print the current batch number and row indices
cat(sprintf("Processing batch %d (rows %d to %d)...\n", i, start_idx, end_idx))
# Subset the data table for the current batch and apply the operations
dt[start_idx:end_idx, `:=` (
has_match = sapply(FULL_TEXT, check_matches, words_vector),
matched_words = sapply(FULL_TEXT, function(x) paste(unlist(str_extract_all(x, words_vector)), collapse=", "))
)]
batch_data <- dt[start_idx:end_idx]
end_time <- Sys.time()
duration <- end_time - start_time
# Print the duration for the current batch
cat(sprintf("Batch %d processed in %f seconds.\n", i, duration))
# ... [rest of your loop code for saving etc.] ...
}
imena <- dt[has_match==T,]
View(imena)
imena <- c("Stepinac","Stojić","Markić", "Mandurić", "Košić" ,"Bajruši", "Bešker","Tomić","Pofuk",  "Lasić", "Marjanović","Bozanić", "Abramović", "Pilsel") %>% tolower()
imena <- c("Stepinac","Stojić","Markić", "Mandurić", "Košić" ,"Bajruši", "Bešker","Tomić","Pofuk",  "Lasić", "Marjanović","Bozanić", "Abramović", "Pilsel") %>% tolower()
pattern_imena <- str_c("\\b(", str_c(imena, collapse = "|"), ")\\b")
# Define the batch size
batch_size <- 1000
# Split your data into batches
batches <- split(dt, ceiling(seq_along(dt[[1]])/batch_size))
# Function to process each batch
process_batch <- function(batch) {
batch %>%
as_tibble() %>%
mutate(
full_text = tolower(FULL_TEXT),
match = str_c(imena, collapse = '|'),
key_word = str_extract_all(full_text, match)
) %>%
filter(lengths(key_word) > 0) %>%
unnest(key_word) %>%
distinct(V1, .keep_all = TRUE)
}
# Process each batch
results <- batches %>%
map(~ process_batch(.x))
imena <- bind_rows(results)
mena <- c("Stepinac","Damir", "Stojić", "Željka" ,"Markić", "Ike", "Mandurić","Vlado", "Košić","Robert" ,"Bajruši", "Inoslav", "Bešker", "Ante" ,"Tomić", "Branimir" ,"Pofuk", "Igor", "Lasić", "Hrvoje", "Marjanović","Bozanić", "Ksenija" ,"Abramović", "Drago","Pilsel") %>% tolower()
imena_root <- sapply(imena, write_tokens)
imena <- c("Stepinac","Damir", "Stojić", "Željka" ,"Markić", "Ike", "Mandurić","Vlado", "Košić","Robert" ,"Bajruši", "Inoslav", "Bešker", "Ante" ,"Tomić", "Branimir" ,"Pofuk", "Igor", "Lasić", "Hrvoje", "Marjanović","Bozanić", "Ksenija" ,"Abramović", "Drago","Pilsel") %>% tolower()
imena_root <- sapply(imena, write_tokens)
imena_root <- sapply(strsplit(imena_root, "\t"), `[`, 2)
imena <- enframe(imena_root, name = "name", value = "root")
imena
words_vector <- str_c("\\b(", str_c(imena, collapse = "|"), ")\\b")
words_vector
words_vector <- str_c("\\b(", str_c(imena$root, collapse = "|"), ")\\b")
words_vector
dt[, FULL_TEXT := tolower(FULL_TEXT)]
# Vectorized function to check for matches
check_matches <- function(text, words_vector) {
any(stri_detect_fixed(text, words_vector, negate = FALSE))
}
batch_size <- 1000
# Calculate the number of batches
num_batches <- ceiling(nrow(dt) / batch_size)
# Loop through each batch
for (i in 1:num_batches) {
start_time <- Sys.time()
# Calculate the start and end row indices for the current batch
start_idx <- (i - 1) * batch_size + 1
end_idx <- min(i * batch_size, nrow(dt))
# Print the current batch number and row indices
cat(sprintf("Processing batch %d (rows %d to %d)...\n", i, start_idx, end_idx))
# Subset the data table for the current batch and apply the operations
dt[start_idx:end_idx, `:=` (
has_match = sapply(FULL_TEXT, check_matches, words_vector),
matched_words = sapply(FULL_TEXT, function(x) paste(words_vector[stri_detect_fixed(x, words_vector)], collapse=", "))
)]
batch_data <- dt[start_idx:end_idx]
end_time <- Sys.time()
duration <- end_time - start_time
# Print the duration for the current batch
cat(sprintf("Batch %d processed in %f seconds.\n", i, duration))
# ... [rest of your loop code for saving etc.] ...
}
imena <- dt[has_match==T,]
# Vectorized function to check for matches
check_matches <- function(text, words_vector) {
any(stri_detect_regex(text, words_vector, negate = FALSE))
}
batch_size <- 1000
# Calculate the number of batches
num_batches <- ceiling(nrow(dt) / batch_size)
# Loop through each batch
for (i in 1:num_batches) {
start_time <- Sys.time()
# Calculate the start and end row indices for the current batch
start_idx <- (i - 1) * batch_size + 1
end_idx <- min(i * batch_size, nrow(dt))
# Print the current batch number and row indices
cat(sprintf("Processing batch %d (rows %d to %d)...\n", i, start_idx, end_idx))
# Subset the data table for the current batch and apply the operations
dt[start_idx:end_idx, `:=` (
has_match = sapply(FULL_TEXT, check_matches, words_vector),
matched_words = sapply(FULL_TEXT, function(x) paste(unlist(str_extract_all(x, words_vector)), collapse=", "))
)]
batch_data <- dt[start_idx:end_idx]
end_time <- Sys.time()
duration <- end_time - start_time
# Print the duration for the current batch
cat(sprintf("Batch %d processed in %f seconds.\n", i, duration))
# ... [rest of your loop code for saving etc.] ...
}
imena <- dt[has_match==T,]
View(imena)
generalno <- c("crkva", "biskup", "Kaptol", "časna sestra", "svećenik", "župnik", "vjernik", "kardinal", "papa", "sveti otac", "redovnik", "redovnica","kršćanstvo", "vjera", "Gospa", "Isus", "katolički", "misa", "pričest", "krizma", "grijeh", "vjeroučitelj", "vjeronauk", "blagoslov","svjedočanstvo", "relikvija", "stigma", "duhovnost", "velečasni","zaređenje", "krunica", "vjeronauk", "ukazanje") %>% tolower()
generalno
a
genralno_root <- sapply(generalno, write_tokens)
genralno_root
genralno_root <- sapply(strsplit(genralno_root, "\t"), `[`, 2)
genralno_root
generalno <- enframe(genralno_root, name = "name", value = "root")
generalno
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
library(xlsx)
library(here)
library(kableExtra)
library(DT)
library(purrr)
library(data.table)
library(tidytext)
library(dplyr)
library(lubridate)
library(anytime)
library(grid)
library(wordcloud)
library(reshape2)
library(ggraph)
library(widyr)
library(topicmodels)
library(ggthemes)
library(xlsx)
library(writexl)
library(data.table)
library(stringi)
dt <- read_excel("D:/LUKA/Academic/HKS/Projekti/Dezinformacije/Data/generalno.xlsx")
library(DBI) ## učitano
con <- dbConnect(RSQLite::SQLite(), path = ":memory:")
library(RSQLite)
install.packages("RSQLite")
library(RSQLite)
library(DBI) ## učitano
con <- dbConnect(RSQLite::SQLite(), path = ":memory:")
copy_to(
dest = con,
df = nycflights13::flights,
name = "flights",
temporary = FALSE,
indexes = list(
c("year", "month", "day"),
"carrier",
"tailnum",
"dest"
)
)
library(dplyr)
copy_to(
dest = con,
df = nycflights13::flights,
name = "flights",
temporary = FALSE,
indexes = list(
c("year", "month", "day"),
"carrier",
"tailnum",
"dest"
)
)
flights_db <- tbl(con, "flights")
flights_db
dbGetQuery(con, "SELECT * FROM flights WHERE dep_delay > 240.0 LIMIT 5")
q_con <-
dbConnect(
bigrquery::bigquery(),
project = "publicdata",
dataset = "samples",
billing = billing_id
)
billing_id <- Sys.getenv("GCE_DEFAULT_PROJECT_ID") ## zamijenite sa vašim ID
q_con <-
dbConnect(
bigrquery::bigquery(),
project = "publicdata",
dataset = "samples",
billing = billing_id
)
dbListTables(bq_con)
dbListTables(q_con)
natality <- tbl(bq_con, "natality")
natality <- tbl(q_con, "natality")
dbListTables(q_con)
View(natality)
bw <-
natality %>%
filter(!is.na(state)) %>% ## makni outlier-e
group_by(year) %>%
summarise(weight_pounds = mean(weight_pounds, na.rm=T)) %>%
collect()
View(bw)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
library(xlsx)
library(here)
library(kableExtra)
library(DT)
library(purrr)
library(data.table)
library(tidytext)
library(dplyr)
library(lubridate)
library(anytime)
library(grid)
library(wordcloud)
library(reshape2)
library(ggraph)
library(widyr)
library(topicmodels)
library(ggthemes)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
library(xlsx)
library(here)
library(kableExtra)
library(DT)
library(purrr)
library(data.table)
library(tidytext)
library(dplyr)
library(lubridate)
library(anytime)
library(grid)
library(wordcloud)
library(reshape2)
library(ggraph)
library(widyr)
library(topicmodels)
library(ggthemes)
library(xlsx)
library(knitr)
library(kableExtra)
# Read In
original <- read.xlsx("D:/LUKA/Freelance/Mediatoolkit/native1.xlsx", sheetIndex = 1) %>% mutate(V1 = as.numeric(V1))
variables <- read.xlsx("D:/LUKA/Academic/Native rad/Native.xlsx", sheetIndex = 1)
variables <- variables[,-c(23,24,25)]# %>% drop_na()
original <- original %>% filter(V1 %in% variables$V1)
dta <- merge(original, variables, by = "V1", all.x = TRUE)
dta$DATE <- as.Date(dta$DATE)
stemmed <- readRDS("D:/LUKA/Freelance/Mediatoolkit/native_token_stemm.rds")
stemmed <- stemmed %>%
rename("wordp" = "word") %>%
rename("word" = "transformed_column")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
library(xlsx)
library(here)
library(kableExtra)
library(DT)
library(purrr)
library(data.table)
library(tidytext)
library(dplyr)
library(lubridate)
library(anytime)
library(grid)
library(wordcloud)
library(reshape2)
library(ggraph)
library(widyr)
library(topicmodels)
library(ggthemes)
library(xlsx)
library(knitr)
library(kableExtra)
library(stopwords)
# Read In
original <- read.xlsx("D:/LUKA/Freelance/Mediatoolkit/native1.xlsx", sheetIndex = 1) %>% mutate(V1 = as.numeric(V1))
variables <- read.xlsx("D:/LUKA/Academic/Native rad/Native.xlsx", sheetIndex = 1)
original <- read.xlsx("C:/Users/lukas/Desktop/native1.xlsx", sheetIndex = 1) %>% mutate(V1 = as.numeric(V1))
variables <- variables[,-c(23,24,25)]# %>% drop_na()
original <- original %>% filter(V1 %in% variables$V1)
dta <- merge(original, variables, by = "V1", all.x = TRUE)
dta$DATE <- as.Date(dta$DATE)
stemmed <- readRDS("C:/Users/lukas/Desktop/native_token_stemm.rds")
stemmed <- readRDS("C:/Users/Lukas/Dropbox/Mediatoolikit/native_token_stemm.rds")
stemmed <- readRDS("C:/Users/Lukas/Dropbox/Mediatoolkit/native_token_stemm.rds")
