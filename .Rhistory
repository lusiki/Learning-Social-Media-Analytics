library(ggthemes)
library(cowplot)
library(magick)
library(png)
library(RCurl)
library(patchwork)
library(grid)
library(ggpubr)
library(scales)
library(kableExtra)
yt <- read.csv2("../data/YouTube/YT.csv")
idNO <- id %>% slice(1251:1350) # %>% slice(-19)
yt %>%
mutate(id = str_sub(link,-24)) %>%
select(id) -> id
idNO <- id %>% slice(1251:1350) # %>% slice(-19)
ids <- paste(idNO$id,collapse = ",")
write.table(ids, "C:/Users/Lukas/OneDrive/Desktop/ytid.txt")
knitr::opts_chunk$set(echo = TRUE)
yt %>%
mutate(id = str_sub(link,-24)) %>%
select(id) -> id
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)
library(ggthemes)
library(cowplot)
library(magick)
library(png)
library(RCurl)
library(patchwork)
library(grid)
library(ggpubr)
library(scales)
library(kableExtra)
yt <- read.csv2("../data/YouTube/YT.csv")
yt %>%
mutate(id = str_sub(link,-24)) %>%
select(id) -> id
idNO <- id %>% slice(1351:nrow(id)) # %>% slice(-19)
nrow(id)
idNO <- id %>% slice(1351:1417) # %>% slice(-19)
ids <- paste(idNO$id,collapse = ",")
write.table(ids, "C:/Users/Lukas/OneDrive/Desktop/ytid.txt")
knitr::opts_chunk$set(echo = TRUE)
filelist = list.files(pattern = "C:/Users/Lukas/OneDrive/Desktop/YouTube Videos/*.txt")
filelist = list.files(pattern = "C:/Users/Lukas/OneDrive/Desktop/YouTube Videos/.*.txt")
filelist
setwd("C:/Users/Lukas/OneDrive/Desktop/YouTube")
filelist = list.files(pattern = ".*.txt")
filelist = list.files(pattern = "*.txt")
filelist
getwd()
setwd("C:/Users/Lukas/OneDrive/Desktop/YouTube")
getwd()
filelist = list.files(path = "C:/Users/Lukas/OneDrive/Desktop/YouTube",
pattern = "*.txt")
filelist
#assuming tab separated values with a header
datalist = lapply(filelist, function(x)read.table(x, header=T))
l
filelist = list.files(path = "C:/Users/Lukas/OneDrive/Desktop/YouTube",
pattern = "*.txt")
#assuming tab separated values with a header
datalist = lapply(filelist, function(x)read.table(x, header=T))
#assuming tab separated values with a header
datalist = lapply(filelist, function(x)read.delim(x, header=T))
filelist
#assuming tab separated values with a header
datalist = lapply(filelist, function(x) read.table(x, header=T))
filelist
filelist = list.files(path = "C:/Users/Lukas/OneDrive/Desktop/YouTube",
pattern = "*.txt",
full.names = TRUE)
filelist
#assuming tab separated values with a header
datalist = lapply(filelist, function(x) read.table(x, header=T))
#install.packages("data.table", repos = "https://cran.rstudio.com")
library(data.table)
# Read all the files and create a FileName column to store filenames
DT <- rbindlist(sapply(filelist, fread, simplify = FALSE),
use.names = TRUE, idcol = "FileName")
View(DT)
filelist
filelist = list.files(path = "C:/Users/Lukas/OneDrive/Desktop/YouTube",
pattern = "*.txt",
full.names = TRUE)
filelist
library(tidyverse)
# Read all the files and create a FileName column to store filenames
df <- filelist %>%
set_names(.) %>%
map_df(read_table2, .id = "FileName")
library(vroom)
# Read all the files and create a FileName column to store filenames
df <- vroom(list_of_files, .id = "FileName")
# Read all the files and create a FileName column to store filenames
df <- vroom(filelist, .id = "FileName")
# Read all the files and create a FileName column to store filenames
df <- vroom(filelist, .id = "FileName")
# Read all the files and create a FileName column to store filenames
df <- filelist %>%
set_names(.) %>%
map_df(readtext, .id = "FileName")
# Read all the files and create a FileName column to store filenames
df <- filelist %>%
set_names(.) %>%
map_df(readtext::readtext, .id = "FileName")
install.packages("readtext")
# Read all the files and create a FileName column to store filenames
df <- filelist %>%
set_names(.) %>%
map_df(readtext::readtext, .id = "FileName")
View(df)
filelist[1]
filelist[1]
yt <- read.delim(filelist[1], header = TRUE)
View(yt)
knitr::opts_chunk$set(echo = TRUE)
filelist = list.files(path = "C:/Users/Lukas/OneDrive/Desktop/YouTube",
pattern = "*.txt",
full.names = TRUE)
filelist
yt <- read.delim(filelist[1],
header = TRUE,
quote = "",
stringsAsFactors = F)
View(yt)
Encoding(datafr)= "UTF-8"
Encoding(yt$channelTitle)= "UTF-8"
yt1 = read_delim(filelist[1],
quote = "")
library(readr)
yt1 = read_delim(filelist[1],
quote = "")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)
library(ggthemes)
library(cowplot)
library(magick)
library(png)
library(RCurl)
library(patchwork)
library(grid)
library(ggpubr)
library(scales)
library(kableExtra)
yt <- read.csv2("../data/YouTube/YT.csv")
filelist = list.files(path = "C:/Users/Lukas/OneDrive/Desktop/YouTube",
pattern = "*.txt",
full.names = TRUE)
library(vroom)
# Read all the files and create a FileName column to store filenames
df <- vroom(filelist)
library(tidyverse)
library(ggplot2)
library(ggthemes)
library(cowplot)
library(magick)
library(png)
library(RCurl)
library(patchwork)
library(grid)
library(ggpubr)
library(scales)
library(kableExtra)
setdiff(df$channelTitle,yt$name)
full <- semi_join(df, yt, by = c('channelTitle','name'))
full <- semi_join(df, yt, by = c("channelTitle","name"))
filelist = list.files(path = "C:/Users/Lukas/OneDrive/Desktop/YouTube",
pattern = "*.txt",
full.names = TRUE)
library(vroom)
# Read all the files and create a FileName column to store filenames
df <- vroom(filelist)
full <- semi_join(df, yt, by = c("channelTitle","name"))
View(df)
full <- semi_join(df, yt, by = c("channelTitle"="name"))
View(full)
full <- left_join(df, yt, by = c("channelTitle"="name"))
length(unique(full$channelTitle))
length(setdiff(df$channelTitle,yt$name))
yt <- read.csv2("../data/YouTube/YT.csv")
t
yt %>%
mutate(id = str_sub(link,-24)) %>%
select(id) -> id
idNO <- id %>% slice(100:200) # %>% slice(-19)
ids <- paste(idNO$id,collapse = ",")
write.table(ids, "C:/Users/Lukas/OneDrive/Desktop/ytid.txt")
View(idNO)
View(yt)
idNO <- id %>% slice(250:350) # %>% slice(-19)
ids <- paste(idNO$id,collapse = ",")
write.table(ids, "C:/Users/Lukas/OneDrive/Desktop/ytid.txt")
str(full)
setdiff(df$channelTitle,yt$name)
View(yt)
View(full)
full <- left_join(df, yt, by = c("channelTitle"="name")) %>% arrange(desc(subscribers))
View(full)
View(full)
View(df)
dplyr::filter(df, grepl("Ella",channelTitle))
View(dplyr::filter(df, grepl("Ella",channelTitle)))
View(dplyr::filter(df, grepl("Ela",channelTitle)))
dplyr::filter(df, grepl("Ela",channelTitle))
length(setdiff(df$channelTitle,yt$name))
setdiff(df$channelTitle,yt$name)
# Read all the files and create a FileName column to store filenames
df <- vroom(filelist) %>%
mutate(id = str_sub(link,-24))
View(df)
yt <- yt %>%
mutate(id = str_sub(link,-24))
names(df)
length(setdiff(df$channelId,yt$id))
setdiff(df$channelId,yt$id)
full <- left_join(df, yt, by = c("channelId"="id")) %>% arrange(desc(subscribers))
razlika = setdiff(df$channelId,yt$id)
razlika2 = setdiff(yt$id,df$channelId)
length(setdiff(yt$id,df$channelId))
razlika2 = setdiff(yt$id,df$channelId)
yt %>% filter(id %in% razlika2)
yt %>% filter(id %in% razlika2) %>% View()
View(full)
dplyr::filter(df, grepl("UC8P837qhN0mpfipm2-7hL9A",channelId))
dplyr::filter(df, grepl("7hL9A",channelId))
dplyr::filter(df, grepl("zbw",channelId))
yt1 = read_delim(filelist[1],
quote = "")
View(yt1)
# Read all the files and create a FileName column to store filenames
df <- vroom(filelist)
library(vroom)
# Read all the files and create a FileName column to store filenames
df <- vroom(filelist)
View(df)
dplyr::filter(df, grepl("Malaj",channelTitle))
View(yt1)
View(df)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)
library(ggthemes)
library(cowplot)
library(magick)
library(png)
library(RCurl)
library(patchwork)
library(grid)
library(ggpubr)
library(scales)
library(kableExtra)
yt <- read.csv2("../data/YouTube/YT.csv")
filelist = list.files(path = "C:/Users/Lukas/OneDrive/Desktop/YouTube",
pattern = "*.txt",
full.names = TRUE)
library(vroom)
# Read all the files and create a FileName column to store filenames
df <- vroom(filelist)
names(df)
names(yt)
yt <- yt %>%
mutate(id = str_sub(link,-24))
names(yt)
razlika1 = setdiff(df$channelId,yt$id)
razlika2 = setdiff(yt$id,df$channelId)
razlika3 = setdiff(df$channelTitle,yt$name)
razlika4 = setdiff(yt$name,df$channelTitle)
View(df)
df[channelTitle== "Entertainment",]
df[df$channelTitle== "Entertainment",]
razlika1 = setdiff(df$channelId,yt$id)
razlika2 = setdiff(yt$id,df$channelId)
df[df$channelId %in% razlika1,]
df[df$channelId %in% razlika1,] %>% View()
df[df$channelId %in% razlika2,] %>% View()
yt[yt$id %in% razlika2,] %>% View()
df[df$channelTitle == "COFI",] %>% View()
df[df$channelTitle == "Malajski Tapir",] %>% View()
yt[yt$id %in% razlika2,] %>% View()
razlika <- yt[yt$id %in% razlika2,]  %>%
mutate(id = str_sub(link,-24))
View(razlika)
razlika <- yt[yt$id %in% razlika2,]  %>%
mutate(id = str_sub(link,-24)) %>%
select(id)
ids <- paste(razlika$id,collapse = ",")
write.table(ids, "C:/Users/Lukas/OneDrive/Desktop/ytid.txt")
yt[yt$id %in% razlika2,]  %>% View()
df[df$channelTitle == "HAUSER",] %>% View()
yt[yt$id %in% razlika2,]  %>% View()
filelist = list.files(path = "C:/Users/Lukas/OneDrive/Desktop/YouTube",
pattern = "*.txt",
full.names = TRUE)
filelist
razlika = read_delim("C:/Users/Lukas/OneDrive/Desktop/YouTube/razlika.txt",
quote = "")
knitr::opts_chunk$set(echo = TRUE)
```{r, echo=FALSE,message=FALSE,warning=FALSE}
library(tidyverse)
library(ggplot2)
library(ggthemes)
library(cowplot)
library(magick)
library(png)
library(RCurl)
library(patchwork)
library(grid)
library(ggpubr)
library(scales)
library(kableExtra)
yt <- read.csv2("../data/YouTube/YT.csv")
filelist = list.files(path = "C:/Users/Lukas/OneDrive/Desktop/YouTube",
pattern = "*.txt",
full.names = TRUE)
library(vroom)
# Read all the files and create a FileName column to store filenames
df <- vroom(filelist)
yt <- yt %>%
mutate(id = str_sub(link,-24))
razlika1 = setdiff(full$channelId,yt$id)
razlika1 = setdiff(df$channelId,yt$id)
razlika2 = setdiff(yt$id,df$channelId)
razlika = read_delim("C:/Users/Lukas/OneDrive/Desktop/YouTube/razlika.txt",
quote = "")
razlikaFull <- left_join(razlika,yt, by = c("channelId"="id"))
full <- left_join(df, yt, by = c("channelId"="id")) %>% arrange(desc(subscribers))
videoYT <- merge(full, razlikaFull, by="row.names", all = TRUE)
require(plyr)
full$rn <- rownames(full)
razlikaFull$rn <- rownames(razlikaFull)
videoYT <- join_all(list(full, razlikaFull), by = 'rn', type = 'full')
razlikaFull %>% arrange(desc(subscribers)) %>% View()
razlikaFull %>% arrange(desc(subscribers))  %>%
group_by(channelTitle) %>%
count()  %>%
View()
View(razlikaFull)
razlikaFull %>%
group_by(channelTitle) %>%
count()
razlikaFull %>% ungroup() %>%
group_by(channelTitle) %>%
count()
razlikaFull %>% ungroup() %>%
group_by(channelId) %>%
count()
unique(razlikaFull$channelTitle)
razlikaFull %>% group_by(channelTitle) %>% summarise(n= n())
razlikaFull %>% group_by(channelTitle) %>% summarise(n())
razlikaFull %>% group_by(channelTitle) %>% summarise(broj = n())
razlikaFull %>% group_by(channelTitle) %>% summarise(broj = count())
razlikaFull %>% group_by(channelTitle) %>% summarise(n=n())
razlikaFull %>% group_by(channelTitle) %>% dplyr::summarise(n=n())
razlikaFull %>% group_by(channelTitle, subscribers) %>% dplyr::summarise(n=n())
razlikaFull %>% group_by(channelTitle, subscribers) %>% dplyr::summarise(n=n()) %>% arrange(desc(subscibers))
razlikaFull %>% group_by(channelTitle, subscribers) %>% dplyr::summarise(n=n()) %>% arrange(desc(subscribers))
full %>% group_by(channelTitle, subscribers) %>%
dplyr::summarise(n=n()) %>%
arrange(desc(subscribers))
razlika3 = setdiff(full$channelTitle,yt$name)
razlika3
full %>% filter(channelTitle=="ADRI")
razlika4 = setdiff(yt$name,videoYT$channelTitle)
razlika4
View(full)
getwd()
knitr::opts_chunk$set(echo = TRUE, cache=TRUE)
source("./Creds/api.R")
source("../Creds/api.R")
source("../Creds/api.R")
source("~/Creds/api.R")
source("./Creds/api.R")
Sys.setenv(toolkittoken <- "ddms5s0l3gejlz2z42ydt0bnwmf6ssqd62bdxteu7t8sumv5ii")
source("./Creds/api.R")
source("../Creds/api.R")
source(Creds/api.R)
source(./Creds/api.R)
source("api.R")
source("Creds/api.R")
source(".Creds/api.R")
groups <- "185076"
keywords <- "6528081"
from_time <- as.character(as.numeric(as.POSIXlt("2021-10-06", format="%Y-%m-%d")))
to_time <- as.character(as.numeric(as.POSIXlt("2022-01-06", format="%Y-%m-%d")))
count <- 2700
probs <- paste0("https://api.mediatoolkit.com/organizations/126686/groups/",groups,
"/keywords/",keywords,
"/mentions?access_token=",token,
"&from_time=",from_time,
"&to_time=",to_time,
"&count=",count,
"&sort=time&type=all&offset=0&ids_only=false")
probs <- paste0("https://api.mediatoolkit.com/organizations/126686/groups/",groups,
"/keywords/",keywords,
"/mentions?access_token=",token,
"&from_time=",from_time,
"&to_time=",to_time,
"&count=",count,
"&sort=time&type=all&offset=0&ids_only=false")
source("./Creds/api.R")
#source("./Creds/api.R")
groups <- "185076"
keywords <- "6528081"
from_time <- as.character(as.numeric(as.POSIXlt("2021-10-06", format="%Y-%m-%d")))
to_time <- as.character(as.numeric(as.POSIXlt("2022-01-06", format="%Y-%m-%d")))
count <- 2700
probs <- paste0("https://api.mediatoolkit.com/organizations/126686/groups/",groups,
"/keywords/",keywords,
"/mentions?access_token=",token,
"&from_time=",from_time,
"&to_time=",to_time,
"&count=",count,
"&sort=time&type=all&offset=0&ids_only=false")
#source("./Creds/api.R")
groups <- "185076"
keywords <- "6528081"
from_time <- as.character(as.numeric(as.POSIXlt("2021-10-06", format="%Y-%m-%d")))
to_time <- as.character(as.numeric(as.POSIXlt("2022-01-06", format="%Y-%m-%d")))
count <- 2700
probs <- paste0("https://api.mediatoolkit.com/organizations/126686/groups/",groups,
"/keywords/",keywords,
"/mentions?access_token=",token,
"&from_time=",from_time,
"&to_time=",to_time,
"&count=",count,
"&sort=time&type=all&offset=0&ids_only=false")
source(here::here('Creds', 'api.R'))
#source("./Creds/api.R")
groups <- "185076"
keywords <- "6528081"
from_time <- as.character(as.numeric(as.POSIXlt("2021-10-06", format="%Y-%m-%d")))
to_time <- as.character(as.numeric(as.POSIXlt("2022-01-06", format="%Y-%m-%d")))
count <- 2700
probs <- paste0("https://api.mediatoolkit.com/organizations/126686/groups/",groups,
"/keywords/",keywords,
"/mentions?access_token=",token,
"&from_time=",from_time,
"&to_time=",to_time,
"&count=",count,
"&sort=time&type=all&offset=0&ids_only=false")
source("~/.active-rstudio-document", encoding = 'UTF-8', echo=TRUE)
freqOFmention %>%
rename (Brand = word,
'Number of mentions' = n)
rijeci_clean %>%
#  filter(word %in% c("xiaomi","samsung","vivo","huawei")) %>%
group_by(word) %>%
summarise(#View =  sum(view, na.rm = TRUE),
Comment =  sum(comment, na.rm = TRUE),
Engagement =  sum(engagement, na.rm = TRUE),
Like =  sum(like, na.rm = TRUE),
#  Virality =  sum(virality, na.rm = TRUE),
#  prValue =  sum(prValue, na.rm = TRUE),
n = n()) %>%
arrange(desc(n))-> freqOFmention
library(kableExtra)
library(ggplot2)
library(ggthemes)
library(scales)
library(tidyverse)
library(httr)
library(lubridate)
library(dplyr)
library(data.table)
library(tidytext)
library(plotly)
source(here::here('Creds', 'api.R'))
#source("./Creds/api.R")
groups <- "185076"
keywords <- "6528081"
from_time <- as.character(as.numeric(as.POSIXlt("2021-10-06", format="%Y-%m-%d")))
to_time <- as.character(as.numeric(as.POSIXlt("2022-01-06", format="%Y-%m-%d")))
count <- 2700
probs <- paste0("https://api.mediatoolkit.com/organizations/126686/groups/",groups,
"/keywords/",keywords,
"/mentions?access_token=",token,
"&from_time=",from_time,
"&to_time=",to_time,
"&count=",count,
"&sort=time&type=all&offset=0&ids_only=false")
# POVUCI
#options(timeout = 4000000)
API_zahtjev <- httr::GET(probs)
jS_tekst <- httr::content(API_zahtjev, as = "text", type = "aplication/json", encoding = "UTF-8")
DF_za_analizu <- jsonlite::fromJSON(jS_tekst, flatten = TRUE)
dta <- data.frame(DF_za_analizu$data)
phillips <- dta %>%
select(keyword = response.keywords,
reach = response.reach,
time = response.insert_time,
description = response.description,
type = response.type,
title = response.title,
mention = response.mention,
from = response.from,
author = response.author,
url = response.url,
domain = response.domain,
comment = response.comment_count,
engagement = response.engagement_rate,
like = response.like_count,
prValue = response.pr_value,
virality = response.virality,
share = response.share_count,
interaction = response.interaction,
ytID = response.youtube_channel_id,
txt = response.full_mention,
view = response.view_count)
