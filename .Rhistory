theme_minimal()
ggplot(gg2, aes(x = factor(text), y = BrojObjava, fill = factor(text))) +
geom_bar(stat = "identity") +
facet_wrap(~ FROM, scales = "free_y") +
coord_flip() +
labs(
x = "Autorstvo",
y = "Broj Objava",
title = "Autorstvo po Medijima"
) +
theme_minimal() +
scale_fill_discrete(name = "text")
ggplot(gg2, aes(x = factor(text), y = BrojObjava, fill = factor(text))) +
geom_bar(stat = "identity") +
facet_wrap(~ FROM, scales = "free_y") +
#  coord_flip() +
labs(
x = "Autorstvo",
y = "Broj Objava",
title = "Autorstvo po Medijima"
) +
theme_minimal() +
scale_fill_discrete(name = "text")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
library(xlsx)
library(here)
library(kableExtra)
library(DT)
library(purrr)
library(data.table)
library(tidytext)
library(dplyr)
library(lubridate)
library(anytime)
library(grid)
library(wordcloud)
library(reshape2)
library(ggraph)
library(widyr)
library(topicmodels)
library(ggthemes)
library(xlsx)
library(writexl)
dt <- read_excel("D:/LUKA/Freelance/Mediatoolkit/catholiq.xlsx") %>% select(-match)
dt <- read_excel("D:/LUKA/Freelance/Mediatoolkit/catholiq.xlsx")
View(dt)
head(dt$TITLE)
dt$TITLE %>% str_extract_all("\\{\\$[0-9\\.]*\\}") %>% compact() %>% head()
unique(dt$SOURCE_TYPE)
paste("Credit reporting, credit repair services,",
"or other personal consumer reports")
knitr::opts_chunk$set(echo = TRUE)
LilaHR  <- read.delim2("C:/Users/Lukas/Dropbox/Mislav@Luka/lilaHR.txt",
header = FALSE,
sep = " ",
stringsAsFactors = FALSE)
View(LilaHR)
LilaHR  <- read.delim2("C:/Users/Lukas/Dropbox/Mislav@Luka/lilaHR.txt",
header = T,
sep = " ",
stringsAsFactors = FALSE)
LilaHR  <- read.delim2("C:/Users/Lukas/Dropbox/Mislav@Luka/lilaHR.txt")
View(LilaHR)
LilaHR  <- read.xlsx2("C:/Users/Lukas/Dropbox/Mislav@Luka/lilaHR.xlsx")
LilaHR  <- read.xlsx2("C:/Users/Lukas/Dropbox/Mislav@Luka/lilaHR.xlsx", sheetIndex = 1)
View(LilaHR)
df <- separate_rows(LilaHR, HR, sep = ", ")
View(df)
zero_rows_count <- sum(apply(df[-1], 1, function(row) all(row == 0)))
print(zero_rows_count)
filtered_df <- df %>%
filter(!apply(.[,-1], 1, function(row) all(row == 0)))
View(filtered_df)
write.xlsx(filtered_df, "C:/Users/Lukas/Dropbox/Mislav@Luka/lilaHR_.xlsx" )
rm(list=ls())
LilaHR  <- read.xlsx2("C:/Users/Lukas/Dropbox/Mislav@Luka/lilaHR_.xlsx", sheetIndex = 1)
View(LilaHR)
LilaHR  <- read.xlsx2("C:/Users/Lukas/Dropbox/Mislav@Luka/lilaHR_.xlsx", sheetIndex = 1)
View(LilaHR)
dt <- read_excel("D:/LUKA/Freelance/Mediatoolkit/catholiq.xlsx")
# tokenize
dt %>%
unnest_tokens(word, TITLE) -> n_token
View(n_token)
# remove stop words, numbers, single letters
n_token %>%
anti_join(stop_corpus, by = "word") %>%
mutate(word = gsub("\\d+", NA, word)) %>%
mutate(word = gsub("^[a-zA-Z]$", NA, word)) -> n_tokenTidy
# read in lexicons
CroSentilex_n <- read.delim("C:/Users/Lukas/Dropbox/Mislav@Luka/crosentilex-negatives.txt",
header = FALSE,
sep = " ",
stringsAsFactors = FALSE,
fileEncoding = "UTF-8")  %>%
rename(word = "V1", sentiment = "V2" ) %>%
mutate(brija = "NEG")
CroSentilex_p  <- read.delim("C:/Users/Lukas/Dropbox/Mislav@Luka/crosentilex-positives.txt",
header = FALSE,
sep = " ",
stringsAsFactors = FALSE,
fileEncoding = "UTF-8") %>%
rename(word = "V1", sentiment = "V2" ) %>%
mutate(brija = "POZ")
Crosentilex_sve <- rbind(setDT(CroSentilex_n), setDT(CroSentilex_p))
# check lexicon data
#head(sample_n(Crosentilex_sve,1000),15)
CroSentilex_Gold  <- read.delim2("C:/Users/Lukas/Dropbox/Mislav@Luka/gs-sentiment-annotations.txt",
header = FALSE,
sep = " ",
stringsAsFactors = FALSE) %>%
rename(word = "V1", sentiment = "V2" )
Encoding(CroSentilex_Gold$word) <- "UTF-8"
CroSentilex_Gold[1,1] <- "dati"
CroSentilex_Gold$sentiment <- str_replace(CroSentilex_Gold$sentiment , "-", "1")
CroSentilex_Gold$sentiment <- str_replace(CroSentilex_Gold$sentiment , "\\+", "2")
CroSentilex_Gold$sentiment <- as.numeric(unlist(CroSentilex_Gold$sentiment))
# check lexicon data
#head(sample_n(CroSentilex_Gold,100),15)
# create stop words
stopwords_cro <- get_stopwords(language = "hr", source = "stopwords-iso")
# check stopwords data
#head(sample_n(stopwords_cro,100),15)
# extend stop words
my_stop_words <- tibble(
word = c(
"jedan","mjera", "može", "možete", "mogu", "kad", "sada", "treba", "ima", "osoba",
"e","prvi", "dva","dvije","drugi",
"tri","treći","pet","kod",
"ove","ova",  "ovo","bez", "kod",
"evo","oko",  "om", "ek",
"mil","tko","šest", "sedam",
"osam",   "čim", "zbog",
"prema", "dok","zato", "koji",
"im", "čak","među", "tek",
"koliko", "tko","kod","poput",
"baš", "dakle", "osim", "svih",
"svoju", "odnosno", "gdje",
"kojoj", "ovi", "toga",
"ubera", "vozača", "hrvatskoj", "usluge", "godine", "više", "taksi", "taxi", "taksija", "taksija", "kaže", "rekao", "19"," aee", "ae","bit.ly", "https", "one", "the"
),
lexicon = "lux"
)
stop_corpus <- my_stop_words %>%
bind_rows(stopwords_cro)
# check stopwords data
#head(sample_n(stop_corpus,100),15)
LilaHR  <- read.xlsx2("C:/Users/Lukas/Dropbox/Mislav@Luka/lilaHR_.xlsx", sheetIndex = 1)
# remove stop words, numbers, single letters
n_token %>%
anti_join(stop_corpus, by = "word") %>%
mutate(word = gsub("\\d+", NA, word)) %>%
mutate(word = gsub("^[a-zA-Z]$", NA, word)) -> n_tokenTidy
# remove NA
n_tokenTidy %>%
filter(!is.na(word)) -> n_tokenTidy
n_tokenTidy %>%
group_by(word) %>%
summarise(N = n()) %>%
arrange(desc(N)) %>%
filter(N > 10000) %>%
datatable(., options = list(scrollX = TRUE, scrollY = "500px"))
n_tokenTidy %>%
group_by(word) %>%
summarise(N = n()) %>%
arrange(desc(N)) %>%
filter(N > 100) %>%
datatable(., options = list(scrollX = TRUE, scrollY = "500px"))
generalno <- c("crkva", "biskup", "Kaptol", "časna sestra", "svećenik", "župnik", "vjernik", "kardinal", "papa", "sveti otac", "redovnik", "redovnica","kršćanstvo", "vjera", "Gospa", "Bog", "Isus", "katolički", "misa", "pričest", "krizma", "grijeh", "vjeroučitelj", "vjeronauk", "blagoslov","svjedočanstvo", "relikvija", "stigma", "duhovnost", "don", "fra", "velečasni","zaređenje", "krunica", "vjeronauk", "ukazanje")
imena <- c("Stepinac","Damir", "Stojić", "Željka" ,"Markić", "Ike", "Mandurić","Vlado", "Košić","Robert" ,"Bajruši", "Inoslav", "Bešker", "Ante" ,"Tomić", "Branimir" ,"Pofuk", "Igor", "Lasić", "Hrvoje", "Marjanović","Bozanić", "Ksenija" ,"Abramović", "Drago","Pilsel")
institucije  <- c("Ksaver", "HBK", "Opus Dei", "Udruga Protagora","Caritas")
pravno <- c("vatikanski", "ugovori", "plaćanje", "blagoslova","sakramenata", "nekretnine", "imovina")
politika <- C("Hod za život", "U ime obitelji", "prolife", "poništenje Rimskih ugovora", "sekularizacija", "sekularna država", "klerikalizam", "Crkva ruši vlast", "veličaju ustaštvo", "oduzimaju prava ženama", "žele stvoriti katoličku državu", "crkvena afera", "zataškavanje Kaptola", "šutnja Kaptola", "Rimski ugovori","vjeronauk u školama", "vatikanski ugovori", "vatikanska banka" ,"klerikalna vlast","država nije odvojena od Crkve", "potiče homofobiju", "rodna ideologija", "klerikalizam", "ravnozemljaši", "gay brak", "podržavali ustaše", "podržavali naciste", "blagoslovili rat", "Hrvatska nije sekularna država","Katolička crkva vlada Hrvatskom","žene u Crkvi")
fraze <- c("pedofilija", "klečavci", "kaptolaši", "popovi lopovi", "zatucani katolici", "katolički fanatici", "katolički fašisti", "katolibani","crkvenjak", "ekstremni vjernici")
pomocno <- c( "smijenjen","konzervativci", "tradicionalisti", "pobačaj", "abortus", "aktivisti", "aktivizam", "jezuiti", "nazadan", "zaostao", "neobrazovan", "privilegije" , "privilegiran", "diskriminacija", "nacionalizam", "nacionalisti", "ekstremisti", "otpušten", "prekrštavanje", "izopćen", "izbačen", "bludničio",  "posvećenje",  , "inkardiniran", "inkardinacija",  "mračno doba", "razotkrio", "prijavio", "bludničio", "pronevjerio", "homofobijam", "zlodjela", "progoni", "dogma", "kontroverzni svećenik", "moderni svećenik", "tolerantna vjera", "vjerska policija", "vjerska kontrola", "crkveni mediji", "vjerski mediji", "ukidanje", "homofob", "pedofil", "homoseksualnost", "patrijarhat", "čudesno ozdravljenje", "čudo")
imena <- c("Stepinac","Damir", "Stojić", "Željka" ,"Markić", "Ike", "Mandurić","Vlado", "Košić","Robert" ,"Bajruši", "Inoslav", "Bešker", "Ante" ,"Tomić", "Branimir" ,"Pofuk", "Igor", "Lasić", "Hrvoje", "Marjanović","Bozanić", "Ksenija" ,"Abramović", "Drago","Pilsel")
institucije  <- c("Ksaver", "HBK", "Opus Dei", "Udruga Protagora","Caritas")
pravno <- c("vatikanski", "ugovori", "plaćanje", "blagoslova","sakramenata", "nekretnine", "imovina")
politika <- C("Hod za život", "U ime obitelji", "prolife", "poništenje Rimskih ugovora", "sekularizacija", "sekularna država", "klerikalizam", "Crkva ruši vlast", "veličaju ustaštvo", "oduzimaju prava ženama", "žele stvoriti katoličku državu", "crkvena afera", "zataškavanje Kaptola", "šutnja Kaptola", "Rimski ugovori","vjeronauk u školama", "vatikanski ugovori", "vatikanska banka" ,"klerikalna vlast","država nije odvojena od Crkve", "potiče homofobiju", "rodna ideologija", "klerikalizam", "ravnozemljaši", "gay brak", "podržavali ustaše", "podržavali naciste", "blagoslovili rat", "Hrvatska nije sekularna država","Katolička crkva vlada Hrvatskom","žene u Crkvi")
fraze <- c("pedofilija", "klečavci", "kaptolaši", "popovi lopovi", "zatucani katolici", "katolički fanatici", "katolički fašisti", "katolibani","crkvenjak", "ekstremni vjernici")
imena <- c("Stepinac","Stojić","Markić", "Mandurić", "Košić" ,"Bajruši", "Bešker","Tomić","Pofuk",  "Lasić", "Marjanović","Bozanić", "Abramović", "Pilsel") %>% tolower()
pattern_imena <- str_c("\\b(", str_c(imena, collapse = "|"), ")\\b")
# Define the batch size
batch_size <- 1000
# Split your data into batches
batches <- split(dt, ceiling(seq_along(dt[[1]])/batch_size))
# Function to process each batch
process_batch <- function(batch) {
batch %>%
as_tibble() %>%
mutate(
full_text = tolower(FULL_TEXT),
match = str_c(imena, collapse = '|'),
key_word = str_extract_all(full_text, match)
) %>%
filter(lengths(key_word) > 0) %>%
unnest(key_word) %>%
distinct(V1, .keep_all = TRUE)
}
# Process each batch
results <- batches %>%
map(~ process_batch(.x))
# Process each batch
results <- batches %>%
map(~ process_batch(.x))
imena <- bind_rows(results)
View(imena)
filtered_imena <- imena %>%
filter(str_detect(full_text, pattern_imena))
filtered_imena %>% group_by(key_word) %>% count() %>% arrange(desc(n))
fraze <- c("pedofilija", "klečavci", "kaptolaši", "popovi", "lopovi", "zatucani" , "fanatici", "fašisti", "katolibani","crkvenjak", "ekstremni")
pattern_fraze <- str_c("\\b(", str_c(fraze, collapse = "|"), ")\\b")
# Define the batch size
batch_size <- 1000
# Split your data into batches
batches <- split(dt, ceiling(seq_along(dt[[1]])/batch_size))
# Function to process each batch
process_batch <- function(batch) {
batch %>%
as_tibble() %>%
mutate(
full_text = tolower(FULL_TEXT),
match = str_c(fraze, collapse = '|'),
key_word = str_extract_all(full_text, match)
) %>%
filter(lengths(key_word) > 0) %>%
unnest(key_word) %>%
distinct(V1, .keep_all = TRUE)
}
# Process each batch
results <- batches %>%
map(~ process_batch(.x))
fraze <- bind_rows(results)
filtered_df <- fraze %>%
filter(str_detect(full_text, pattern_fraze))
filtered_df %>% group_by(key_word) %>% count() %>% arrange(desc(n))
pravno <- c("vatikanski", "ugovori", "plaćanje", "blagoslova","sakramenata", "nekretnine", "imovina")
pattern_pravno <- str_c("\\b(", str_c(pravno, collapse = "|"), ")\\b")
# Define the batch size
batch_size <- 1000
# Split your data into batches
batches <- split(dt, ceiling(seq_along(dt[[1]])/batch_size))
# Function to process each batch
process_batch <- function(batch) {
batch %>%
as_tibble()  %>%
mutate(
full_text = tolower(FULL_TEXT),
match = str_c(pravno, collapse = '|'),
key_word = str_extract_all(full_text, match)
) %>%
filter(lengths(key_word) > 0) %>%
unnest(key_word) %>%
distinct(V1, .keep_all = TRUE)
}
# Process each batch
results <- batches %>%
map(~ process_batch(.x))
pravno <- bind_rows(results)
filtered_df <- pravno %>%
filter(str_detect(full_text, pattern_pravno))
filtered_df %>% group_by(key_word) %>% count() %>% arrange(desc(n))
institucije  <- c("Ksaver", "HBK", "Opus Dei", "Udruga Protagora","Caritas") %>% tolower()
pattern_institucije <- str_c("\\b(", str_c(institucije, collapse = "|"), ")\\b")
# Define the batch size
batch_size <- 1000
# Split your data into batches
batches <- split(dt, ceiling(seq_along(dt[[1]])/batch_size))
# Function to process each batch
process_batch <- function(batch) {
batch %>%
as_tibble() %>%
mutate(
full_text = tolower(FULL_TEXT),
match = str_c(institucije, collapse = '|'),
key_word = str_extract_all(full_text, match)
) %>%
filter(lengths(key_word) > 0) %>%
unnest(key_word) %>%
distinct(V1, .keep_all = TRUE)
}
# Process each batch
results <- batches %>%
map(~ process_batch(.x))
# Process each batch
results <- batches %>%
map(~ process_batch(.x))
institucije <- bind_rows(results)
filtered_df <- institucije %>%
filter(str_detect(full_text, pattern_institucije))
filtered_df %>% group_by(key_word) %>% count() %>% arrange(desc(n))
politika <- c("Hod","život", "obitelji", "prolife", "poništenje", "ugovora", "sekularizacija", "sekularna","država", "klerikalizam", "ruši","vlast", "veličaju" ,"ustaštvo", "oduzimaju", "prava", "ženama", "katoličku","državu", "afera", "zataškavanje", "Kaptol", "šutnja", "Rimski","vjeronauk" ,"škola", "vatikanski", "ugovori", "vatikanska", "banka" ,"klerikalna", "vlast","država","odvojena", "potiče", "homofobiju", "rodna", "ideologija", "klerikalizam", "ravnozemljaši", "gay", "brak", "podržavali", "ustaše", "podržavali", "naciste", "blagoslovili", "rat", "Hrvatska", "sekularna","katolička", "crkva", "vlada","Hrvatskom","žene") %>% tolower()
politika <- c("Hod","život", "obitelji", "prolife", "poništenje", "ugovora", "sekularizacija", "sekularna","država", "klerikalizam", "ruši","vlast", "veličaju" ,"ustaštvo", "oduzimaju", "prava", "ženama", "katoličku","državu", "afera", "zataškavanje", "Kaptol", "šutnja", "Rimski","vjeronauk" ,"škola", "vatikanski", "ugovori", "vatikanska", "banka" ,"klerikalna", "vlast","država","odvojena", "potiče", "homofobiju", "rodna", "ideologija", "klerikalizam", "ravnozemljaši", "gay", "brak", "podržavali", "ustaše", "podržavali", "naciste", "blagoslovili", "rat", "Hrvatska", "sekularna","katolička", "crkva", "vlada","Hrvatskom","žene") %>% tolower()
pattern_politika <- str_c("\\b(", str_c(politika, collapse = "|"), ")\\b")
# Define the batch size
batch_size <- 1000
# Split your data into batches
batches <- split(dt, ceiling(seq_along(dt[[1]])/batch_size))
# Function to process each batch
process_batch <- function(batch) {
batch %>%
as_tibble()  %>%
mutate(
full_text = tolower(FULL_TEXT),
match = str_c(politika, collapse = '|'),
key_word = str_extract_all(full_text, match)
) %>%
filter(lengths(key_word) > 0) %>%
unnest(key_word) %>%
distinct(V1, .keep_all = TRUE)
}
# Process each batch
results <- batches %>%
map(~ process_batch(.x))
politika <- bind_rows(results)
filtered_df <- politika %>%
filter(str_detect(full_text, pattern_politika))
View(filtered_df)
View(LilaHR)
View(n_token)
knitr::opts_chunk$set(echo = TRUE)
library(reticulate)
reticulate::repl_python()
import re
import sys
import re
import sys
stop=set(['biti','jesam','budem','sam','jesi','budeš','si','jesmo','budemo','smo','jeste','budete','ste','jesu','budu','su','bih','bijah','bjeh','bijaše','bi','bje','bješe','bijasmo','bismo','bjesmo','bijaste','biste','bjeste','bijahu','biste','bjeste','bijahu','bi','biše','bjehu','bješe','bio','bili','budimo','budite','bila','bilo','bile','ću','ćeš','će','ćemo','ćete','želim','želiš','želi','želimo','želite','žele','moram','moraš','mora','moramo','morate','moraju','trebam','trebaš','treba','trebamo','trebate','trebaju','mogu','možeš','može','možemo','možete'])
def istakniSlogotvornoR(niz):
return re.sub(r'(^|[^aeiou])r($|[^aeiou])',r'\1R\2',niz)
def imaSamoglasnik(niz):
if re.search(r'[aeiouR]',istakniSlogotvornoR(niz)) is None:
return False
else:
return True
def transformiraj(pojavnica):
for trazi,zamijeni in transformacije:
if pojavnica.endswith(trazi):
return pojavnica[:-len(trazi)]+zamijeni
return pojavnica
def korjenuj(pojavnica):
for pravilo in pravila:
dioba=pravilo.match(pojavnica)
if dioba is not None:
if imaSamoglasnik(dioba.group(1)) and len(dioba.group(1))>1:
return dioba.group(1)
return pojavnica
if __name__=='__main__':
if len(sys.argv)!=3:
print 'Usage: python Croatian_stemmer.py input_file output_file'
print 'input_file should be an utf8-encoded text file which is then tokenized, stemmed and written in the output_file in a tab-separated fashion.'
sys.exit(1)
output_file=open(sys.argv[2],'w')
pravila=[re.compile(r'^('+osnova+')('+nastavak+r')$') for osnova, nastavak in [e.decode('utf8').strip().split(' ') for e in open('rules.txt')]]
transformacije=[e.decode('utf8').strip().split('\t') for e in open('transformations.txt')]
for token in re.findall(r'\w+',open(sys.argv[1]).read().decode('utf8'),re.UNICODE):
if token.lower() in stop:
output_file.write((token+'\t'+token.lower()+'\n').encode('utf8'))
continue
output_file.write((token+'\t'+korjenuj(transformiraj(token.lower()))+'\n').encode('utf8'))
output_file.close()
quit
istakniSlogotvornoR <- function(niz) {
stringr::str_replace_all(niz, "(^|[^aeiou])r($|[^aeiou])", "\\1R\\2")
}
imaSamoglasnik <- function(niz) {
!is.na(stringr::str_detect(istakniSlogotvornoR(niz), "[aeiouR]"))
}
stop=c('biti','jesam','budem','sam','jesi','budeš','si','jesmo','budemo','smo','jeste','budete','ste','jesu','budu','su','bih','bijah','bjeh','bijaše','bi','bje','bješe','bijasmo','bismo','bjesmo','bijaste','biste','bjeste','bijahu','biste','bjeste','bijahu','bi','biše','bjehu','bješe','bio','bili','budimo','budite','bila','bilo','bile','ću','ćeš','će','ćemo','ćete','želim','želiš','želi','želimo','želite','žele','moram','moraš','mora','moramo','morate','moraju','trebam','trebaš','treba','trebamo','trebate','trebaju','mogu','možeš','može','možemo','možete')
transformiraj <- function(pojavnica) {
for(i in 1:nrow(transformacije)) {
trazi <- transformacije[i, 1]
zamijeni <- transformacije[i, 2]
if (endsWith(pojavnica, trazi)) {
return(sub(paste0(trazi, "$"), zamijeni, pojavnica))
}
}
return(pojavnica)
}
korjenuj <- function(pojavnica) {
for(pravilo in pravila) {
dioba <- stringr::str_match(pojavnica, pravilo)
if (!is.na(dioba[2])) {
if (imaSamoglasnik(dioba[2]) && nchar(dioba[2]) > 1) {
return(dioba[2])
}
}
}
return(pojavnica)
}
# Assuming you have 'input_file.txt' and 'output_file.txt' as your input and output
input_file <- 'input_file.txt'
output_file <- 'output_file.txt'
pravila <- lapply(strsplit(trimws(readLines('rules.txt')), ' '), function(x) paste0('^(', x[1], ')(', x[2], ')$'))
transformacije <- as.data.frame(do.call(rbind, strsplit(trimws(readLines('transformations.txt')), '\t')))
text <- tolower(readLines(input_file))
pravila <- lapply(strsplit(trimws(readLines('C:/Users/Lukas/Dropbox/Mislav@Luka/rules.txt')), ' '), function(x) paste0('^(', x[1], ')(', x[2], ')$'))
transformacije <- as.data.frame(do.call(rbind, strsplit(trimws(readLines('C:/Users/Lukas/Dropbox/Mislav@Luka/transformations.txt')), '\t')))
View(n_tokenTidy)
text <- n_tokenTidy$word %>% slice(1000)
text <- n_tokenTidy$word %>% head(1000)
text
tokens <- unlist(stringi::stri_extract_all_words(text))
tokens
write_tokens <- function(token) {
if (token %in% stop) {
return(paste0(token, '\t', token))
} else {
return(paste0(token, '\t', korjenuj(transformiraj(token))))
}
}
results <- sapply(tokens, write_tokens)
results
results[1]
results[1:10]
extracted <- sapply(strsplit(results, "\t"), `[`, 2)
extracted
names(extracted) <- NULL
extracted
stopwords_cro
stop_corpus
View(fraze)
# tokenize
fraze %>%
unnest_tokens(word, FULL_TEXT) -> n_token
fraze %>%
unnest_tokens(word, FULL_TEXT) -> n_token
# remove stop words, numbers, single letters
n_token %>%
anti_join(stop_corpus, by = "word") %>%
mutate(word = gsub("\\d+", NA, word)) %>%
mutate(word = gsub("^[a-zA-Z]$", NA, word)) -> n_tokenTidy
# remove NA
n_tokenTidy %>%
filter(!is.na(word)) -> n_tokenTidy
View(n_tokenTidy)
n_tokenTidy <- n_tokenTidy %>%
mutate(
word_korijen = sapply(tokens_column, function(x) {
result <- sapply(x, write_tokens)
extracted <- sapply(strsplit(result, "\t"), `[`, 2)
names(extracted) <- NULL
return(extracted)
})
)
n_tokenTidy <- n_tokenTidy %>%
mutate(
word_korijen = sapply(word, function(x) {
result <- sapply(x, write_tokens)
extracted <- sapply(strsplit(result, "\t"), `[`, 2)
names(extracted) <- NULL
return(extracted)
})
)
proba <- n_tokenTidy %>% slice(1:10000)
proba <- n_tokenTidy %>% slice(1:10000) %>%
mutate(
word_korijen = sapply(word, function(x) {
result <- sapply(x, write_tokens)
extracted <- sapply(strsplit(result, "\t"), `[`, 2)
names(extracted) <- NULL
return(extracted)
})
)
proba <- n_tokenTidy %>% slice(1:1000) %>%
mutate(
results = map(tokens_column, write_tokens),
transformed_column = map_chr(results, ~ str_extract(.x, "(?<=\t)[^\t]+$"))
) %>%
select(-results)
proba <- n_tokenTidy %>% slice(1:1000) %>%
mutate(
results = map(word, write_tokens),
transformed_column = map_chr(results, ~ str_extract(.x, "(?<=\t)[^\t]+$"))
) %>%
select(-results)
proba
proba <- n_tokenTidy %>% slice(1:10000) %>%
mutate(
results = map(word, write_tokens),
transformed_column = map_chr(results, ~ str_extract(.x, "(?<=\t)[^\t]+$"))
) %>%
select(-results)
proba %>%
group_by(word) %>%
summarise(N = n()) %>%
arrange(desc(N)) %>%
filter(N > 100) %>%
datatable(., options = list(scrollX = TRUE, scrollY = "500px"))
View(proba)
proba %>%
group_by(word) %>%
summarise(N = n()) %>%
arrange(desc(N)) %>%
filter(N > 10) %>%
datatable(., options = list(scrollX = TRUE, scrollY = "500px"))
proba %>%
group_by(transformed_column) %>%
summarise(N = n()) %>%
arrange(desc(N)) %>%
filter(N > 10) %>%
datatable(., options = list(scrollX = TRUE, scrollY = "500px"))
proba %>%
group_by(word) %>%
summarise(N = n()) %>%
arrange(desc(N)) %>%
filter(N > 10) %>%
datatable(., options = list(scrollX = TRUE, scrollY = "500px"))
setDT(n_tokenTidy)
n_tokenTidy[, transformed_column := sapply(strsplit(sapply(word, write_tokens), "\t"), `[`, 2)]
