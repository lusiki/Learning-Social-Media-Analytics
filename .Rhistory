inner_join(CroSentilex_Gold, by = "word") %>%
count(word, sentiment, sort = TRUE) -> sg
sg %>%
group_by(sentiment) %>%
top_n(20) %>%
ungroup() %>%
mutate(sentiment = case_when(sentiment == 0 ~ "NEUTRALNO",
sentiment == 1 ~ "NEGATIVNO",
sentiment == 2 ~ "POZITIVNO")) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n, fill = sentiment)) +
geom_col(show.legend = FALSE) +
ggtitle( "Doprinos sentimentu") +
labs( x = "Rijec", y = "Broj rijeci") +
facet_wrap(~ sentiment, scales = "free_y") +
coord_flip() +
theme_economist()-> gg_doprinos_sentimentu
gg_doprinos_sentimentu
phillipstxt %>%
mutate(kword = case_when(grepl("phill", MENTION_SNIPPET, ignore.case = TRUE) ~ "phillips",
grepl("bosch", MENTION_SNIPPET, ignore.case = TRUE) ~ "bosch",
grepl("braun", MENTION_SNIPPET, ignore.case = TRUE) ~ "braun",
grepl("dyson", MENTION_SNIPPET, ignore.case = TRUE) ~ "dyson")) %>%
filter(SOURCE_TYPE == "web" ) %>%
unnest_tokens(word, TITLE) %>%
anti_join(stop_corpus, by = "word") %>%
inner_join(CroSentilex_Gold, by = "word") %>%
count(word, sentiment, sort = TRUE) -> sg
sg %>%
group_by(sentiment) %>%
top_n(20) %>%
ungroup() %>%
mutate(sentiment = case_when(sentiment == 0 ~ "NEUTRALNO",
sentiment == 1 ~ "NEGATIVNO",
sentiment == 2 ~ "POZITIVNO")) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n, fill = sentiment)) +
geom_col(show.legend = FALSE) +
ggtitle( "Doprinos sentimentu") +
labs( x = "Rijec", y = "Broj rijeci") +
facet_wrap(~ sentiment, scales = "free_y") +
coord_flip() +
theme_economist()-> gg_doprinos_sentimentu
gg_doprinos_sentimentu
phillipstxt %>%
mutate(kword = case_when(grepl("phill", MENTION_SNIPPET, ignore.case = TRUE) ~ "phillips",
grepl("bosch", MENTION_SNIPPET, ignore.case = TRUE) ~ "bosch",
grepl("braun", MENTION_SNIPPET, ignore.case = TRUE) ~ "braun",
grepl("dyson", MENTION_SNIPPET, ignore.case = TRUE) ~ "dyson")) %>%
filter(SOURCE_TYPE == "twitter" ) %>%
unnest_tokens(word, TITLE) %>%
anti_join(stop_corpus, by = "word") %>%
inner_join(CroSentilex_Gold, by = "word") %>%
count(word, sentiment, sort = TRUE) -> sg
sg %>%
group_by(sentiment) %>%
top_n(20) %>%
ungroup() %>%
mutate(sentiment = case_when(sentiment == 0 ~ "NEUTRALNO",
sentiment == 1 ~ "NEGATIVNO",
sentiment == 2 ~ "POZITIVNO")) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n, fill = sentiment)) +
geom_col(show.legend = FALSE) +
ggtitle( "Doprinos sentimentu") +
labs( x = "Rijec", y = "Broj rijeci") +
facet_wrap(~ sentiment, scales = "free_y") +
coord_flip() +
theme_economist()-> gg_doprinos_sentimentu
gg_doprinos_sentimentu
phillipstxt %>%
mutate(kword = case_when(grepl("phill", MENTION_SNIPPET, ignore.case = TRUE) ~ "phillips",
grepl("bosch", MENTION_SNIPPET, ignore.case = TRUE) ~ "bosch",
grepl("braun", MENTION_SNIPPET, ignore.case = TRUE) ~ "braun",
grepl("dyson", MENTION_SNIPPET, ignore.case = TRUE) ~ "dyson")) %>%
filter(SOURCE_TYPE == "instagram" ) %>%
unnest_tokens(word, TITLE) %>%
anti_join(stop_corpus, by = "word") %>%
inner_join(CroSentilex_Gold, by = "word") %>%
count(word, sentiment, sort = TRUE) -> sg
sg %>%
group_by(sentiment) %>%
top_n(20) %>%
ungroup() %>%
mutate(sentiment = case_when(sentiment == 0 ~ "NEUTRALNO",
sentiment == 1 ~ "NEGATIVNO",
sentiment == 2 ~ "POZITIVNO")) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n, fill = sentiment)) +
geom_col(show.legend = FALSE) +
ggtitle( "Doprinos sentimentu") +
labs( x = "Rijec", y = "Broj rijeci") +
facet_wrap(~ sentiment, scales = "free_y") +
coord_flip() +
theme_economist()-> gg_doprinos_sentimentu
gg_doprinos_sentimentu
phillipstxt %>%
mutate(kword = case_when(grepl("phill", MENTION_SNIPPET, ignore.case = TRUE) ~ "phillips",
grepl("bosch", MENTION_SNIPPET, ignore.case = TRUE) ~ "bosch",
grepl("braun", MENTION_SNIPPET, ignore.case = TRUE) ~ "braun",
grepl("dyson", MENTION_SNIPPET, ignore.case = TRUE) ~ "dyson")) %>%
filter(SOURCE_TYPE == "facebook" ) %>%
unnest_tokens(word, TITLE) %>%
anti_join(stop_corpus, by = "word") %>%
inner_join(CroSentilex_Gold, by = "word") %>%
count(word, sentiment, sort = TRUE) -> sg
sg %>%
group_by(sentiment) %>%
top_n(20) %>%
ungroup() %>%
mutate(sentiment = case_when(sentiment == 0 ~ "NEUTRALNO",
sentiment == 1 ~ "NEGATIVNO",
sentiment == 2 ~ "POZITIVNO")) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n, fill = sentiment)) +
geom_col(show.legend = FALSE) +
ggtitle( "Doprinos sentimentu") +
labs( x = "Rijec", y = "Broj rijeci") +
facet_wrap(~ sentiment, scales = "free_y") +
coord_flip() +
theme_economist()-> gg_doprinos_sentimentu
gg_doprinos_sentimentu
knitr::opts_chunk$set(echo = TRUE, cache = F)
library(kableExtra)
library(ggplot2)
library(ggthemes)
library(scales)
library(tidyverse)
library(httr)
library(lubridate)
library(dplyr)
library(data.table)
library(tidytext)
library(plotly)
source(here::here('Creds', 'api.R'))
#source("./Creds/api.R")
groups <- "185076"
keywords <- "6528081"
from_time <- as.character(as.numeric(as.POSIXlt("2021-10-06", format="%Y-%m-%d")))
to_time <- as.character(as.numeric(as.POSIXlt("2022-01-06", format="%Y-%m-%d")))
count <- 2700
probs <- paste0("https://api.mediatoolkit.com/organizations/126686/groups/",groups,
"/keywords/",keywords,
"/mentions?access_token=",token,
"&from_time=",from_time,
"&to_time=",to_time,
"&count=",count,
"&sort=time&type=all&offset=0&ids_only=false")
API_zahtjev <- httr::GET(probs)
jS_tekst <- httr::content(API_zahtjev, as = "text", type = "aplication/json", encoding = "UTF-8")
DF_za_analizu <- jsonlite::fromJSON(jS_tekst, flatten = TRUE)
dta <- data.frame(DF_za_analizu$data)
dta
phillips <- dta %>%
select(keyword = response.keywords,
reach = response.reach,
time = response.insert_time,
description = response.description,
type = response.type,
title = response.title,
mention = response.mention,
from = response.from,
author = response.author,
url = response.url,
domain = response.domain,
comment = response.comment_count,
engagement = response.engagement_rate,
like = response.like_count,
prValue = response.pr_value,
virality = response.virality,
share = response.share_count,
interaction = response.interaction,
ytID = response.youtube_channel_id,
txt = response.full_mention,
view = response.view_count)
phillips
knitr::opts_chunk$set(echo = F)
library(tidyverse)
library(tidyverse)
library(readxl)
??list.files
f <- list.files(path = "D:/LUKA/Freelance/Mediatoolkit/FULLDATA", pattern="xls$")
f
f <- list.files(path = "D:/LUKA/Freelance/Mediatoolkit/FULLDATA", pattern="xlsx")
f
all_raw <- map_df(raw, read_excel)
raw <- list.files(path = "D:/LUKA/Freelance/Mediatoolkit/FULLDATA", pattern="xlsx")
all_raw <- map_df(raw, read_excel)
raw
all_raw <- map_df(raw, read_excel)
raw
path <- "D:/LUKA/Freelance/Mediatoolkit/FULLDATA"
raw <- list.files(path = path , pattern="xlsx")
raw_path <- paste(path, "/", raw)
raw_path
raw_path <- paste0(path, "/", raw)
raw_path
all_raw <- map_df(raw, read_excel)
all_raw <- map_df(raw_path, read_excel)
all_raw <- map_df(raw_path[1:5,], read_excel)
raw_path
all_raw <- map_df(raw_path[1:5], read_excel)
View(all_raw)
str(all_raw)
object.size(all_raw)
knitr::opts_chunk$set(echo = F, message = F, warning = F)
path <- "../sample.xlsx"
raw_data <- read_excel("../sample.xlsx")
raw_data <- read_excel("./sample.xlsx")
raw_data <- read_excel("./data/sample.xlsx")
raw_data <- read_excel("../data/sample.xlsx")
raw_data <- read_excel("..data/sample.xlsx")
raw_data <- read_excel("./data/sample.xlsx")
raw_data <- read_excel("~/data/sample.xlsx")
raw_data <- read_excel("~/data/Mediatoolkit/sample.xlsx")
raw_data <- read_excel("./data/Mediatoolkit/sample.xlsx")
raw_data <- read_excel("../data/Mediatoolkit/sample.xlsx")
raw_data <- read_excel("../data/Mediatoolkit/sample.xlsx")
raw_data <- read_excel("./data/Mediatoolkit/sample.xlsx")
raw_data <- read_excel("/data/Mediatoolkit/sample.xlsx")
here(sample.xlsx)
library(here)
here(sample.xlsx)
here()
here("sample.xlsx")
getwd()
raw_data <- read_excel("D:/LUKA/Academic/HS/NASTAVA/21-22/LearningSocialMediaAnalytics/Learning-Social-Media-Analytics/data/Mediatoolkit/sample.xlsx")
raw_data <- read_excel(here::here("sample.xlsx"))
raw_data <- read_excel(here::here("data/sample.xlsx"))
here("sample.xlsx")
here("Mediatoolkit/sample.xlsx")
here("data/Mediatoolkit/sample.xlsx")
raw_data <- read_excel(here::here("data/Mediatoolkit/sample.xlsx"))
library(here)
str(raw)
raw_data <- read_excel(here::here("data/Mediatoolkit/sample.xlsx"))
str(raw)
str(raw_data)
glimpse(raw_data)
dim(raw_data)
```{r, echo=T}
raw_data <- read_excel(here::here("data/Mediatoolkit/sample.xlsx"))
dim(raw_data)
glimpse(raw_data[1:7,])
raw_data[1:7,]
glimpse(raw_data[,1:7])
# most important variables
names(raw_data)
unique(raw_data$DATE)
# observations
nrow(one_day_sample)
# read into environment
one_day_sample <- read_excel(here::here("data/Mediatoolkit/sample.xlsx"))
# read into environment
one_day_sample <- read_excel(here::here("data/Mediatoolkit/sample.xlsx"))
# size of the data
dim(one_day_sample)
# sneek peak
glimpse(one_day_sample[,1:9])
# observations
nrow(one_day_sample)
# dates
unique(one_day_sample$SOURCE_TYPE)
# dates
unique(one_day_sample$LOCATIONS)
# dates
unique(one_day_sample$AUTHOR)
# dates
nrow(unique(one_day_sample$AUTHOR))
# dates
nrow(unique(one_day_sample$AUTHOR))
# dates
count(unique(one_day_sample$AUTHOR))
# dates
length(unique(one_day_sample$AUTHOR))
# unique authors
length(unique(one_day_sample$TITLE))
unique(one_day_sample$TITLE)
unique(one_day_sample$FROM)
# unique titles
length(unique(one_day_sample$FROM))
# unique sources
length(unique(one_day_sample$URL))
# unique sources
length(unique(one_day_sample$LANGUAGES))
unique(one_day_sample$LANGUAGES)
# unique urls
length(unique(one_day_sample$URL))
# sneek peak
glimpse(one_day_sample[sample(),1:8])
# sneek peak
glimpse(one_day_sample[sample(nrow(one_day_sample)),1:8])
# time
unique(one_day_sample$TIME)
# time
length(unique(one_day_sample$TIME))
one_day_sample %>%
group_by(SOURCE_TYPE) %>%
count()
one_day_sample %>%
group_by(SOURCE_TYPE) %>%
count() %>%
arrange(desc(n))
options(digits=2)
one_day_sample %>%
group_by(SOURCE_TYPE) %>%
count() %>%
arrange(desc(n))
options(big.mark = ",")
one_day_sample %>%
group_by(SOURCE_TYPE) %>%
count() %>%
arrange(desc(n))
one_day_sample %>%
group_by(SOURCE_TYPE) %>%
count() %>%
arrange(desc(n)) %>%
mutate_if(is.numeric, format, big.mark = ".")
one_day_sample %>%
group_by(SOURCE_TYPE) %>%
count() %>%
arrange(desc(n)) %>%
mutate_if(is.numeric, format, big.mark = ".") %>%
kbl()
library(kableExtra)
one_day_sample %>%
group_by(SOURCE_TYPE) %>%
count() %>%
arrange(desc(n)) %>%
mutate_if(is.numeric, format, big.mark = ".") %>%
kbl()
one_day_sample %>%
group_by(SOURCE_TYPE) %>%
count() %>%
arrange(desc(n)) %>%
mutate_if(is.numeric, format, big.mark = ".") %>%
kable_classic()
one_day_sample %>%
group_by(SOURCE_TYPE) %>%
count() %>%
arrange(desc(n))
# per network(/per day)
one_day_sample %>%
group_by(SOURCE_TYPE) %>%
count() %>%
arrange(desc(n)) %>%
mutate_if(is.numeric, format, big.mark = ".") %>%
kbl()
# per network(/per day)
one_day_sample %>%
group_by(SOURCE_TYPE) %>%
count() %>%
arrange(desc(n)) %>%
mutate_if(is.numeric, format, big.mark = ".") %>%
kbl() %>%
kable_styling(font_size = 7)
unique(one_day_sample$GROUP_NAME
)
one_day_sample %>%
select(MENTION_SNIPPET) %>%
unique() %>%
sample_n(5)
one_day_sample %>%
select(MENTION_SNIPPET) %>%
unique() %>% datatable(., rownames = FALSE, filter="top", options = list(pageLength = 5, scrollX=T) )
library(DT)
one_day_sample %>%
select(MENTION_SNIPPET) %>%
unique() %>% datatable(., rownames = FALSE, filter="top", options = list(pageLength = 5, scrollX=T) )
library(DT)
one_day_sample %>%
select(DATE, MENTION_SNIPPET) %>%
unique(.) %>%
sample_n(150) %>%
kbl() %>%
kable_styling(font_size = 11)
# SAMPLE SOME TITLES
one_day_sample %>%
select(SOURCE_TYPE, TITLE) %>%
unique(.) %>%
sample_n(9) %>%
kbl() %>%
kable_styling(font_size = 11)
knitr::opts_chunk$set(echo = F, message = F, warning = F)
library(tidyverse)
library(readxl)
library(here)
library(kableExtra)
library(DT)
path <- "D:/LUKA/Freelance/Mediatoolkit/FULLDATA"
raw <- list.files(path = path , pattern="xlsx")
raw_path <- paste0(path, "/", raw)
all_raw <- map_df(raw_path, read_excel)
all_raw <- all_raw  %>%  mutate(DATE = as.Date(DATE,"%Y-%m-%d" ))
# choose variables to investigate
all_raw %>%
filter(SOURCE_TYPE == "youtube") %>%
select(AUTHOR,
REACH,
LIKE_COUNT,
VIEW_COUNT,
COMMENTS_COUNT,
TITLE,
MENTION_SNIPPET,
URL,
DATE,
TIME) -> youtube
youtube %>%
group_by(AUTHOR) %>%
count() %>%
arrange(desc(n)) %>%
mutate_if(is.numeric, format, big.mark = ".") %>%
head(10) %>% kbl() %>% kable_styling(font_size = 11)
youtube %>%
group_by(AUTHOR) %>%
summarise(REACH = sum(REACH),
LIKE = sum(LIKE_COUNT),
VIEW = sum(VIEW_COUNT),
COMMENTS= sum(COMMENTS_COUNT)) %>%
arrange(desc(VIEW)) %>%
mutate_if(is.numeric, format, big.mark = ".") %>%
head(10) %>% kbl() %>% kable_styling(font_size = 11)
# choose variables to investigate
one_day_sample %>%
filter(SOURCE_TYPE == "forum") %>%
select(FROM,
TITLE,
MENTION_SNIPPET,
DATE,
TIME) -> forum
# choose variables to investigate
all_raw %>%
filter(SOURCE_TYPE == "forum") %>%
select(FROM,
TITLE,
MENTION_SNIPPET,
DATE,
TIME) -> forum
# choose variables to investigate
all_raw %>%
filter(SOURCE_TYPE == "forum") %>%
select(FROM,
TITLE,
MENTION_SNIPPET,
DATE,
TIME) -> forum
# not a very good coverage
forum %>%
group_by(FROM) %>%
count()
# not a very good coverage
forum %>%
group_by(FROM) %>%
count() %>%
arrange(desc(n))
# not a very good coverage
forum %>%
group_by(FROM) %>%
count() %>%
arrange(desc(n)) %>%
mutate_if(is.numeric, format, big.mark = ".")
# not a very good coverage
forum %>%
group_by(FROM) %>%
count() %>%
arrange(desc(n)) %>%
mutate_if(is.numeric, format, big.mark = ".") %>%
head(12) %>% kbl() %>% kable_styling(font_size = 11)
# not a very good coverage
forum %>%
group_by(FROM) %>%
count() %>%
arrange(desc(n)) %>%
mutate_if(is.numeric, format, big.mark = ".") %>%
head(8) %>% kbl() %>% kable_styling(font_size = 11)
# choose variables to investigate
all_raw %>%
filter(SOURCE_TYPE == "instagram") %>%
select(FROM,
TITLE,
AUTHOR,
MENTION_SNIPPET,
REACH,
LIKE_COUNT,
COMMENT_COUNT,
SHARE_COUNT,
VIEW_COUNT,
DATE,
TIME) -> instagram
# not a very good coverage
instagram %>%
group_by(FROM) %>%
summarise(REACH = sum(REACH),
COMMENT = sum(COMMENT_COUNT),
LIKE = sum(LIKE_COUNT),
VIEW = sum(VIEW_COUNT))%>%
mutate_if(is.numeric, format, big.mark = ".") %>%
arrange(desc(LIKE)) %>%
head(12) %>% kbl() %>% kable_styling(font_size = 11)
# not a very good coverage
instagram %>%
group_by(FROM) %>%
count() %>%
arrange(desc(n)) %>%
head(12) %>% kbl() %>% kable_styling(font_size = 11)
# not a very good coverage
instagram %>%
group_by(FROM) %>%
count() %>%
arrange(desc(n)) %>%
mutate_if(is.numeric, format, big.mark = ".") %>%
head(12) %>% kbl() %>% kable_styling(font_size = 11)
