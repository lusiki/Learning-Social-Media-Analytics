slice(1:3000) %>%
group_by(V1) %>%
summarise(LIKE = sum(LIKE_COUNT),across(c(TITLE, AUTHOR, FROM, URL))) %>%
ungroup() %>%
select(-V1, TITLE, AUTHOR, FROM, URL, LIKE) %>%
datatable(., options = list(scrollX = TRUE, scrollY = "500px"))
# Articles by comments
dta  %>%
filter(SOURCE_TYPE == "web") %>%
ungroup %>%
arrange(desc(COMMENT_COUNT)) %>%
slice(1:3000) %>%
group_by(V1) %>%
summarise(COMMENT = sum(COMMENT_COUNT),across(c(TITLE, AUTHOR, FROM, URL))) %>%
ungroup() %>%
select(-V1, TITLE, AUTHOR, FROM, URL, COMMENT) %>%
datatable(., options = list(scrollX = TRUE, scrollY = "500px"))
# Arcicles by shares
dta  %>%
filter(SOURCE_TYPE == "web") %>%
ungroup %>%
arrange(desc(SHARE_COUNT)) %>%
slice(1:3000) %>%
group_by(V1) %>%
summarise(SHARE = sum(SHARE_COUNT),across(c(TITLE, AUTHOR, FROM, URL))) %>%
ungroup() %>%
select(-V1, TITLE, AUTHOR, FROM, URL, SHARE) %>%
datatable(., options = list(scrollX = TRUE, scrollY = "500px"))
# read in lexicons
CroSentilex_n <- read.delim("C:/Users/Lukas/Dropbox/Mislav@Luka/crosentilex-negatives.txt",
header = FALSE,
sep = " ",
stringsAsFactors = FALSE,
fileEncoding = "UTF-8")  %>%
rename(word = "V1", sentiment = "V2" ) %>%
mutate(brija = "NEG")
CroSentilex_p  <- read.delim("C:/Users/Lukas/Dropbox/Mislav@Luka/crosentilex-positives.txt",
header = FALSE,
sep = " ",
stringsAsFactors = FALSE,
fileEncoding = "UTF-8") %>%
rename(word = "V1", sentiment = "V2" ) %>%
mutate(brija = "POZ")
Crosentilex_sve <- rbind(setDT(CroSentilex_n), setDT(CroSentilex_p))
# check lexicon data
#head(sample_n(Crosentilex_sve,1000),15)
CroSentilex_Gold  <- read.delim2("C:/Users/Lukas/Dropbox/Mislav@Luka/gs-sentiment-annotations.txt",
header = FALSE,
sep = " ",
stringsAsFactors = FALSE) %>%
rename(word = "V1", sentiment = "V2" )
Encoding(CroSentilex_Gold$word) <- "UTF-8"
CroSentilex_Gold[1,1] <- "dati"
CroSentilex_Gold$sentiment <- str_replace(CroSentilex_Gold$sentiment , "-", "1")
CroSentilex_Gold$sentiment <- str_replace(CroSentilex_Gold$sentiment , "\\+", "2")
CroSentilex_Gold$sentiment <- as.numeric(unlist(CroSentilex_Gold$sentiment))
# check lexicon data
#head(sample_n(CroSentilex_Gold,100),15)
# create stop words
stopwords_cro <- get_stopwords(language = "hr", source = "stopwords-iso")
# check stopwords data
#head(sample_n(stopwords_cro,100),15)
# extend stop words
my_stop_words <- tibble(
word = c(
"jedan","mjera", "može", "možete", "mogu", "kad", "sada", "treba", "ima", "osoba",
"e","prvi", "dva","dvije","drugi",
"tri","treći","pet","kod",
"ove","ova",  "ovo","bez", "kod",
"evo","oko",  "om", "ek",
"mil","tko","šest", "sedam",
"osam",   "čim", "zbog",
"prema", "dok","zato", "koji",
"im", "čak","među", "tek",
"koliko", "tko","kod","poput",
"baš", "dakle", "osim", "svih",
"svoju", "odnosno", "gdje",
"kojoj", "ovi", "toga",
"ubera", "vozača", "hrvatskoj", "usluge", "godine", "više", "taksi", "taxi", "taksija", "taksija", "kaže", "rekao", "19"," aee", "ae","bit.ly", "https", "one", "the"
),
lexicon = "lux"
)
stop_corpus <- my_stop_words %>%
bind_rows(stopwords_cro)
# check stopwords data
#head(sample_n(stop_corpus,100),15)
# dim before tokenize
dim(dta)
# tokenize
dta %>%
unnest_tokens(word, FULL_TEXT) -> fb_token
# dim after tokenize
dim(fb_token)
# check
# fb_token %>%
#   select(FROM, word, MENTION_SNIPPET ) %>%
#     sample_n(.,100)
# remove stop words, numbers, single letters
fb_token %>%
anti_join(stop_corpus, by = "word") %>%
mutate(word = gsub("\\d+", NA, word)) %>%
mutate(word = gsub("^[a-zA-Z]$", NA, word)) -> fb_tokenTidy
# remove NA
fb_tokenTidy %>%
filter(!is.na(word)) -> fb_tokenTidy
# check
# fb_tokenTidy  %>%
#   select(FROM, word, MENTION_SNIPPET ) %>%
#   sample_n(.,100)
# dim after clean
dim(fb_tokenTidy)
# dim before tokenize
dim(dta)
# tokenize
dta %>%
filter(SOURCE_TYPE == "web") %>%
unnest_tokens(word, FULL_TEXT) -> fb_token
# dim after tokenize
dim(fb_token)
# check
# fb_token %>%
#   select(FROM, word, MENTION_SNIPPET ) %>%
#     sample_n(.,100)
# remove stop words, numbers, single letters
fb_token %>%
anti_join(stop_corpus, by = "word") %>%
mutate(word = gsub("\\d+", NA, word)) %>%
mutate(word = gsub("^[a-zA-Z]$", NA, word)) -> fb_tokenTidy
# remove NA
fb_tokenTidy %>%
filter(!is.na(word)) -> fb_tokenTidy
# check
# fb_tokenTidy  %>%
#   select(FROM, word, MENTION_SNIPPET ) %>%
#   sample_n(.,100)
# dim after clean
dim(fb_tokenTidy)
## Most common words
fb_tokenTidy[,.N,by = word][order(-N),]
## Vizualize most common words
fb_tokenTidy[,.N,by = word][N>10000][order(-N),][,word := reorder(word,N)] %>%
ggplot(aes(word, N)) +
geom_col() +
xlab(NULL) +
coord_flip() +
theme_economist()
## Vizualize most common words over time
fb_tokenTidy[,DAY:=floor_date(DATE,"day")][,N:=.N,by=DAY][,gn:=sum(N)][
word %in% c("ukrajini", "pomoć", "humanitarnu", "udruga", "prava"),] %>%
ggplot(., aes(DAY,  N / gn)) +
geom_point() +
ggtitle("Učestalost korištenja riječi") +
ylab("% ukupnih riječi") +
geom_smooth() +
facet_wrap(~ word, scales = "free_y") +
scale_y_continuous(labels = scales::percent_format())+
theme_economist()
## Most common words
fb_tokenTidy[,.N,by = word][order(-N),] %>%
datatable(., options = list(scrollX = TRUE, scrollY = "500px"))
## Vizualize most common words
fb_tokenTidy[,.N,by = word][N>10000][order(-N),][,word := reorder(word,N)] %>%
ggplot(aes(word, N)) +
geom_col() +
xlab(NULL) +
coord_flip() +
theme_economist()
## Vizualize most common words
fb_tokenTidy[,.N,by = word][N>10000][order(-N),][,word := reorder(word,N)] %>%
ggplot(aes(word, N)) +
geom_col() +
xlab(NULL) +
coord_flip() +
theme_economist()
## Vizualize most common words over time
fb_tokenTidy[,DAY:=floor_date(DATE,"day")][,N:=.N,by=DAY][,gn:=sum(N)][
word %in% c("ukrajini", "pomoć", "humanitarnu", "udruga", "prava"),] %>%
ggplot(., aes(DAY,  N / gn)) +
geom_point() +
ggtitle("Učestalost korištenja riječi") +
ylab("% ukupnih riječi") +
geom_smooth() +
facet_wrap(~ word, scales = "free_y") +
scale_y_continuous(labels = scales::percent_format())+
theme_economist()
fb_bigram <- fb_TopLike %>%
unnest_tokens(bigram, FULL_TEXT, token = "ngrams", n = 2)
# Select postes with +5k likes
dta[order(-LIKE_COUNT)][LIKE_COUNT >= 500] -> fb_TopLike
# check
dim(fb_TopLike)
# influencer activity
fb_TopLike[,.N,FROM][order(-N)]
# influencer by like
fb_TopLike[,.(FROM, LIKE_COUNT)][,LIKES := sum(LIKE_COUNT),FROM][,.(FROM,LIKES)][order(-LIKES)] %>% unique()
# tokenize
fb_TopLike %>%
unnest_tokens(word, FULL_TEXT) -> fb_token_TopLike
# dim after tokenize
dim(fb_token_TopLike)
# remove stop words, numbers, single letters
fb_token_TopLike %>%
anti_join(stop_corpus, by = "word") %>%
mutate(word = gsub("\\d+", NA, word)) %>%
mutate(word = gsub("^[a-zA-Z]$", NA, word)) -> fb_tokenTidy_TopLike
# remove NA
fb_tokenTidy_TopLike %>%
filter(!is.na(word)) -> fb_tokenTidy_TopLike
## most common words
fb_tokenTidy_TopLike[,.N,by = word][order(-N),]
## word cloud
fb_tokenTidy_TopLike %>%
anti_join(CroSentilex_Gold,by="word") %>%
count(word) %>%
arrange(desc(n)) %>%
top_n(100) %>%
with(wordcloud(word, n, max.words = 120))
## Udio riječi po domenama
domenaWords <- fb_tokenTidy_TopLike %>%
filter(FROM %in% c("24sata", "jutarnji.hr", "slobodnadalmacija.hr", "Index.hr" )) %>%
count(FROM, word, sort = T)
ukupnoWords <- domenaWords %>%
group_by(FROM) %>%
summarise(totWords = sum(n))
domenaWords <- left_join(domenaWords, ukupnoWords)
# domenaWords %>% head(15)
# domenaWords %>%
# ggplot(., aes(n/totWords, fill = domena)) +
#   geom_histogram(show.legend = FALSE) +
#   xlim(NA, 0.0009) +
#   facet_wrap(~domena, ncol = 2, scales = "free_y")
## Najbitnije riječi po domenma
idf <- domenaWords %>%
bind_tf_idf(word, FROM, n)
#idf %>% head(10)
# idf %>%
#   select(-totWords) %>%
#   arrange(desc(tf_idf))
idf %>%
arrange(desc(tf_idf)) %>%
mutate(word = factor(word, levels = rev(unique(word)))) %>%
mutate(FROM = factor(FROM)) %>%
group_by(FROM) %>%
top_n(11) %>%
ungroup() %>%
ggplot(aes(word, tf_idf, fill = FROM)) +
geom_col(show.legend = FALSE) +
labs(x = NULL, y = "tf-idf") +
facet_wrap(~FROM, ncol = 2, scales = "free") +
coord_flip() +
theme_economist()
fb_bigram <- fb_TopLike %>%
unnest_tokens(bigram, FULL_TEXT, token = "ngrams", n = 2)
#fb_bigram %>% head(10)
# fb_bigram %>%
#   count(bigram, sort = T) %>%
#   head(25)
fb_bigram_sep <- fb_bigram %>%
separate(bigram, c("word1","word2"), sep = " ")
fb_bigram_tidy <- fb_bigram_sep %>%
filter(!word1 %in% stop_corpus$word) %>%
filter(!word2 %in% stop_corpus$word) %>%
mutate(word1 = gsub("\\d+", NA, word1)) %>%
mutate(word2 = gsub("\\d+", NA, word2)) %>%
mutate(word1 = gsub("^[a-zA-Z]$", NA, word1)) %>%
mutate(word2 = gsub("^[a-zA-Z]$", NA, word2))
fb_bigram_tidy_bigram_counts <- fb_bigram_tidy %>%
count(word1, word2, sort = TRUE)
bigrams_united <- fb_bigram_tidy %>%
unite(bigram, word1, word2, sep = " ") %>%
filter(., !grepl("NA",bigram))
#bigrams_united
bigrams_united %>%
count(FROM,bigram,sort = T) -> topicBigram
bigrams_united %>%
count(bigram, sort = T) %>%
head(45)
# Najvažniji bigrami po domenama
bigram_tf_idf <- bigrams_united %>%
#  filter (!is.na(bigram)) %>%
count(FROM, bigram) %>%
bind_tf_idf(bigram, FROM, n) %>%
arrange(desc(tf_idf))
bigram_tf_idf %>%
filter(FROM %in% c("24sata", "jutarnji.hr", "slobodnadalmacija.hr", "Index.hr")) %>%
arrange(desc(tf_idf)) %>%
mutate(bigram = factor(bigram, levels = rev(unique(bigram)))) %>%
group_by(FROM) %>%
top_n(20) %>%
ungroup() %>%
ggplot(aes(bigram, tf_idf, fill = FROM)) +
geom_col(show.legend = FALSE) +
labs(x = NULL, y = "tf-idf") +
facet_wrap(~FROM, ncol = 2, scales = "free") +
coord_flip() +
theme_economist()
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
library(xlsx)
library(here)
library(kableExtra)
library(DT)
library(purrr)
library(data.table)
library(tidytext)
library(dplyr)
library(lubridate)
library(anytime)
library(grid)
library(wordcloud)
library(reshape2)
library(ggraph)
library(widyr)
library(topicmodels)
library(ggthemes)
library(xlsx)
# Read In
original <- read.xlsx("D:/LUKA/Freelance/Mediatoolkit/native1.xlsx", sheetIndex = 1) %>% mutate(V1 = as.numeric(V1))
variables <- read.xlsx("C:/Users/Lukas/OneDrive/Desktop/Native.xlsx", sheetIndex = 1)
variables <- variables[,-c(23,24,25)]# %>% drop_na()
original <- original %>% filter(V1 %in% variables$V1)
dta <- merge(original, variables, by = "V1", all.x = TRUE)
dta$DATE <- as.Date(dta$DATE)
View(dta)
View(variables)
names(dta)
View(dta)
dta <- merge(original, variables, by = "V1", all.x = TRUE)
dta$DATE <- as.Date(dta$DATE)
sentiment <- data.frame(
number = c(1, 2, 3),
text = c("Pozitivan", "Neutralan", "Negativan")
)
ggplot(data = dta, aes(x = SENTIMENT)) +
geom_histogram(binwidth = 0.5, fill = "blue", alpha = 0.7) +
ggtitle("Sentiment") +
xlab("Sentiment") +
ylab("Frequency")+
scale_x_continuous(breaks = seq(from = min(dta$SENTIMENT), to =  max(dta$SENTIMENT), by = 1))
ggplot(data = dta, aes(x = SENTIMENT)) +
geom_histogram(binwidth = 0.5, fill = "blue", alpha = 0.7) +
ggtitle("Sentiment") +
xlab("Sentiment") +
ylab("Frequency")
ggplot(data = dta, aes(x = SENTIMENT)) +
geom_histogram(binwidth = 0.5, fill = "blue", alpha = 0.7) +
ggtitle("Sentiment") +
xlab("Sentiment") +
ylab("Frequency")+
scale_x_continuous(breaks = seq(from = min(dta$SENTIMENT), to =  max(dta$SENTIMENT), by = 1))
dta$SENTIMENT
min(dta$SENTIMENT)
sentiment <- data.frame(
number = c(1, 2, 3),
text = c("Pozitivan", "Neutralan", "Negativan")
)
ggplot(data = dta, aes(x = SENTIMENT)) +
geom_histogram(binwidth = 0.5, fill = "blue", alpha = 0.7) +
ggtitle("Sentiment") +
xlab("Sentiment") +
ylab("Frequency") #+
#scale_x_continuous(breaks = seq(from = min(dta$SENTIMENT), to =  max(dta$SENTIMENT), by = 1))
industry_list <- data.frame(
id = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28),
category = c(
"Financijska industrija",
"Građevinska industrija",
"Moda i ljepota",
"Politička institucija",
"Sportska industrija",
"Zdravlje",
"Obrazovanje i znanost",
"Tehnologija",
"Auto-moto industrija",
"ICT",
"Kultura i umjetnost",
"Turizam, odmor, putovanja, ugostiteljstvo",
"Energetska industrija",
"Prehrambena industrija",
"Industrija bezalkoholnih pića",
"Alkoholna pića",
"Nekretninska industrija",
"Maloprodajna trgovina",
"Igre na sreću",
"Medijske kuće i marketinške, digitalne agencije",
"Namještaj, saloni namještaja, kućanske potrepštine, kućanski uređaji, sredstva za čišćenje",
"Trgovački / shopping centri",
"Glazbena industrija",
"Filmska industrija",
"Brodogradnja",
"Pošta / distribucija pošiljki",
"Komunalne usluge"
)
)
# Create a histogram of the 'price' variable in the 'diamonds' dataset
ggplot(data = dta, aes(x = INDUSTRIJA)) +
geom_histogram(binwidth = 1, fill = "blue", alpha = 0.7) +
ggtitle("Industrija") +
xlab("Industrija") +
ylab("Frequency") +
scale_x_continuous(breaks = seq(from = min(dta$INDUSTRIJA), to =  max(dta$INDUSTRIJA), by = 1))
# Create a histogram of the 'price' variable in the 'diamonds' dataset
ggplot(data = dta, aes(x = INDUSTRIJA)) +
geom_histogram(binwidth = 1, fill = "blue", alpha = 0.7) +
ggtitle("Industrija") +
xlab("Industrija") +
ylab("Frequency") +
scale_x_continuous(breaks = seq(from = min(dta$INDUSTRIJA), to =  max(dta$INDUSTRIJA), by = 1))
# Create a histogram of the 'price' variable in the 'diamonds' dataset
ggplot(data = dta, aes(x = INDUSTRIJA)) +
geom_histogram(binwidth = 1, fill = "blue", alpha = 0.7) +
ggtitle("Industrija") +
xlab("Industrija") +
ylab("Frequency") +
scale_x_continuous(breaks = seq(from = min(dta$INDUSTRIJA), to =  max(dta$INDUSTRIJA), by = 1)) %>%
coord_flip()
# Create a histogram of the 'price' variable in the 'diamonds' dataset
ggplot(data = dta, aes(x = INDUSTRIJA)) +
geom_histogram(binwidth = 1, fill = "blue", alpha = 0.7) +
ggtitle("Industrija") +
xlab("Industrija") +
ylab("Frequency") +
scale_x_continuous(breaks = seq(from = min(dta$INDUSTRIJA), to =  max(dta$INDUSTRIJA), by = 1)) +
coord_flip()
industry_list %>%
datatable(., options = list(scrollX = TRUE, scrollY = "500px"))
dta %>%
group_by(INDUSTRIJA) %>%
summarise(BrojObjava = n()) %>%
arrange(desc(BrojObjava)) %>%
left_join(industry_list, by = c("industry_list" = "number")) %>%
datatable(., options = list(scrollX = TRUE, scrollY = "500px"))
dta %>%
group_by(INDUSTRIJA) %>%
summarise(BrojObjava = n()) %>%
arrange(desc(BrojObjava))
dta %>%
group_by(INDUSTRIJA) %>%
summarise(BrojObjava = n()) %>%
arrange(desc(BrojObjava)) %>%
left_join(industry_list, by = c("INDUSTRIJA" = "id")) %>%
datatable(., options = list(scrollX = TRUE, scrollY = "500px"))
dta %>%
group_by(INDUSTRIJA,SENTIMENT) %>%
summarise(BrojObjava = n()) %>%
arrange(desc(BrojObjava)) %>%
left_join(industry_list, by = c("INDUSTRIJA" = "id")) %>%
datatable(., options = list(scrollX = TRUE, scrollY = "500px"))
dta %>%
group_by(INDUSTRIJA,SENTIMENT) %>%
summarise(BrojObjava = n()) %>%
#  arrange(desc(BrojObjava)) %>%
left_join(industry_list, by = c("INDUSTRIJA" = "id")) %>%
datatable(., options = list(scrollX = TRUE, scrollY = "500px"))
dta %>%
group_by(INDUSTRIJA,SENTIMENT) %>%
summarise(BrojObjava = n())
dta %>%
group_by(INDUSTRIJA,SENTIMENT) %>%
summarise(BrojObjava = n()) %>%
#  arrange(desc(BrojObjava)) %>%
left_join(industry_list, by = c("INDUSTRIJA" = "id"))
dta %>%
group_by(INDUSTRIJA,SENTIMENT) %>%
summarise(BrojObjava = n()) %>%
#  arrange(desc(BrojObjava)) %>%
left_join(industry_list, by = c("INDUSTRIJA" = "id")) %>%
datatable(., options = list(scrollX = TRUE, scrollY = "500px"))
dta %>%
group_by(INDUSTRIJA,SENTIMENT) %>%
summarise(BrojObjava = n())
sentind <- dta %>%
group_by(INDUSTRIJA,SENTIMENT) %>%
summarise(BrojObjava = n()) %>%
#  arrange(desc(BrojObjava)) %>%
left_join(industry_list, by = c("INDUSTRIJA" = "id"))
sentind
ggplot(sentind, aes(x = BrojObjava)) +
geom_bar(stat = "identity") +
facet_wrap(category ~ SENTIMENT, scales = "free", ncol = 3) +
labs(title = "",
x = "Broj Objava",
y = "Count") +
theme_minimal()
ggplot(sentind, aes(x = BrojObjava)) +
geom_bar(stat = "identity") +
facet_wrap(INDUSTRIJA ~ SENTIMENT, scales = "free", ncol = 3) +
labs(title = "",
x = "Broj Objava",
y = "Count") +
theme_minimal()
sentind <- dta %>%
group_by(INDUSTRIJA,SENTIMENT) %>%
summarise(BrojObjava = n()) %>%
#  arrange(desc(BrojObjava)) %>%
left_join(industry_list, by = c("INDUSTRIJA" = "id"))
sentind
ggplot(sentind, aes(x = BrojObjava)) +
geom_histogram(stat = "identity") +
facet_wrap(INDUSTRIJA ~ SENTIMENT, scales = "free", ncol = 3) +
labs(title = "",
x = "Broj Objava",
y = "Count") +
theme_minimal()
ggplot(sentind, aes(x = BrojObjava)) +
geom_histogram(stat = "identity") +
facet_wrap(INDUSTRIJA ~ SENTIMENT, scales = "free", ncol = 3) +
labs(title = "",
x = "Broj Objava",
y = "Count")
sentind
