#            str_detect(AUTHOR,fixed("native",ignore_case = TRUE))|
#            str_detect(AUTHOR,fixed("tnative",ignore_case = TRUE))|
#            str_detect(FULL_TEXT,fixed("tnative",ignore_case = TRUE))|
#            str_detect(AUTHOR,fixed("tnative",ignore_case = TRUE)))
dta <- dt[SOURCE_TYPE == "web" &
(str_detect(FULL_TEXT, fixed("sadržaj nastao",ignore_case = TRUE)) |
str_detect(AUTHOR, fixed("sponzor",ignore_case = TRUE)) |
str_detect(AUTHOR, fixed("native",ignore_case = TRUE)) |
str_detect(AUTHOR, fixed("tnative",ignore_case = TRUE)) |
str_detect(FULL_TEXT, fixed("tnative",ignore_case = TRUE)) |
str_detect(FULL_TEXT, fixed("sadržaj donosi", ignore_case = TRUE)) |
str_detect(FULL_TEXT, fixed("sponzorirani sadržaj", ignore_case = TRUE)) |
str_detect(AUTHOR, fixed("tnative",ignore_case = TRUE)))]
variables <- variables[,-c(23,24,25)]# %>% drop_na()
original <- original %>% filter(V1 %in% variables$V1)
dta <- merge(original, variables, by = "V1", all.x = TRUE)
dta$DATE <- as.Date(dta$DATE)
# articles over time
daily_counts <- dta %>%
group_by(DATE) %>%
summarise(count = n())
# descriptives
summ <- daily_counts %>%
summarize(min = min(count), max = max(count),
mean = mean(count), q1= quantile(count, probs = 0.25),
median = median(count), q3= quantile(count, probs = 0.75),
sd = sd(count)) %>%
mutate_if(is.numeric, round, digits=2)
summ
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
library(xlsx)
library(here)
library(kableExtra)
library(DT)
library(purrr)
library(data.table)
library(tidytext)
library(dplyr)
library(lubridate)
library(anytime)
library(grid)
library(wordcloud)
library(reshape2)
library(ggraph)
library(widyr)
library(topicmodels)
library(ggthemes)
library(xlsx)
dt <- fread("D:/LUKA/Freelance/Mediatoolkit/catholiq.xlsx")
View(dt)
dt <- read.xlsx("D:/LUKA/Freelance/Mediatoolkit/catholiq.xlsx")
dt <- read.xlsx("D:/LUKA/Freelance/Mediatoolkit/catholiq.xlsx", sheetIndex = 1)
dt <- read.xlsx2("D:/LUKA/Freelance/Mediatoolkit/catholiq.xlsx", sheetIndex = 1)
dt <- read.xlsx("D:/LUKA/Freelance/Mediatoolkit/catholiq.xlsx", sheetIndex = 1)
dt <- read_excel("D:/LUKA/Freelance/Mediatoolkit/catholiq.xlsx")
View(dt)
dt <- read_excel("D:/LUKA/Freelance/Mediatoolkit/catholiq.xlsx") %>% select(-match)
imena <- c("Stepinac","don Damir Stojić", "Željka Markić", "pater Ike Mandurić","Vlado Košić","Robert Bajruši", "Inoslav Bešker", "Ante Tomić", "Branimir Pofuk", "Igor Lasić", "Hrvoje Marjanović","Bozanić", "Ksenija Abramović", "Drago Pilsel")
# Define the batch size
batch_size <- 1000
# Split your data into batches
batches <- split(dt, ceiling(seq_along(dt[[1]])/batch_size))
# Split your data into batches
batches <- split(dt, ceiling(seq_along(dt[[1]])/batch_size))
# Function to process each batch
process_batch <- function(batch) {
batch %>%
as_tibble() %>%
select(V1, DATE, TITLE, URL, FULL_TEXT) %>%
mutate(
full_text = tolower(FULL_TEXT),
match = str_c(imena, collapse = '|'),
key_word = str_extract_all(full_text, match)
) %>%
filter(lengths(key_word) > 0) %>%
unnest(key_word) %>%
distinct(V1, .keep_all = TRUE)
}
# Process each batch
results <- batches %>%
map(~ process_batch(.x))
df <- bind_rows(results)
pattern_imena
pattern_imena
imena
pattern_imena <- str_c("\\b(", str_c(imena, collapse = "|"), ")\\b")
pattern_imena
# Process each batch
results <- batches %>%
map(~ process_batch(.x))
df <- bind_rows(results)
imena <- c("Stepinac","Damir", "Stojić", "Željka" ,"Markić", "Ike", "Mandurić","Vlado", "Košić","Robert" ,"Bajruši", "Inoslav", "Bešker", "Ante" ,"Tomić", "Branimir" ,"Pofuk", "Igor", "Lasić", "Hrvoje", "Marjanović","Bozanić", "Ksenija" ,"Abramović", "Drago","Pilsel")
pattern_imena <- str_c("\\b(", str_c(imena, collapse = "|"), ")\\b")
# Split your data into batches
batches <- split(dt, ceiling(seq_along(dt[[1]])/batch_size))
# Function to process each batch
process_batch <- function(batch) {
batch %>%
as_tibble() %>%
select(V1, DATE, TITLE, URL, FULL_TEXT) %>%
mutate(
full_text = tolower(FULL_TEXT),
match = str_c(imena, collapse = '|'),
key_word = str_extract_all(full_text, match)
) %>%
filter(lengths(key_word) > 0) %>%
unnest(key_word) %>%
distinct(V1, .keep_all = TRUE)
}
# Process each batch
results <- batches %>%
map(~ process_batch(.x))
df <- bind_rows(results)
fraze <- c("pedofilija", "klečavci", "kaptolaši", "popovi lopovi", "zatucani katolici", "katolički fanatici", "katolički fašisti", "katolibani","crkvenjak", "ekstremni vjernici")
# Define the batch size
batch_size <- 1000
# Split your data into batches
batches <- split(dt, ceiling(seq_along(dt[[1]])/batch_size))
# Function to process each batch
process_batch <- function(batch) {
batch %>%
as_tibble() %>%
select(V1, DATE, TITLE, URL, FULL_TEXT) %>%
mutate(
full_text = tolower(FULL_TEXT),
match = str_c(fraze, collapse = '|'),
key_word = str_extract_all(full_text, match)
) %>%
filter(lengths(key_word) > 0) %>%
unnest(key_word) %>%
distinct(V1, .keep_all = TRUE)
}
# Process each batch
results <- batches %>%
map(~ process_batch(.x))
df <- bind_rows(results)
View(df)
filtered_df <- df %>%
filter(str_detect(full_text, pattern_imena))
filtered_df <- df %>%
filter(str_detect(full_text, pattern_fraze))
pattern_fraze <- str_c("\\b(", str_c(fraze, collapse = "|"), ")\\b")
filtered_df <- df %>%
filter(str_detect(full_text, pattern_fraze))
View(filtered_df)
imena <- c("Stepinac","Damir", "Stojić", "Željka" ,"Markić", "Ike", "Mandurić","Vlado", "Košić","Robert" ,"Bajruši", "Inoslav", "Bešker", "Ante" ,"Tomić", "Branimir" ,"Pofuk", "Igor", "Lasić", "Hrvoje", "Marjanović","Bozanić", "Ksenija" ,"Abramović", "Drago","Pilsel")
pattern_imena <- str_c("\\b(", str_c(imena, collapse = "|"), ")\\b")
# Define the batch size
batch_size <- 1000
batch %>%
as_tibble() %>%
select(V1, DATE, TITLE, URL, FULL_TEXT) %>%
mutate(
full_text = tolower(FULL_TEXT),
match = str_c(imena, collapse = '|'),
key_word = str_extract_all(full_text, match)
) %>%
filter(lengths(key_word) > 0) %>%
unnest(key_word) %>%
distinct(V1, .keep_all = TRUE)
# Split your data into batches
batches <- split(dt, ceiling(seq_along(dt[[1]])/batch_size))
# Function to process each batch
process_batch <- function(batch) {
batch %>%
as_tibble() %>%
select(V1, DATE, TITLE, URL, FULL_TEXT) %>%
mutate(
full_text = tolower(FULL_TEXT),
match = str_c(imena, collapse = '|'),
key_word = str_extract_all(full_text, match)
) %>%
filter(lengths(key_word) > 0) %>%
unnest(key_word) %>%
distinct(V1, .keep_all = TRUE)
}
# Process each batch
results <- batches %>%
map(~ process_batch(.x))
df <- bind_rows(results)
dta <- dt %>%
# filter(SOURCE_TYPE =="web")  %>%
filter(str_detect(FULL_TEXT,fixed("stojić",ignore_case = TRUE)))
View(dta)
dta <- dt %>%
# filter(SOURCE_TYPE =="web")  %>%
filter(str_detect(FULL_TEXT,fixed("stojić",ignore_case = TRUE)))
str_c(imena, collapse = '|')
imena <- c("Stepinac","Damir", "Stojić", "Željka" ,"Markić", "Ike", "Mandurić","Vlado", "Košić","Robert" ,"Bajruši", "Inoslav", "Bešker", "Ante" ,"Tomić", "Branimir" ,"Pofuk", "Igor", "Lasić", "Hrvoje", "Marjanović","Bozanić", "Ksenija" ,"Abramović", "Drago","Pilsel") %>% tolower()
imena
# Function to process each batch
process_batch <- function(batch) {
batch %>%
as_tibble() %>%
select(V1, DATE, TITLE, URL, FULL_TEXT) %>%
mutate(
full_text = tolower(FULL_TEXT),
match = str_c(imena, collapse = '|'),
key_word = str_extract_all(full_text, match)
) %>%
filter(lengths(key_word) > 0) %>%
unnest(key_word) %>%
distinct(V1, .keep_all = TRUE)
}
# Process each batch
results <- batches %>%
map(~ process_batch(.x))
df <- bind_rows(results)
View(df)
pattern_imena <- str_c("\\b(", str_c(imena, collapse = "|"), ")\\b")
filtered_df <- df %>%
filter(str_detect(full_text, pattern_imena))
View(filtered_df)
imena <- c("Stepinac","Stojić","Markić", "Ike", "Mandurić", "Košić" ,"Bajruši", "Bešker","Tomić","Pofuk",  "Lasić", "Marjanović","Bozanić", "Abramović", "Pilsel") %>% tolower()
pattern_imena <- str_c("\\b(", str_c(imena, collapse = "|"), ")\\b")
# Define the batch size
batch_size <- 1000
# Split your data into batches
batches <- split(dt, ceiling(seq_along(dt[[1]])/batch_size))
# Function to process each batch
process_batch <- function(batch) {
batch %>%
as_tibble() %>%
select(V1, DATE, TITLE, URL, FULL_TEXT) %>%
mutate(
full_text = tolower(FULL_TEXT),
match = str_c(imena, collapse = '|'),
key_word = str_extract_all(full_text, match)
) %>%
filter(lengths(key_word) > 0) %>%
unnest(key_word) %>%
distinct(V1, .keep_all = TRUE)
}
# Process each batch
results <- batches %>%
map(~ process_batch(.x))
df <- bind_rows(results)
filtered_df <- df %>%
filter(str_detect(full_text, pattern_imena))
View(filtered_df)
pravno <- c("vatikanski", "ugovori", "plaćanje", "blagoslova","sakramenata", "nekretnine", "imovina")
institucije  <- c("Ksaver", "HBK", "Opus Dei", "Udruga Protagora","Caritas")
pravno <- c("vatikanski", "ugovori", "plaćanje", "blagoslova","sakramenata", "nekretnine", "imovina")
pattern_pravno <- str_c("\\b(", str_c(pravno, collapse = "|"), ")\\b")
# Define the batch size
batch_size <- 1000
# Split your data into batches
batches <- split(dt, ceiling(seq_along(dt[[1]])/batch_size))
# Function to process each batch
process_batch <- function(batch) {
batch %>%
as_tibble() %>%
select(V1, DATE, TITLE, URL, FULL_TEXT) %>%
mutate(
full_text = tolower(FULL_TEXT),
match = str_c(pravno, collapse = '|'),
key_word = str_extract_all(full_text, match)
) %>%
filter(lengths(key_word) > 0) %>%
unnest(key_word) %>%
distinct(V1, .keep_all = TRUE)
}
# Process each batch
results <- batches %>%
map(~ process_batch(.x))
df <- bind_rows(results)
View(df)
filtered_df <- df %>%
filter(str_detect(full_text, pattern_pravno))
institucije  <- c("Ksaver", "HBK", "Opus Dei", "Udruga Protagora","Caritas") %>% tolower()
pattern_institucije <- str_c("\\b(", str_c(institucije, collapse = "|"), ")\\b")
# Define the batch size
batch_size <- 1000
# Split your data into batches
batches <- split(dt, ceiling(seq_along(dt[[1]])/batch_size))
# Function to process each batch
process_batch <- function(batch) {
batch %>%
as_tibble() %>%
select(V1, DATE, TITLE, URL, FULL_TEXT) %>%
mutate(
full_text = tolower(FULL_TEXT),
match = str_c(institucije, collapse = '|'),
key_word = str_extract_all(full_text, match)
) %>%
filter(lengths(key_word) > 0) %>%
unnest(key_word) %>%
distinct(V1, .keep_all = TRUE)
}
# Process each batch
results <- batches %>%
map(~ process_batch(.x))
df <- bind_rows(results)
filtered_df <- df %>%
filter(str_detect(full_text, pattern_institucije))
politika <- C("Hod","život", "obitelji", "prolife", "poništenje", "ugovora", "sekularizacija", "sekularna","država", "klerikalizam", "ruši","vlast", "veličaju" ,"ustaštvo", "oduzimaju", "prava", "ženama", "katoličku","državu", "afera", "zataškavanje", "Kaptol", "šutnja", , "Rimski","vjeronauk" ,"škola", "vatikanski", "ugovori", "vatikanska", "banka" ,"klerikalna", "vlast","država","odvojena", "potiče", "homofobiju", "rodna", "ideologija", "klerikalizam", "ravnozemljaši", "gay", "brak", "podržavali", "ustaše", "podržavali", "naciste", "blagoslovili", "rat", "Hrvatska", "nije", "sekularna","katolička", "crkva", "vlada","Hrvatskom","žene") %>% tolower()
politika <- C("Hod","život", "obitelji", "prolife", "poništenje", "ugovora", "sekularizacija", "sekularna","država", "klerikalizam", "ruši","vlast", "veličaju" ,"ustaštvo", "oduzimaju", "prava", "ženama", "katoličku","državu", "afera", "zataškavanje", "Kaptol", "šutnja", "Rimski","vjeronauk" ,"škola", "vatikanski", "ugovori", "vatikanska", "banka" ,"klerikalna", "vlast","država","odvojena", "potiče", "homofobiju", "rodna", "ideologija", "klerikalizam", "ravnozemljaši", "gay", "brak", "podržavali", "ustaše", "podržavali", "naciste", "blagoslovili", "rat", "Hrvatska", "nije", "sekularna","katolička", "crkva", "vlada","Hrvatskom","žene") %>% tolower()
politika <- c("Hod","život", "obitelji", "prolife", "poništenje", "ugovora", "sekularizacija", "sekularna","država", "klerikalizam", "ruši","vlast", "veličaju" ,"ustaštvo", "oduzimaju", "prava", "ženama", "katoličku","državu", "afera", "zataškavanje", "Kaptol", "šutnja", "Rimski","vjeronauk" ,"škola", "vatikanski", "ugovori", "vatikanska", "banka" ,"klerikalna", "vlast","država","odvojena", "potiče", "homofobiju", "rodna", "ideologija", "klerikalizam", "ravnozemljaši", "gay", "brak", "podržavali", "ustaše", "podržavali", "naciste", "blagoslovili", "rat", "Hrvatska", "nije", "sekularna","katolička", "crkva", "vlada","Hrvatskom","žene") %>% tolower()
politika
pattern_politika <- str_c("\\b(", str_c(politika, collapse = "|"), ")\\b")
# Split your data into batches
batches <- split(dt, ceiling(seq_along(dt[[1]])/batch_size))
# Function to process each batch
process_batch <- function(batch) {
batch %>%
as_tibble() %>%
select(V1, DATE, TITLE, URL, FULL_TEXT) %>%
mutate(
full_text = tolower(FULL_TEXT),
match = str_c(politika, collapse = '|'),
key_word = str_extract_all(full_text, match)
) %>%
filter(lengths(key_word) > 0) %>%
unnest(key_word) %>%
distinct(V1, .keep_all = TRUE)
}
# Process each batch
results <- batches %>%
map(~ process_batch(.x))
df <- bind_rows(results)
filtered_df <- df %>%
filter(str_detect(full_text, pattern_politika))
politika <- c("Hod","život", "obitelji", "prolife", "poništenje", "ugovora", "sekularizacija", "sekularna","država", "klerikalizam", "ruši","vlast", "veličaju" ,"ustaštvo", "oduzimaju", "prava", "ženama", "katoličku","državu", "afera", "zataškavanje", "Kaptol", "šutnja", "Rimski","vjeronauk" ,"škola", "vatikanski", "ugovori", "vatikanska", "banka" ,"klerikalna", "vlast","država","odvojena", "potiče", "homofobiju", "rodna", "ideologija", "klerikalizam", "ravnozemljaši", "gay", "brak", "podržavali", "ustaše", "podržavali", "naciste", "blagoslovili", "rat", "Hrvatska", "sekularna","katolička", "crkva", "vlada","Hrvatskom","žene") %>% tolower()
pattern_politika <- str_c("\\b(", str_c(politika, collapse = "|"), ")\\b")
# Define the batch size
batch_size <- 1000
# Split your data into batches
batches <- split(dt, ceiling(seq_along(dt[[1]])/batch_size))
# Function to process each batch
process_batch <- function(batch) {
batch %>%
as_tibble() %>%
select(V1, DATE, TITLE, URL, FULL_TEXT) %>%
mutate(
full_text = tolower(FULL_TEXT),
match = str_c(politika, collapse = '|'),
key_word = str_extract_all(full_text, match)
) %>%
filter(lengths(key_word) > 0) %>%
unnest(key_word) %>%
distinct(V1, .keep_all = TRUE)
}
# Process each batch
results <- batches %>%
map(~ process_batch(.x))
df <- bind_rows(results)
filtered_df <- df %>%
filter(str_detect(full_text, pattern_politika))
pomocno <- c( "smijenjen","konzervativci", "tradicionalisti", "pobačaj", "abortus", "aktivisti", "aktivizam", "jezuiti", "nazadan", "zaostao", "neobrazovan", "privilegije" , "privilegiran", "diskriminacija", "nacionalizam", "nacionalisti", "ekstremisti", "otpušten", "prekrštavanje", "izopćen", "izbačen", "bludničio",  "posvećenje",  , "inkardiniran", "inkardinacija",  "mračno doba", "razotkrio", "prijavio", "bludničio", "pronevjerio", "homofobijam", "zlodjela", "progoni", "dogma", "kontroverzni" , "moderni", "svećenik", "tolerantna", "vjera", "vjerska", "policija", "vjerska", "kontrola", "crkveni", "mediji", "vjerski" ,"mediji", "ukidanje", "homofob", "pedofil", "homoseksualnost", "patrijarhat", "čudesno" , "ozdravljenje", "čudo")
pomocno <- c( "smijenjen","konzervativci", "tradicionalisti", "pobačaj", "abortus", "aktivisti", "aktivizam", "jezuiti", "nazadan", "zaostao", "neobrazovan", "privilegije" , "privilegiran", "diskriminacija", "nacionalizam", "nacionalisti", "ekstremisti", "otpušten", "prekrštavanje", "izopćen", "izbačen", "bludničio",  "posvećenje", "inkardiniran", "inkardinacija",  "mračno doba", "razotkrio", "prijavio", "bludničio", "pronevjerio", "homofobijam", "zlodjela", "progoni", "dogma", "kontroverzni" , "moderni", "svećenik", "tolerantna", "vjera", "vjerska", "policija", "vjerska", "kontrola", "crkveni", "mediji", "vjerski" ,"mediji", "ukidanje", "homofob", "pedofil", "homoseksualnost", "patrijarhat", "čudesno" , "ozdravljenje", "čudo")
pattern_pomocno <- str_c("\\b(", str_c(pomocno, collapse = "|"), ")\\b")
# Define the batch size
batch_size <- 1000
# Split your data into batches
batches <- split(dt, ceiling(seq_along(dt[[1]])/batch_size))
# Function to process each batch
process_batch <- function(batch) {
batch %>%
as_tibble() %>%
select(V1, DATE, TITLE, URL, FULL_TEXT) %>%
mutate(
full_text = tolower(FULL_TEXT),
match = str_c(pomocno, collapse = '|'),
key_word = str_extract_all(full_text, match)
) %>%
filter(lengths(key_word) > 0) %>%
unnest(key_word) %>%
distinct(V1, .keep_all = TRUE)
}
# Process each batch
results <- batches %>%
map(~ process_batch(.x))
df <- bind_rows(results)
filtered_df <- df %>%
filter(str_detect(full_text, pattern_pomocno))
filtered_df %>% group_by(key_word) %>% count() %>% arrange(desc(n))
View(dt)
# fullDta <- fread("D:/LUKA/Freelance/Mediatoolkit/FULLDATA_NOTXT.csv")
# fullDtaTxt <- fread("D:/LUKA/Freelance/Mediatoolkit/FULLDATA_TXT.csv")
all <- fread("D:/LUKA/Freelance/Mediatoolkit/MktFULLtxt.csv")
dta <- merge(dt, all, by = "V1", all.x = TRUE)
View(dta)
dt <- merge(dt, all, by = "V1", all.x = TRUE)
dta$DATE <- as.Date(dta$DATE)
dt$DATE <- as.Date(dt$DATE)
dt$DATE <- as.Date(dt$DATE)
View(dt)
dt$DATE <- as.Date(dt$DATE.x)
range(dt$DATE)
# articles over time
daily_counts <- dt %>%
group_by(DATE) %>%
summarise(count = n())
# descriptives
summ <- daily_counts %>%
summarize(min = min(count), max = max(count),
mean = mean(count), q1= quantile(count, probs = 0.25),
median = median(count), q3= quantile(count, probs = 0.75),
sd = sd(count)) %>%
mutate_if(is.numeric, round, digits=2)
summ
# create plot of articles over time
ggplot(data = daily_counts, aes(x = DATE, y = count)) +
geom_line() +
labs(x = "Date", y = "Number of Articles")
# Portals by activity
activity <- dt %>%
group_by(FROM) %>%
summarise(count = n()) %>%
mutate(percent = round(count / sum(count) * 100,2)) %>%
arrange(desc(count))
datatable(activity, options = list(scrollX = TRUE, scrollY = "500px"))
activity
datatable(activity, options = list(scrollX = TRUE, scrollY = "500px"))
# read in lexicons
CroSentilex_n <- read.delim("C:/Users/Lukas/Dropbox/Mislav@Luka/crosentilex-negatives.txt",
header = FALSE,
sep = " ",
stringsAsFactors = FALSE,
fileEncoding = "UTF-8")  %>%
rename(word = "V1", sentiment = "V2" ) %>%
mutate(brija = "NEG")
# read in lexicons
CroSentilex_n <- read.delim("C:/Users/Lukas/Dropbox/Mislav@Luka/crosentilex-negatives.txt",
header = FALSE,
sep = " ",
stringsAsFactors = FALSE,
fileEncoding = "UTF-8")  %>%
rename(word = "V1", sentiment = "V2" ) %>%
mutate(brija = "NEG")
CroSentilex_p  <- read.delim("C:/Users/Lukas/Dropbox/Mislav@Luka/crosentilex-positives.txt",
header = FALSE,
sep = " ",
stringsAsFactors = FALSE,
fileEncoding = "UTF-8") %>%
rename(word = "V1", sentiment = "V2" ) %>%
mutate(brija = "POZ")
Crosentilex_sve <- rbind(setDT(CroSentilex_n), setDT(CroSentilex_p))
CroSentilex_Gold  <- read.delim2("C:/Users/Lukas/Dropbox/Mislav@Luka/gs-sentiment-annotations.txt",
header = FALSE,
sep = " ",
stringsAsFactors = FALSE) %>%
rename(word = "V1", sentiment = "V2" )
Encoding(CroSentilex_Gold$word) <- "UTF-8"
CroSentilex_Gold[1,1] <- "dati"
CroSentilex_Gold$sentiment <- str_replace(CroSentilex_Gold$sentiment , "-", "1")
CroSentilex_Gold$sentiment <- str_replace(CroSentilex_Gold$sentiment , "\\+", "2")
CroSentilex_Gold$sentiment <- as.numeric(unlist(CroSentilex_Gold$sentiment))
# create stop words
stopwords_cro <- get_stopwords(language = "hr", source = "stopwords-iso")
# check stopwords data
#head(sample_n(stopwords_cro,100),15)
# extend stop words
my_stop_words <- tibble(
word = c(
"jedan","mjera", "može", "možete", "mogu", "kad", "sada", "treba", "ima", "osoba",
"e","prvi", "dva","dvije","drugi",
"tri","treći","pet","kod",
"ove","ova",  "ovo","bez", "kod",
"evo","oko",  "om", "ek",
"mil","tko","šest", "sedam",
"osam",   "čim", "zbog",
"prema", "dok","zato", "koji",
"im", "čak","među", "tek",
"koliko", "tko","kod","poput",
"baš", "dakle", "osim", "svih",
"svoju", "odnosno", "gdje",
"kojoj", "ovi", "toga",
"ubera", "vozača", "hrvatskoj", "usluge", "godine", "više", "taksi", "taxi", "taksija", "taksija", "kaže", "rekao", "19"," aee", "ae","bit.ly", "https", "one", "the"
),
lexicon = "lux"
)
stop_corpus <- my_stop_words %>%
bind_rows(stopwords_cro)
# tokenize
dt %>%
unnest_tokens(word, FULL_TEXT) -> n_token
# tokenize
dt %>%
unnest_tokens(word, FULL_TEXT.x) -> n_token
n_tokenTidy %>%
group_by(word) %>%
summarise(N = n()) %>%
arrange(desc(N)) %>%
filter(N > 50) %>%
datatable(., options = list(scrollX = TRUE, scrollY = "500px"))
n_tokenTidy %>%
group_by(word) %>%
summarise(N = n()) %>%
arrange(desc(N)) %>%
filter(N > 50) %>%
datatable(., options = list(scrollX = TRUE, scrollY = "500px"))
# remove NA
n_tokenTidy %>%
filter(!is.na(word)) -> n_tokenTidy
# remove stop words, numbers, single letters
n_token %>%
anti_join(stop_corpus, by = "word") %>%
mutate(word = gsub("\\d+", NA, word)) %>%
mutate(word = gsub("^[a-zA-Z]$", NA, word)) -> n_tokenTidy
# remove NA
n_tokenTidy %>%
filter(!is.na(word)) -> n_tokenTidy
rm(all)
n_tokenTidy %>%
group_by(word) %>%
summarise(N = n()) %>%
arrange(desc(N)) %>%
filter(N > 50) %>%
datatable(., options = list(scrollX = TRUE, scrollY = "500px"))
