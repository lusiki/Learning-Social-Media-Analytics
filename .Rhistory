fb <- as.data.table(fb)
# influencers by INTERACTIONS
fb[,INTERACTIONS := sum(INTERACTIONS), FROM][,.(INTERACTIONS,FROM)][order(-INTERACTIONS)] %>% unique()
# influencers by COMMENT
fb[,COMMENT := sum(COMMENT_COUNT), FROM][,.(COMMENT,FROM)][order(-COMMENT)] %>% unique()
# influencers by COMMENT II
fb[, `:=` (ACTIVITY = .N , COMMENT = sum(COMMENT_COUNT),ENGAGE = COMMENT/ACTIVITY), FROM][,.(FROM,ACTIVITY,COMMENT, ENGAGE)][ACTIVITY >= 100][order(-COMMENT)] %>% unique()
# influencers by SHARE
fb[,SHARE := sum(SHARE_COUNT), FROM][,.(SHARE,FROM)][order(-SHARE)] %>% unique()
# influencers by SHARE II
fb[, `:=` (ACTIVITY = .N , SHARE = sum(SHARE_COUNT), DISPERSION = SHARE/ACTIVITY), FROM][,.(FROM,ACTIVITY,SHARE,DISPERSION)][ACTIVITY >= 100][order(-DISPERSION)] %>% unique()
fb[, `:=` (ACTIVITY = .N ,LETTERS = sum(nchar(FULL_TEXT)),EFFORT = LETTERS/ACTIVITY), FROM][,.(FROM,ACTIVITY,LETTERS, EFFORT)][ACTIVITY >= 100][order(-EFFORT)] %>% unique()
fb[, `:=` (ACTIVITY = .N ,LETTERS = sum(nchar(FULL_TEXT)), EFFORT = LETTERS/ACTIVITY), FROM]
fb[, `:=` (ACTIVITY = .N ,LETTERS = sum(nchar(FULL_TEXT))),FROM]
str(fb)
fb[, `:=` (ACTIVITY = .N ,LETTERS = sum(nchar(FULL_TEXT)), EFFORT = LETTERS/ACTIVITY), FROM][,.(FROM,ACTIVITY,LETTERS, EFFORT)][ACTIVITY >= 100][order(-EFFORT)] %>% unique()
fb[,.(SHARE_COUNT,FROM,FULL_TEXT, URL)][order(-SHARE_COUNT)]
fb[, `:=` (ACTIVITY = .N ,LETTERS = sum(nchar(FULL_TEXT)), EFFORT = LETTERS/ACTIVITY), FROM][,.(FROM,ACTIVITY,LETTERS, EFFORT)][ACTIVITY >= 100][order(-EFFORT)] %>% unique()
# influencers by ACTIVITY
fb[,.N,FROM][order(-N)]
# influencers by FOLLOWERS
fb[,FOLLOWERS := max(FOLLOWERS_COUNT), FROM][,c("FOLLOWERS","FROM")][order(-FOLLOWERS)] %>% unique()
# influencers by REACH
fb[,REACH := sum(REACH), FROM][,.(REACH,FROM)][order(-REACH)] %>% unique()
fb %>%
group_by(FROM) %>%
mutate(ACTIVITY = n(),
REACH = sum(REACH),
EFFECT = REACH/ACTIVITY) %>%
filter(ACTIVITY>100) %>%
arrange(desc(EFFECT)) %>%
unique()
#  fb %>%
#  group_by(FROM) %>%
#  mutate(ACTIVITY = n(),
#         REACH = sum(REACH),
#         EFFECT = REACH/ACTIVITY) %>%
#  filter(ACTIVITY>100) %>%
#  arrange(desc(EFFECT)) %>%
#  unique() -> fb
#fb <- as.data.table(fb)
# influencers by LIKE
fb[,LIKE := sum(LIKE_COUNT), FROM][,.(LIKE,FROM)][order(-LIKE)] %>% unique()
fb %>%
group_by(FROM) %>%
mutate(ACTIVITY = n(),
REACH = sum(REACH),
EFFECT = REACH/ACTIVITY) %>%
select(FROM,ACTIVITY,REACH,EFFECT) %>%
filter(ACTIVITY>100) %>%
arrange(desc(EFFECT)) %>%
unique()
# influencers by INTERACTIONS
fb[,INTERACTIONS := sum(INTERACTIONS), FROM][,.(INTERACTIONS,FROM)][order(-INTERACTIONS)] %>% unique()
fb %>%
group_by(FROM) %>%
mutate(LIKE = sum(LIKE_COUNT),
ACTIVITY = n(),
EFFECT = LIKE/ACTIVITY) %>%
select(FROM,ACTIVITY,LIKE,EFFECT) %>%
filter(ACTIVITY>100) %>%
arrange(desc(EFFECT)) %>%
unique()
fb %>%
group_by(FROM) %>%
mutate(COMMENT = sum(COMMENT_COUNT),
ACTIVITY = n(),
ENGAGE = COMMENT/ACTIVITY) %>%
select(FROM,ACTIVITY,COMMENT,ENGAGE) %>%
filter(ACTIVITY>100) %>%
arrange(desc(EFFECT)) %>%
unique()
fb %>%
group_by(FROM) %>%
mutate(COMMENT = sum(COMMENT_COUNT),
ACTIVITY = n(),
ENGAGE = COMMENT/ACTIVITY) %>%
select(FROM,ACTIVITY,COMMENT,ENGAGE) %>%
filter(ACTIVITY>100) %>%
arrange(desc(ENGAGE)) %>%
unique()
# influencers by SHARE
fb[,SHARE := sum(SHARE_COUNT), FROM][,.(SHARE,FROM)][order(-SHARE)] %>% unique()
knitr::opts_chunk$set(echo = T, message = F, warning = F)
library(tidyverse)
library(readxl)
library(here)
library(kableExtra)
library(DT)
library(data.table)
library(lubridate)
library(anytime)
library(tidytext)
library(grid)
library(wordcloud)
library(reshape2)
library(ggraph)
library(widyr)
library(topicmodels)
library(ggthemes)
library(reportMD)
path <- "D:/LUKA/Freelance/Mediatoolkit/FULLtxtDATA"
raw <- list.files(path = path , pattern="xlsx")
raw_path <- paste0(path, "/", raw)
all_raw <- map_df(raw_path, read_excel)
all <- as.data.table(all_raw)
all <- all[,DATE := as.Date(DATE,"%Y-%m-%d")][,DATETIME := anytime(paste(DATE,TIME))]
posts <- all[!duplicated(all),]
rm(all,all_raw)
posts[.N,DATE]
posts[,.N,DATE]
posts[,.N,DATE] %>% View()
posts[,.N,DATE][order(-DATE)] %>% View()
names(posts)
View(posts)
posts[,SOURCE_TYPE == "web"][,.(unique(FROM))][]
posts[,SOURCE_TYPE == "web"][,.(FROM)][]
posts[,SOURCE_TYPE == "web"]
posts[SOURCE_TYPE == "web",][,FROM][]
posts[SOURCE_TYPE == "web",][,unique(FROM)][]
posts[SOURCE_TYPE == "web"][,.N,FROM][order(-N)]
posts[SOURCE_TYPE == "web"][,.N,FROM][,unique(FROM)][order(-N)]
posts[SOURCE_TYPE == "web"][,.N,FROM][order(-N)][,unique(FROM)]
posts[SOURCE_TYPE == "web"][,.N,FROM][order(-N)]
posts[SOURCE_TYPE == "web"][,.N,FROM][order(-N)] -> portali
View(portali)
write.csv2(portali, "C:/Users/Lukas/OneDrive/Desktop/portali.csv")
posts[,.N, SOURCE_TYPE]
posts[SOURCE_TYPE == "youtube",]
posts[SOURCE_TYPE == "youtube",] %>% View()
posts[SOURCE_TYPE == "youtube",][order(-REACH)] %>% View()
posts[SOURCE_TYPE == "youtube",][order(-VIEW_COUNT)] %>% View()
posts[SOURCE_TYPE == "youtube",][order(-LIKE_COUNT)] %>% View()
posts[SOURCE_TYPE == "youtube",.N,FROM]
posts[SOURCE_TYPE == "youtube",.N,FROM][order(-N)]
yt[order(-LIKE_COUNT)] %>% head(50)
# select facebook
yt <- posts[SOURCE_TYPE == "facebook",]
yt <- as.data.table(yt)
yt[order(-LIKE_COUNT)] %>% head(50)
yt[,.N, FROM][order(-N)] %>% head(50)
# select facebook
yt <- posts[SOURCE_TYPE == "youtube",]
yt <- as.data.table(yt)
yt[,.N, FROM][order(-N)] %>% head(50)
yt[,.N, FROM][order(-N)] %>% head(100)
yt[,.N, FROM][order(-N)] %>% head(150)
yt[,LIKE = sum(LIKE_COUNT),FROM][order(-LIKE)] %>% head(50)
yt[, LIKE = sum(LIKE_COUNT),FROM]
yt[, LIKE := sum(LIKE_COUNT),FROM][order(-LIKE)] %>% head(50)
yt[, LIKE := sum(LIKE_COUNT),FROM][,.(FROM, LIKE)][order(-LIKE)] %>% head(50)
yt[, LIKE := sum(LIKE_COUNT),FROM][,.(unique(FROM), LIKE)][order(-LIKE)] %>% head(50)
yt[, LIKE := sum(LIKE_COUNT),FROM][order(-LIKE)] %>% head(50)
posts[SOURCE_TYPE == "youtube",.N,FROM][order(-N)][unique(FROM)]
yt[, LIKE := sum(LIKE_COUNT),FROM][order(-LIKE)][unique(FROM)] %>% head(50)
yt[, LIKE = sum(LIKE_COUNT),FROM]
yt[, sum(LIKE_COUNT),FROM]
yt[, sum(LIKE_COUNT),FROM][order(-LIKE)] %>% head(50)
yt[, order(sum(LIKE_COUNT)),FROM]
yt[, order(-sum(LIKE_COUNT)),FROM]
yt[, .(sum(LIKE_COUNT)),FROM][order(-LIKE)]
yt[, .(sum(LIKE_COUNT)),FROM]
yt[, .(LIKE = sum(LIKE_COUNT)),FROM][order(-LIKE)]
yt[, .(LIKE = sum(LIKE_COUNT)),FROM][order(-LIKE)] %>% head(150)
View(yt)
# Top reach
yt[, .(REACH = sum(REACH)),FROM][order(-REACH)] %>% head(150)
# Top engagement
yt[, .(ENGAGEMENT = sum(ENGAGEMENT_RATE)),FROM][order(-ENGAGEMENT)] %>% head(150)
# Top interactions
yt[, .(INTERACTIONS_ = sum(INTERACTIONS)),FROM][order(-INTERACTIONS_)] %>% head(150)
View(yt)
# Top view
yt[, .(VIEW = sum(VIEW_COUNT)),FROM][order(-VIEW)] %>% head(150)
# Top comment
yt[, .(COMMENT = sum(COMMENTS_COUNT)),FROM][order(-COMMENT)] %>% head(150)
# Top like
yt[order(-LIKE)] %>% head(150)
# Top like
yt[order(-LIKE),.(FROM,URL,FULL_TEXT)] %>% head(150)
# Top like
yt[order(-LIKE),.(FROM,URL,FULL_TEXT)] %>% head(250)
# Top reach
yt[order(-REACH)] %>% head(150)
# Top reach
yt[order(-REACH),.(FROM,URL,FULL_TEXT)] %>% head(150)
# Top reach
yt[order(-REACH),.(FROM,TITLE,URL,FULL_TEXT)] %>% head(150)
# Top engagement
yt[order(-ENGAGEMENT),.(FROM,TITLE,URL,FULL_TEXT)] %>% head(150)
# Top engagement
yt[order(-ENGAGEMENT),.(FROM,TITLE,URL,FULL_TEXT)] %>% head(150)
# Top reach
yt[order(-REACH),.(FROM,TITLE,URL,FULL_TEXT)] %>% head(150)
# Top interactions
yt[order(-INTERACTIONS),.(FROM,TITLE,URL,FULL_TEXT)] %>% head(150)
# Top like
yt[order(-LIKE),.(FROM,TITLE,LIKE,URL,FULL_TEXT)] %>% head(250)
# Top comment
yt[order(-COMMENTS_COUNT),.(FROM,TITLE,COMMENTS_COUNT,URL,FULL_TEXT] %>% head(150)
# Top comment
yt[order(-COMMENTS_COUNT),.(FROM,TITLE,COMMENTS_COUNT,URL,FULL_TEXT)] %>% head(150)
# Top view
yt[order(-VIEW_COUNT),.(FROM,TITLE,VIEW_COUNT,URL,FULL_TEXT)] %>% head(150)
# Top interactions
yt[order(-INTERACTIONS),.(FROM,TITLE,INTERACTIONS,URL,FULL_TEXT)] %>% head(150)
page  <- "https://www.channelcrawler.com/eng/results/48267/sort:Channel.subscribers/direction:desc"
nums <- seq(2,50)
links <- c(page,
paste0("https://www.channelcrawler.com/eng/results/48267/page:"
,nums,
"/sort:Channel.subscribers/direction:desc"))
parser <- function(url) {
Sys.sleep(runif(1, min = 2, max = 7))
name <- read_html(url) %>%
html_nodes(., "h4") %>%
html_nodes(., "a") %>%
html_attr(.,"title")
link <- read_html(url) %>%
html_nodes(., "h4") %>%
html_nodes(.,"a") %>%
html_attr(.,"href")
genre <- read_html(url) %>%
html_nodes(.,  "b") %>%
.[seq(1,length(.),2)] %>%
html_text()
meta <- read_html(url) %>%
html_nodes(.,"#main-content.container") %>%
html_nodes(.,  "p") %>%
html_nodes(., "small") %>%
.[seq(1,length(.),2)] %>%
html_text()  %>%
str_replace_all(., "[\t]" , "") %>%
gsub("\n", "*", .) %>%
data.frame(do.call("rbind", strsplit(as.character(.), "*", fixed = TRUE))) %>%
select(X2:X5)
subscribers <- meta$X2 %>%
gsub(" Subscribers", "",. ) %>%
gsub("M", "*1000000",.) %>%
gsub("K","*1000",.) #%>%
# gsub("\\.", "",.) %>%
# as.numeric()
videos <- meta$X3 %>%
gsub(" Videos","",.) %>%
as.numeric()
views <- meta$X4 %>%
gsub(" Total Views","",.) %>%
gsub("B", "*100000000",.) %>%
gsub("M","*1000000",.) %>%
gsub("K","*1000",.) #%>%
# gsub("\\.", "",.) %>%
# as.numeric()
lastvideo <- meta$X5 %>%
gsub("Latest Video: ", "",.) %>%
mdy("%b %d %Y") %>%
na.omit()
description <- cbind.data.frame(name, genre, subscribers, videos,
views, lastvideo,link, # link_proizvod, # brand_,
stringsAsFactors = FALSE)
return(description)
}
all <- lapply(links[1:10],parser)
library(magrittr) #for pipes
library(dplyr) #for pull function
library(rvest) #get html nodes
library(xml2) #pull html data
library(selectr) #for xpath element
library(tibble)
library(purrr) #for map functions
library(datapasta) #for recreating tibble's with ease
library(stringr)
library(rebus)
library(XML)
library(tidyr)
library(lubridate)
all <- lapply(links[1:10],parser)
parser <- function(url) {
Sys.sleep(runif(1, min = 2, max = 7))
name <- read_html(url) %>%
html_nodes(., "h4") %>%
html_nodes(., "a") %>%
html_attr(.,"title")
link <- read_html(url) %>%
html_nodes(., "h4") %>%
html_nodes(.,"a") %>%
html_attr(.,"href")
genre <- read_html(url) %>%
html_nodes(.,  "b") %>%
.[seq(1,length(.),2)] %>%
html_text()
meta <- read_html(url) %>%
html_nodes(.,"#main-content.container") %>%
html_nodes(.,  "p") %>%
html_nodes(., "small") %>%
.[seq(1,length(.),2)] %>%
html_text()  %>%
str_replace_all(., "[\t]" , "") %>%
gsub("\n", "*", .) %>%
data.frame(do.call("rbind", strsplit(as.character(.), "*", fixed = TRUE))) %>%
select(X2:X5)
subscribers <- meta$X2 %>%
gsub(" Subscribers", "",. ) %>%
gsub("M", "*1000000",.) %>%
gsub("K","*1000",.) #%>%
# gsub("\\.", "",.) %>%
# as.numeric()
videos <- meta$X3 %>%
gsub(" Videos","",.) %>%
as.numeric()
views <- meta$X4 %>%
gsub(" Total Views","",.) %>%
gsub("B", "*100000000",.) %>%
gsub("M","*1000000",.) %>%
gsub("K","*1000",.) #%>%
# gsub("\\.", "",.) %>%
# as.numeric()
lastvideo <- meta$X5 %>%
gsub("Latest Video: ", "",.) %>%
mdy("%b %d %Y") %>%
na.omit()
description <- cbind.data.frame(name, genre, subscribers, videos,
views, lastvideo,link, # link_proizvod, # brand_,
stringsAsFactors = FALSE)
return(description)
}
all <- lapply(links[1:10],parser)
parse_proizvodi <- function(url) {
p <- tryCatch({
read_html(url, user_agent = get_header()) %>%
html_node(xpath = '//*[@id="js-product-list"]') %>%
html_nodes("a") %>%
html_attr("href") %>%
.[str_detect(., "/\\d+")] %>%
unique(.)
}, error = function(e) NA)
return(p)
}
parse_proizvodi_vise_pokusaja <- function(url, broj_pokusaja = 5) {
pokusaj <- 1
proizvodi_j <- parse_proizvodi(url)
while (pokusaj <= broj_pokusaja & any(is.na(proizvodi_j))) {
proizvodi_j <- parse_proizvodi(url)
pokusaj <- pokusaj + 1
print(paste0("Pokusaj: ", pokusaj))
}
return(proizvodi_j)
}
parse_proizvodi_ <- function(url) {
p <- tryCatch({
read_html(url, user_agent = get_header())
}, error = function(e) NA)
return(p)
}
parse_proizvodi_vise_pokusaja_ <- function(url, broj_pokusaja = 5) {
pokusaj <- 1
proizvodi_j <- parse_proizvodi_(url)
while (pokusaj <= broj_pokusaja & any(is.na(proizvodi_j))) {
proizvodi_j <- parse_proizvodi_(url)
pokusaj <- pokusaj + 1
print(paste0("Pokusaj: ", pokusaj))
}
return(proizvodi_j)
}
all <- lapply(links[1:10],parser)
page  <- "https://www.channelcrawler.com/eng/results/48267/sort:Channel.subscribers/direction:desc"
nums <- seq(2,50)
links <- c(page,
paste0("https://www.channelcrawler.com/eng/results/48267/page:"
,nums,
"/sort:Channel.subscribers/direction:desc"))
links
page  <- "https://www.channelcrawler.com/eng/results/282308/sort:Channel.subscribers/direction:desc"
nums <- seq(2,50)
links <- c(page,
paste0("https://www.channelcrawler.com/eng/results/282308/page:"
,nums,
"/sort:Channel.subscribers/direction:desc"))
links
links <- c(page,
paste0("https://www.channelcrawler.com/eng/results/282308/page:"
,nums))
links
links <- c(page,
paste0("https://www.channelcrawler.com/eng/results/282308/page:"
,nums))
links
page  <- "https://www.channelcrawler.com/eng/results2/282308"
nums <- seq(2,50)
links <- c(page,
paste0("https://www.channelcrawler.com/eng/results2/282308/page:"
,nums))
links
nums <- seq(2,13)
links <- c(page,
paste0("https://www.channelcrawler.com/eng/results2/282308/page:"
,nums))
links
parser <- function(url) {
Sys.sleep(runif(1, min = 2, max = 7))
name <- read_html(url) %>%
html_nodes(., "h4") %>%
html_nodes(., "a") %>%
html_attr(.,"title")
link <- read_html(url) %>%
html_nodes(., "h4") %>%
html_nodes(.,"a") %>%
html_attr(.,"href")
genre <- read_html(url) %>%
html_nodes(.,  "b") %>%
.[seq(1,length(.),2)] %>%
html_text()
meta <- read_html(url) %>%
html_nodes(.,"#main-content.container") %>%
html_nodes(.,  "p") %>%
html_nodes(., "small") %>%
.[seq(1,length(.),2)] %>%
html_text()  %>%
str_replace_all(., "[\t]" , "") %>%
gsub("\n", "*", .) %>%
data.frame(do.call("rbind", strsplit(as.character(.), "*", fixed = TRUE))) %>%
select(X2:X5)
subscribers <- meta$X2 %>%
gsub(" Subscribers", "",. ) %>%
gsub("M", "*1000000",.) %>%
gsub("K","*1000",.) #%>%
# gsub("\\.", "",.) %>%
# as.numeric()
videos <- meta$X3 %>%
gsub(" Videos","",.) %>%
as.numeric()
views <- meta$X4 %>%
gsub(" Total Views","",.) %>%
gsub("B", "*100000000",.) %>%
gsub("M","*1000000",.) %>%
gsub("K","*1000",.) #%>%
# gsub("\\.", "",.) %>%
# as.numeric()
lastvideo <- meta$X5 %>%
gsub("Latest Video: ", "",.) %>%
mdy("%b %d %Y") %>%
na.omit()
description <- cbind.data.frame(name, genre, subscribers, videos,
views, lastvideo,link, # link_proizvod, # brand_,
stringsAsFactors = FALSE)
return(description)
}
all <- lapply(links[1:13],parser)
links
name <- read_html("https://www.channelcrawler.com/eng/results2/282308/page:4") %>%
html_nodes(., "h4") %>%
html_nodes(., "a") %>%
html_attr(.,"title")
link <- read_html("https://www.channelcrawler.com/eng/results2/282308/page:4") %>%
html_nodes(., "h4") %>%
html_nodes(.,"a") %>%
html_attr(.,"href")
genre <- read_html("https://www.channelcrawler.com/eng/results2/282308/page:4") %>%
html_nodes(.,  "b") %>%
.[seq(1,length(.),2)] %>%
html_text()
meta <- read_html("https://www.channelcrawler.com/eng/results2/282308/page:4") %>%
html_nodes(.,"#main-content.container") %>%
html_nodes(.,  "p") %>%
html_nodes(., "small") %>%
.[seq(1,length(.),2)] %>%
html_text()  %>%
str_replace_all(., "[\t]" , "") %>%
gsub("\n", "*", .) %>%
data.frame(do.call("rbind", strsplit(as.character(.), "*", fixed = TRUE))) %>%
select(X2:X5)
View(meta)
subscribers <- meta$X2 %>%
gsub(" Subscribers", "",. ) %>%
gsub("M", "*1000000",.) %>%
gsub("K","*1000",.) #%>%
subscribers
videos <- meta$X3 %>%
gsub(" Videos","",.) %>%
as.numeric()
videos
views <- meta$X4 %>%
gsub(" Total Views","",.) %>%
gsub("B", "*100000000",.) %>%
gsub("M","*1000000",.) %>%
gsub("K","*1000",.) #%>%
views
lastvideo <- meta$X5 %>%
gsub("Latest Video: ", "",.) %>%
mdy("%b %d %Y") %>%
na.omit()
lastvideo
description <- cbind.data.frame(name, genre, subscribers, videos,
views, lastvideo,link, # link_proizvod, # brand_,
stringsAsFactors = FALSE)
genre <- read_html("https://www.channelcrawler.com/eng/results2/282308/page:4") %>%
html_nodes(.,  "b") %>%
.[seq(1,length(.),2)] %>%
html_text()
description <- merge(name, genre, subscribers, videos,
views, lastvideo,link, # link_proizvod, # brand_,
stringsAsFactors = FALSE)
name
name <- read_html("https://www.channelcrawler.com/eng/results2/282308/page:4") %>%
html_nodes(., "h4") %>%
html_nodes(., "a") %>%
html_attr(.,"title")
name
name <- read_html("https://www.channelcrawler.com/eng/results2/282308/page:2") %>%
html_nodes(., "h4") %>%
html_nodes(., "a") %>%
html_attr(.,"title")
name
