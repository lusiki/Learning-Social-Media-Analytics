library(tidytext)
library(dplyr)
library(lubridate)
library(anytime)
library(grid)
library(wordcloud)
library(reshape2)
library(ggraph)
library(widyr)
library(topicmodels)
library(ggthemes)
library(xlsx)
library(writexl)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
library(xlsx)
library(here)
library(kableExtra)
library(DT)
library(purrr)
library(data.table)
library(tidytext)
library(dplyr)
library(lubridate)
library(anytime)
library(grid)
library(wordcloud)
library(reshape2)
library(ggraph)
library(widyr)
library(topicmodels)
library(ggthemes)
library(xlsx)
# Read In
original <- read.xlsx("D:/LUKA/Freelance/Mediatoolkit/native1.xlsx", sheetIndex = 1) %>% mutate(V1 = as.numeric(V1))
variables <- read.xlsx("C:/Users/Lukas/OneDrive/Desktop/Native.xlsx", sheetIndex = 1)
variables <- variables[,-c(23,24,25)]# %>% drop_na()
original <- original %>% filter(V1 %in% variables$V1)
dta <- merge(original, variables, by = "V1", all.x = TRUE)
dta$DATE <- as.Date(dta$DATE)
stemmed <- readRDS("D:/LUKA/Freelance/Mediatoolkit/native_token_stemm.rds")
stemmed <- stemmed %>%
rename("wordp" = "word") %>%
rename("word" = "transformed_column")
# read in lexicons
CroSentilex_n <- read.delim("C:/Users/Lukas/Dropbox/Mislav@Luka/crosentilex-negatives.txt",
header = FALSE,
sep = " ",
stringsAsFactors = FALSE,
fileEncoding = "UTF-8")  %>%
rename(word = "V1", sentiment = "V2" ) %>%
mutate(brija = "NEG")
CroSentilex_p  <- read.delim("C:/Users/Lukas/Dropbox/Mislav@Luka/crosentilex-positives.txt",
header = FALSE,
sep = " ",
stringsAsFactors = FALSE,
fileEncoding = "UTF-8") %>%
rename(word = "V1", sentiment = "V2" ) %>%
mutate(brija = "POZ")
Crosentilex_sve <- rbind(setDT(CroSentilex_n), setDT(CroSentilex_p))
# check lexicon data
#head(sample_n(Crosentilex_sve,1000),15)
CroSentilex_Gold  <- read.delim2("C:/Users/Lukas/Dropbox/Mislav@Luka/gs-sentiment-annotations.txt",
header = FALSE,
sep = " ",
stringsAsFactors = FALSE) %>%
rename(word = "V1", sentiment = "V2" )
Encoding(CroSentilex_Gold$word) <- "UTF-8"
CroSentilex_Gold[1,1] <- "dati"
CroSentilex_Gold$sentiment <- str_replace(CroSentilex_Gold$sentiment , "-", "1")
CroSentilex_Gold$sentiment <- str_replace(CroSentilex_Gold$sentiment , "\\+", "2")
CroSentilex_Gold$sentiment <- as.numeric(unlist(CroSentilex_Gold$sentiment))
# check lexicon data
#head(sample_n(CroSentilex_Gold,100),15)
LilaHR  <- read_excel("C:/Users/Lukas/Dropbox/Mislav@Luka/lilaHR_.xlsx", sheet = "Sheet1")
proba <- read.csv2("C:/Users/Lukas/Dropbox/Mislav@Luka/lilaHRcsv.csv", encoding = "UTF-8")
#df <- separate_rows(LilaHR, HR, sep = ", ")
#
# zero_rows_count <- sum(apply(df[-1], 1, function(row) all(row == 0)))
# print(zero_rows_count)
#
# filtered_df <- df %>%
#   filter(!apply(.[,-1], 1, function(row) all(row == 0)))
#
# write.xlsx(filtered_df, "C:/Users/Lukas/Dropbox/Mislav@Luka/lilaHR_.xlsx" )
# create stop words
stopwords_cro <- get_stopwords(language = "hr", source = "stopwords-iso")
# check stopwords data
#head(sample_n(stopwords_cro,100),15)
# extend stop words
my_stop_words <- tibble(
word = c(
"jedan","mjera", "može", "možete", "mogu", "kad", "sada", "treba", "ima", "osoba",
"e","prvi", "dva","dvije","drugi",
"tri","treći","pet","kod",
"ove","ova",  "ovo","bez", "kod",
"evo","oko",  "om", "ek",
"mil","tko","šest", "sedam",
"osam",   "čim", "zbog",
"prema", "dok","zato", "koji",
"im", "čak","među", "tek",
"koliko", "tko","kod","poput",
"baš", "dakle", "osim", "svih",
"svoju", "odnosno", "gdje",
"kojoj", "ovi", "toga",
"ubera", "vozača", "hrvatskoj", "usluge", "godine", "više", "taksi", "taxi", "taksija", "taksija", "kaže", "rekao", "19"," aee", "ae","bit.ly", "https", "one", "the"
),
lexicon = "lux"
)
# full set with diacritics
cro_sw_full_d <- tibble(word = c("a","ako","ali","baš","bez","bi","bih","bila","bili","bilo","bio","bismo","bit","biti","bolje","bude","čak","čega","čemu","često","četiri","čime","čini","će","ćemo","ćete","ću","da","dakle","dalje","dan","dana","dana","danas","dio","do","dobro","dok","dosta","dva","dvije","eto","evo","ga","gdje","god","godina","godine","gotovo","grada","i","iako","ići","ih","ili","im","ima","imaju","imali","imam","imao","imati","inače","ipak","isto","iz","iza","između","ja","jako","je","jedan","jedna","jednog","jednom","jednostavno","jednu","jer","joj","još","ju","ka","kad","kada","kaj","kako","kao","kaže","kod","koja","koje","kojeg","kojeg","kojem","koji","kojih","kojim","kojima","kojoj","kojom","koju","koliko","kraju","kroz","li","malo","manje","me","među","međutim","mene","meni","mi","milijuna","mislim","mjesto","mnogo","mogao","mogli","mogu","moj","mora","možda","može","možemo","možete","mu","na","način","nad","naime","nakon","nam","naravno","nas","ne","neće","nego","neka","neke","neki","nekog","nekoliko","neku","nema","nešto","netko","ni","nije","nikad","nisam","nisu","ništa","niti","no","njih","o","od","odmah","odnosno","oko","on","ona","onda","oni","onih","ono","opet","osim","ova","ovaj","ovdje","ove","ovim","ovo","ovog","ovom","ovu","pa","pak","par","po","pod","poput","posto","postoji","pred","preko","prema","pri","prije","protiv","prvi","puno","put","radi","reći","s","sa","sad","sada","sam","samo","sati","se","sebe","si","smo","ste","stoga","strane","su","svaki","sve","svi","svih","svoj","svoje","svoju","što","ta","tada","taj","tako","također","tamo","te","tek","teško","ti","tih","tijekom","time","tko","to","tog","toga","toj","toliko","tom","tome","treba","tu","u","uopće","upravo","uvijek","uz","vam","vas","već","vi","više","vrijeme","vrlo","za","zapravo","zar","zato","zbog","zna","znači"),
lexicon = "boras")
stop_corpus <- my_stop_words %>%
bind_rows(stopwords_cro)
stop_corpus <- stop_corpus %>%
bind_rows(cro_sw_full_d)
# check stopwords data
#head(sample_n(stop_corpus,100),15)
CroSentilex_n
LilaHR  <- read_excel("C:/Users/Lukas/Dropbox/Mislav@Luka/lilaHR_.xlsx", sheet = "Sheet1")
LilaHR
industry_list <- data.frame(
id = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28),
category = c(
"Financijska industrija",
"Građevinska industrija",
"Moda i ljepota",
"Politička institucija",
"Sportska industrija",
"Zdravlje",
"Obrazovanje i znanost",
"Tehnologija",
"Auto-moto industrija",
"ICT",
"Kultura i umjetnost",
"Turizam, odmor, putovanja, ugostiteljstvo",
"Energetska industrija",
"Prehrambena industrija",
"Industrija bezalkoholnih pića",
"Alkoholna pića",
"Nekretninska industrija",
"Maloprodajna trgovina",
"Igre na sreću",
"Medijske kuće i marketinške, digitalne agencije",
"Namještaj, saloni namještaja, kućanske potrepštine, kućanski uređaji, sredstva za čišćenje",
"Trgovački / shopping centri",
"Glazbena industrija",
"Filmska industrija",
"Brodogradnja",
"Pošta / distribucija pošiljki",
"Komunalne usluge"
)
)
# Create a histogram of the 'price' variable in the 'diamonds' dataset
ggplot(data = dta, aes(x = INDUSTRIJA)) +
geom_histogram(binwidth = 1, fill = "blue", alpha = 0.7) +
ggtitle("Industrija") +
xlab("Industrija") +
ylab("Frequency") +
scale_x_continuous(breaks = seq(from = min(dta$INDUSTRIJA), to =  max(dta$INDUSTRIJA), by = 1))
dta
dta %>%
mutate(percentIND = round(INDUSTRIJA / sum(INDUSTRIJA) * 100,2))
dta %>%
group_by(INDUSTRIJA) %>%
summarise(N = n())
dta %>%
group_by(INDUSTRIJA) %>%
summarise(N = n()) %>%
mutate(percentIND = round(N / sum(N) * 100,2))
IND <- dta %>%
group_by(INDUSTRIJA) %>%
summarise(N = n()) %>%
mutate(percentIND = round(N / sum(N) * 100,2))
# Create a histogram of the 'price' variable in the 'diamonds' dataset
ggplot(data = IND, aes(x = percentIND)) +
geom_histogram(binwidth = 1, fill = "blue", alpha = 0.7) +
ggtitle("Industrija") +
xlab("Industrija") +
ylab("Frequency") +
scale_x_continuous(breaks = seq(from = min(dta$INDUSTRIJA), to =  max(dta$INDUSTRIJA), by = 1))
# Create a histogram of the 'price' variable in the 'diamonds' dataset
ggplot(data = IND, aes(x = percentIND)) +
geom_histogram(binwidth = 1, fill = "blue", alpha = 0.7) +
ggtitle("Industrija") +
xlab("Industrija") +
ylab("%") +
scale_x_continuous(breaks = seq(from = min(dta$INDUSTRIJA), to =  max(dta$INDUSTRIJA), by = 1))
IND <- dta %>%
group_by(INDUSTRIJA) %>%
summarise(N = n()) %>%
mutate(percentIND = round(N / sum(N) * 100,2))
IND
IND %>%
datatable(., options = list(scrollX = TRUE, scrollY = "500px"))
PORIJEKLO <- dta %>%
group_by(PORIJEKLO) %>%
summarise(N = n()) %>%
mutate(percentIND = round(N / sum(N) * 100,2))
PORIJEKLO <- dta %>%
group_by(HRV.IL.STRANI.BREND) %>%
summarise(N = n()) %>%
mutate(percentIND = round(N / sum(N) * 100,2))
PORIJEKLO %>%
datatable(., options = list(scrollX = TRUE, scrollY = "500px"))
ggplot(data = PORIJEKLO, aes(x = percentPORIJEKLO)) +
geom_histogram(binwidth = 0.5, fill = "blue", alpha = 0.7) +
ggtitle("Porijeklo") +
xlab("Industrija") +
ylab("Frequency") +
scale_x_continuous(breaks = seq(from = min(dta$HRV.IL.STRANI.BREND), to =  max(dta$HRV.IL.STRANI.BREND), by = 1))
PORIJEKLO <- dta %>%
group_by(HRV.IL.STRANI.BREND) %>%
summarise(N = n()) %>%
mutate(percentPORIJEKLO = round(N / sum(N) * 100,2))
PORIJEKLO %>%
datatable(., options = list(scrollX = TRUE, scrollY = "500px"))
ggplot(data = PORIJEKLO, aes(x = percentPORIJEKLO)) +
geom_histogram(binwidth = 0.5, fill = "blue", alpha = 0.7) +
ggtitle("Porijeklo") +
xlab("Industrija") +
ylab("Frequency")
PORIJEKLO %>%
datatable(., options = list(scrollX = TRUE, scrollY = "500px"))
ggplot(data = dta, aes(x = HRV.IL.STRANI.BREND)) +
geom_histogram(binwidth = 0.5, fill = "blue", alpha = 0.7) +
ggtitle("Porijeklo") +
xlab("Industrija") +
ylab("Frequency") +
scale_x_continuous(breaks = seq(from = min(dta$HRV.IL.STRANI.BREND), to =  max(dta$HRV.IL.STRANI.BREND), by = 1))
SENTIMENT <- dta %>%
group_by(SENTIMENT) %>%
summarise(N = n()) %>%
mutate(percentSENTIMENT = round(N / sum(N) * 100,2))
SENTIMENT %>%
datatable(., options = list(scrollX = TRUE, scrollY = "500px"))
CroSentilex_Gold
View(LilaHR)
stop=c('biti','jesam','budem','sam','jesi','budeš','si','jesmo','budemo','smo','jeste','budete','ste','jesu','budu','su','bih','bijah','bjeh','bijaše','bi','bje','bješe','bijasmo','bismo','bjesmo','bijaste','biste','bjeste','bijahu','biste','bjeste','bijahu','bi','biše','bjehu','bješe','bio','bili','budimo','budite','bila','bilo','bile','ću','ćeš','će','ćemo','ćete','želim','želiš','želi','želimo','želite','žele','moram','moraš','mora','moramo','morate','moraju','trebam','trebaš','treba','trebamo','trebate','trebaju','mogu','možeš','može','možemo','možete')
istakniSlogotvornoR <- function(niz) {
stringr::str_replace_all(niz, "(^|[^aeiou])r($|[^aeiou])", "\\1R\\2")
}
imaSamoglasnik <- function(niz) {
!is.na(stringr::str_detect(istakniSlogotvornoR(niz), "[aeiouR]"))
}
transformiraj <- function(pojavnica) {
for(i in 1:nrow(transformacije)) {
trazi <- transformacije[i, 1]
zamijeni <- transformacije[i, 2]
if (endsWith(pojavnica, trazi)) {
return(sub(paste0(trazi, "$"), zamijeni, pojavnica))
}
}
return(pojavnica)
}
korjenuj <- function(pojavnica) {
for(pravilo in pravila) {
dioba <- stringr::str_match(pojavnica, pravilo)
if (!is.na(dioba[2])) {
if (imaSamoglasnik(dioba[2]) && nchar(dioba[2]) > 1) {
return(dioba[2])
}
}
}
return(pojavnica)
}
pravila <- lapply(strsplit(trimws(readLines('C:/Users/Lukas/Dropbox/Mislav@Luka/rules.txt')), ' '), function(x) paste0('^(', x[1], ')(', x[2], ')$'))
transformacije <- as.data.frame(do.call(rbind, strsplit(trimws(readLines('C:/Users/Lukas/Dropbox/Mislav@Luka/transformations.txt')), '\t')))
#text <- n_tokenTidy$word %>% head(1000)
#text <- tolower(readLines(input_file))
tokens <- unlist(stringi::stri_extract_all_words(text))
stop=c('biti','jesam','budem','sam','jesi','budeš','si','jesmo','budemo','smo','jeste','budete','ste','jesu','budu','su','bih','bijah','bjeh','bijaše','bi','bje','bješe','bijasmo','bismo','bjesmo','bijaste','biste','bjeste','bijahu','biste','bjeste','bijahu','bi','biše','bjehu','bješe','bio','bili','budimo','budite','bila','bilo','bile','ću','ćeš','će','ćemo','ćete','želim','želiš','želi','želimo','želite','žele','moram','moraš','mora','moramo','morate','moraju','trebam','trebaš','treba','trebamo','trebate','trebaju','mogu','možeš','može','možemo','možete')
istakniSlogotvornoR <- function(niz) {
stringr::str_replace_all(niz, "(^|[^aeiou])r($|[^aeiou])", "\\1R\\2")
}
imaSamoglasnik <- function(niz) {
!is.na(stringr::str_detect(istakniSlogotvornoR(niz), "[aeiouR]"))
}
transformiraj <- function(pojavnica) {
for(i in 1:nrow(transformacije)) {
trazi <- transformacije[i, 1]
zamijeni <- transformacije[i, 2]
if (endsWith(pojavnica, trazi)) {
return(sub(paste0(trazi, "$"), zamijeni, pojavnica))
}
}
return(pojavnica)
}
korjenuj <- function(pojavnica) {
for(pravilo in pravila) {
dioba <- stringr::str_match(pojavnica, pravilo)
if (!is.na(dioba[2])) {
if (imaSamoglasnik(dioba[2]) && nchar(dioba[2]) > 1) {
return(dioba[2])
}
}
}
return(pojavnica)
}
pravila <- lapply(strsplit(trimws(readLines('C:/Users/Lukas/Dropbox/Mislav@Luka/rules.txt')), ' '), function(x) paste0('^(', x[1], ')(', x[2], ')$'))
transformacije <- as.data.frame(do.call(rbind, strsplit(trimws(readLines('C:/Users/Lukas/Dropbox/Mislav@Luka/transformations.txt')), '\t')))
#text <- n_tokenTidy$word %>% head(1000)
#text <- tolower(readLines(input_file))
#tokens <- unlist(stringi::stri_extract_all_words(text))
write_tokens <- function(token) {
if (token %in% stop) {
return(paste0(token, '\t', token))
} else {
return(paste0(token, '\t', korjenuj(transformiraj(token))))
}
}
process_batch <- function(batch) {
batch[, transformed_column := sapply(strsplit(sapply(word, write_tokens), "\t"), `[`, 2)]
return(batch)
}
# Splitting data into batches
batch_size <- 1000  # Adjust this to the size you want
number_of_batches <- ceiling(nrow(LilaHR) / batch_size)
batched_data <- split(LilaHR, seq(1, nrow(LilaHR), by=batch_size))
# Applying the transformation on each batch and collecting results
result_list <- lapply(batched_data, process_batch)
setDT(LilaHR)
# Applying the transformation on each batch and collecting results
result_list <- lapply(batched_data, process_batch)
LilaHR[, transformed_column := sapply(strsplit(sapply(word, write_tokens), "\t"), `[`, 2)]
process_batch <- function(batch) {
batch[, transformed_column := sapply(strsplit(sapply(word, write_tokens), "\t"), `[`, 2)]
return(batch)
}
# Splitting data into batches
batch_size <- 1000  # Adjust this to the size you want
number_of_batches <- ceiling(nrow(LilaHR) / batch_size)
number_of_batches
batched_data <- split(LilaHR, seq(1, nrow(LilaHR), by=batch_size))
# Applying the transformation on each batch and collecting results
result_list <- lapply(batched_data, process_batch)
LilaHR
batch[, transformed_column := sapply(strsplit(sapply(HR, write_tokens), "\t"), `[`, 2)]
process_batch <- function(batch) {
batch[, transformed_column := sapply(strsplit(sapply(HR, write_tokens), "\t"), `[`, 2)]
return(batch)
}
# Splitting data into batches
batch_size <- 1000  # Adjust this to the size you want
number_of_batches <- ceiling(nrow(LilaHR) / batch_size)
batched_data <- split(LilaHR, seq(1, nrow(LilaHR), by=batch_size))
# Applying the transformation on each batch and collecting results
result_list <- lapply(batched_data, process_batch)
View(LilaHR)
LilaHR %>% rename("word" = "HR")
LilaHR <- LilaHR %>% rename("word" = "HR")
process_batch <- function(batch) {
batch[, transformed_column := sapply(strsplit(sapply(word, write_tokens), "\t"), `[`, 2)]
return(batch)
}
# Splitting data into batches
batch_size <- 1000  # Adjust this to the size you want
number_of_batches <- ceiling(nrow(LilaHR) / batch_size)
batched_data <- split(LilaHR, seq(1, nrow(LilaHR), by=batch_size))
# Applying the transformation on each batch and collecting results
result_list <- lapply(batched_data, process_batch)
LilaHR
proba <- LilaHR %>%
mutate(
word_korijen = sapply(word, function(x) {
result <- sapply(x, write_tokens)
extracted <- sapply(strsplit(result, "\t"), `[`, 2)
return(extracted)
})
)
proba <- LilaHR %>%
mutate(
results = map(word, write_tokens),
transformed_column = map_chr(results, ~ str_extract(.x, "(?<=\t)[^\t]+$"))
) %>%
select(-results)
# read in lexicons
CroSentilex_n <- read.delim("C:/Users/Lukas/Dropbox/Mislav@Luka/crosentilex-negatives.txt",
header = FALSE,
sep = " ",
stringsAsFactors = FALSE,
fileEncoding = "UTF-8")  %>%
rename(word = "V1", sentiment = "V2" ) %>%
mutate(brija = "NEG")
CroSentilex_p  <- read.delim("C:/Users/Lukas/Dropbox/Mislav@Luka/crosentilex-positives.txt",
header = FALSE,
sep = " ",
stringsAsFactors = FALSE,
fileEncoding = "UTF-8") %>%
rename(word = "V1", sentiment = "V2" ) %>%
mutate(brija = "POZ")
Crosentilex_sve <- rbind(setDT(CroSentilex_n), setDT(CroSentilex_p))
# check lexicon data
#head(sample_n(Crosentilex_sve,1000),15)
CroSentilex_Gold  <- read.delim2("C:/Users/Lukas/Dropbox/Mislav@Luka/gs-sentiment-annotations.txt",
header = FALSE,
sep = " ",
stringsAsFactors = FALSE) %>%
rename(word = "V1", sentiment = "V2" )
Encoding(CroSentilex_Gold$word) <- "UTF-8"
CroSentilex_Gold[1,1] <- "dati"
CroSentilex_Gold$sentiment <- str_replace(CroSentilex_Gold$sentiment , "-", "1")
CroSentilex_Gold$sentiment <- str_replace(CroSentilex_Gold$sentiment , "\\+", "2")
CroSentilex_Gold$sentiment <- as.numeric(unlist(CroSentilex_Gold$sentiment))
# check lexicon data
#head(sample_n(CroSentilex_Gold,100),15)
LilaHR  <- read_excel("C:/Users/Lukas/Dropbox/Mislav@Luka/lilaHR_.xlsx", sheet = "Sheet1")
proba <- read.csv2("C:/Users/Lukas/Dropbox/Mislav@Luka/lilaHRcsv.csv", encoding = "UTF-8")
#df <- separate_rows(LilaHR, HR, sep = ", ")
#
# zero_rows_count <- sum(apply(df[-1], 1, function(row) all(row == 0)))
# print(zero_rows_count)
#
# filtered_df <- df %>%
#   filter(!apply(.[,-1], 1, function(row) all(row == 0)))
#
# write.xlsx(filtered_df, "C:/Users/Lukas/Dropbox/Mislav@Luka/lilaHR_.xlsx" )
# create stop words
stopwords_cro <- get_stopwords(language = "hr", source = "stopwords-iso")
# check stopwords data
#head(sample_n(stopwords_cro,100),15)
# extend stop words
my_stop_words <- tibble(
word = c(
"jedan","mjera", "može", "možete", "mogu", "kad", "sada", "treba", "ima", "osoba",
"e","prvi", "dva","dvije","drugi",
"tri","treći","pet","kod",
"ove","ova",  "ovo","bez", "kod",
"evo","oko",  "om", "ek",
"mil","tko","šest", "sedam",
"osam",   "čim", "zbog",
"prema", "dok","zato", "koji",
"im", "čak","među", "tek",
"koliko", "tko","kod","poput",
"baš", "dakle", "osim", "svih",
"svoju", "odnosno", "gdje",
"kojoj", "ovi", "toga",
"ubera", "vozača", "hrvatskoj", "usluge", "godine", "više", "taksi", "taxi", "taksija", "taksija", "kaže", "rekao", "19"," aee", "ae","bit.ly", "https", "one", "the"
),
lexicon = "lux"
)
# full set with diacritics
cro_sw_full_d <- tibble(word = c("a","ako","ali","baš","bez","bi","bih","bila","bili","bilo","bio","bismo","bit","biti","bolje","bude","čak","čega","čemu","često","četiri","čime","čini","će","ćemo","ćete","ću","da","dakle","dalje","dan","dana","dana","danas","dio","do","dobro","dok","dosta","dva","dvije","eto","evo","ga","gdje","god","godina","godine","gotovo","grada","i","iako","ići","ih","ili","im","ima","imaju","imali","imam","imao","imati","inače","ipak","isto","iz","iza","između","ja","jako","je","jedan","jedna","jednog","jednom","jednostavno","jednu","jer","joj","još","ju","ka","kad","kada","kaj","kako","kao","kaže","kod","koja","koje","kojeg","kojeg","kojem","koji","kojih","kojim","kojima","kojoj","kojom","koju","koliko","kraju","kroz","li","malo","manje","me","među","međutim","mene","meni","mi","milijuna","mislim","mjesto","mnogo","mogao","mogli","mogu","moj","mora","možda","može","možemo","možete","mu","na","način","nad","naime","nakon","nam","naravno","nas","ne","neće","nego","neka","neke","neki","nekog","nekoliko","neku","nema","nešto","netko","ni","nije","nikad","nisam","nisu","ništa","niti","no","njih","o","od","odmah","odnosno","oko","on","ona","onda","oni","onih","ono","opet","osim","ova","ovaj","ovdje","ove","ovim","ovo","ovog","ovom","ovu","pa","pak","par","po","pod","poput","posto","postoji","pred","preko","prema","pri","prije","protiv","prvi","puno","put","radi","reći","s","sa","sad","sada","sam","samo","sati","se","sebe","si","smo","ste","stoga","strane","su","svaki","sve","svi","svih","svoj","svoje","svoju","što","ta","tada","taj","tako","također","tamo","te","tek","teško","ti","tih","tijekom","time","tko","to","tog","toga","toj","toliko","tom","tome","treba","tu","u","uopće","upravo","uvijek","uz","vam","vas","već","vi","više","vrijeme","vrlo","za","zapravo","zar","zato","zbog","zna","znači"),
lexicon = "boras")
stop_corpus <- my_stop_words %>%
bind_rows(stopwords_cro)
stop_corpus <- stop_corpus %>%
bind_rows(cro_sw_full_d)
# check stopwords data
#head(sample_n(stop_corpus,100),15)
# dim before tokenize
#dim(dta)
# tokenize
dta %>%
unnest_tokens(word, FULL_TEXT) -> n_token
# dim after tokenize
#dim(n_token)
# check
# fb_token %>%
#   select(FROM, word, MENTION_SNIPPET ) %>%
#     sample_n(.,100)
# remove stop words, numbers, single letters
n_token %>%
anti_join(stop_corpus, by = "word") %>%
mutate(word = gsub("\\d+", NA, word)) %>%
mutate(word = gsub("^[a-zA-Z]$", NA, word)) -> n_tokenTidy
# remove NA
n_tokenTidy %>%
filter(!is.na(word)) -> n_tokenTidy
# check
# fb_tokenTidy  %>%
#   select(FROM, word, MENTION_SNIPPET ) %>%
#   sample_n(.,100)
# dim after clean
#dim(n_tokenTidy)
proba <- n_tokenTidy %>% slice(1:500) %>%
mutate(
results = map(word, write_tokens),
transformed_column = map_chr(results, ~ str_extract(.x, "(?<=\t)[^\t]+$"))
) %>%
select(-results)
proba
LilaHR
LilaHR <- LilaHR %>% rename("word" = "HR")
LilaHR
proba <- LilaHR %>% slice(1:500) %>%
mutate(
results = map(word, write_tokens),
transformed_column = map_chr(results, ~ str_extract(.x, "(?<=\t)[^\t]+$"))
) %>%
select(-results)
proba
proba <- LilaHR %>% #slice(1:500) %>%
mutate(
results = map(word, write_tokens),
transformed_column = map_chr(results, ~ str_extract(.x, "(?<=\t)[^\t]+$"))
) %>%
select(-results)
View(LilaHR)
CroSentilex_Gold[1,1] <- "dati"
LilaHR  <- read_excel("C:/Users/Lukas/Dropbox/Mislav@Luka/lilaHR_.xlsx", sheet = "Sheet1") %>% filter(is.na)
LilaHR  <- read_excel("C:/Users/Lukas/Dropbox/Mislav@Luka/lilaHR_.xlsx", sheet = "Sheet1")
LilaHR <- LilaHR[complete.cases(LilaHR), ]
LilaHR <- LilaHR %>% rename("word" = "HR")
proba <- LilaHR %>% #slice(1:500) %>%
mutate(
results = map(word, write_tokens),
transformed_column = map_chr(results, ~ str_extract(.x, "(?<=\t)[^\t]+$"))
) %>%
select(-results)
View(proba)
