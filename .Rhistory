#  filter(datum > "2020-02-20") %>%
group_by(word) %>%
filter(n() > 200) %>%
filter(!is.na(word)) %>%
pairwise_cor(word,DATE, sort = T) -> corsWords
# articles over time
daily_counts <- dta %>%
group_by(DATE) %>%
summarise(count = n())
daily_counts
# descriptives
summ <- daily_counts %>%
summarize(min = min(count), max = max(count),
mean = mean(count), q1= quantile(count, probs = 0.25),
median = median(count), q3= quantile(count, probs = 0.75),
sd = sd(count)) %>%
mutate_if(is.numeric, round, digits=2)
summ
# create plot of articles over time
ggplot(data = daily_counts, aes(x = DATE, y = count)) +
geom_line() +
labs(x = "Date", y = "Number of Articles")
daily_counts
str(dta)
# date range
range(dta$DATE)
dta$DATE <- as.Date(dta$DATE)
str(dta)
# articles over time
daily_counts <- dta %>%
group_by(DATE) %>%
summarise(count = n())
# descriptives
summ <- daily_counts %>%
summarize(min = min(count), max = max(count),
mean = mean(count), q1= quantile(count, probs = 0.25),
median = median(count), q3= quantile(count, probs = 0.75),
sd = sd(count)) %>%
mutate_if(is.numeric, round, digits=2)
# create plot of articles over time
ggplot(data = daily_counts, aes(x = DATE, y = count)) +
geom_line() +
labs(x = "Date", y = "Number of Articles")
summ
daily_counts
# create plot of articles over time
ggplot(data = daily_counts, aes(x = DATE, y = count)) +
geom_line() +
labs(x = "Date", y = "Number of Articles")
# remove stop words, numbers, single letters
n_token %>%
anti_join(stop_corpus, by = "word") %>%
mutate(word = gsub("\\d+", NA, word)) %>%
mutate(word = gsub("^[a-zA-Z]$", NA, word)) -> n_tokenTidy
# remove NA
n_tokenTidy %>%
filter(!is.na(word)) -> n_tokenTidy
## Most common words
n_tokenTidy[,.N,by = word][order(-N),] %>%
datatable(., options = list(scrollX = TRUE, scrollY = "500px"))
n_tokenTidy %>%
group_by(word) %>%
summarise(N = n()) %>%
arrange(desc(N)) %>%
filter(N > 70)
n_tokenTidy %>%
group_by(word) %>%
summarise(N = n()) %>%
arrange(desc(N)) %>%
filter(N > 50) %>%
datatable(., options = list(scrollX = TRUE, scrollY = "500px"))
an_tokenTidy <- n_tokenTidy %>%
group_by(word, FROM) %>%
summarise(N = n()) %>%
arrange(desc(N)) %>%
filter(N > 70)
ggplot(an_tokenTidy, aes(reorder(word, N), N, fill = FROM)) +
geom_col(show.legend = FALSE) +
ggtitle( "") +
labs( x = "Riječ", y = "Number of words") +
facet_wrap(~ FROM, scales = "free_y") +
coord_flip() +
theme_economist()
ggplot(an_tokenTidy, aes(reorder(word, N), N, fill = FROM)) +
geom_col(show.legend = FALSE) +
ggtitle( "") +
labs( x = "Riječ", y = "Number of words") +
facet_wrap(~ FROM, scales = "free_y") +
coord_flip() +
theme_economist()
ggplot(an_tokenTidy, aes(reorder(word, N), N, fill = FROM)) +
geom_col(show.legend = FALSE) +
ggtitle( "") +
labs( x = "Riječ", y = "Number of words") +
facet_wrap(~ FROM, scales = "free_y") +
coord_flip() +
theme_economist()
n_tokenTidy %>%
group_by(word) %>%
summarise(N = n()) %>%
arrange(desc(N)) %>%
filter(N > 50) %>%
datatable(., options = list(scrollX = TRUE, scrollY = "500px"))
an_tokenTidy <- n_tokenTidy %>%
group_by(word, FROM) %>%
summarise(N = n()) %>%
arrange(desc(N)) %>%
filter(N > 70)
an_tokenTidy$FROM
unique(an_tokenTidy$FROM)
n_tokenTidy %>%
group_by(word) %>%
summarise(N = n()) %>%
arrange(desc(N)) %>%
filter(FROM == "jutarnji.hr")  %>%
filter(N > 50) %>%
datatable(., options = list(scrollX = TRUE, scrollY = "500px"))
n_tokenTidy %>%
filter(FROM == "jutarnji.hr") %>%
group_by(word) %>%
summarise(N = n()) %>%
arrange(desc(N))   %>%
filter(N > 50) %>%
datatable(., options = list(scrollX = TRUE, scrollY = "500px"))
n_tokenTidy %>%
filter(FROM == "jutarnji.hr") %>%
group_by(word) %>%
summarise(N = n()) %>%
arrange(desc(N))   %>%
filter(N > 10) %>%
datatable(., options = list(scrollX = TRUE, scrollY = "500px"))
## WordCloud(vulgaris)
fb_tokenTidy %>%
anti_join(CroSentilex_Gold,by="word") %>%
count(word) %>%
arrange(desc(n)) %>%
top_n(100) %>%
with(wordcloud(word, n, max.words = 80))
## WordCloud(vulgaris)
n_tokenTidy %>%
anti_join(CroSentilex_Gold,by="word") %>%
count(word) %>%
arrange(desc(n)) %>%
top_n(100) %>%
with(wordcloud(word, n, max.words = 80))
## WordCloud(vulgaris)
n_tokenTidy %>%
anti_join(CroSentilex_Gold,by="word") %>%
count(word) %>%
arrange(desc(n)) %>%
top_n(200) %>%
with(wordcloud(word, n, max.words = 80))
## Sentiment
doprinos_sentimentu <- function(dataset, no = n) {
dataset %>%
inner_join(CroSentilex_Gold, by = "word") %>%
count(word, sentiment,sort = TRUE) %>%
group_by(sentiment) %>%
top_n(no) %>%
ungroup() %>%
mutate(sentiment = case_when(sentiment == 0 ~ "NEUTRAL",
sentiment == 1 ~ "NEGATIVE",
sentiment == 2 ~ "POSITIVE")) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n, fill = sentiment)) +
geom_col(show.legend = FALSE) +
ggtitle( "Sentiment") +
labs( x = "Riječ", y = "Number of words") +
facet_wrap(~ sentiment, scales = "free_y") +
coord_flip() +
theme_economist() -> gg_doprinos_sentimentu
gg_doprinos_sentimentu
}
doprinos_sentimentu(n_tokenTidy,30)
## ComparisonCloud
n_tokenTidy %>%
inner_join(CroSentilex_Gold,by="word") %>%
count(word, sentiment) %>%
top_n(200) %>%
mutate(sentiment = case_when(sentiment == 0 ~ "+/-",
sentiment == 1 ~ "-",
sentiment == 2 ~ "+")) %>%
acast(word ~ sentiment, value.var = "n", fill = 0) %>%
comparison.cloud(colors = c("firebrick3", "deepskyblue3","darkslategray"),
max.words = 120)
n_tokenTidy %>%
group_by(word) %>%
summarise(N = n()) %>%
arrange(desc(N)) %>%
filter(N > 50) %>%
datatable(., options = list(scrollX = TRUE, scrollY = "500px"))
n_tokenTidy %>%
filter(FROM == "vecernji.hr") %>%
inner_join(CroSentilex_Gold,by="word") %>%
count(word, sentiment) %>%
top_n(200) %>%
mutate(sentiment = case_when(sentiment == 0 ~ "+/-",
sentiment == 1 ~ "-",
sentiment == 2 ~ "+")) %>%
acast(word ~ sentiment, value.var = "n", fill = 0) %>%
comparison.cloud(colors = c("firebrick3", "deepskyblue3","darkslategray"),
max.words = 120)
n_tokenTidy %>%
filter(FROM == "index.hr") %>%
inner_join(CroSentilex_Gold,by="word") %>%
count(word, sentiment) %>%
top_n(200) %>%
mutate(sentiment = case_when(sentiment == 0 ~ "+/-",
sentiment == 1 ~ "-",
sentiment == 2 ~ "+")) %>%
acast(word ~ sentiment, value.var = "n", fill = 0) %>%
comparison.cloud(colors = c("firebrick3", "deepskyblue3","darkslategray"),
max.words = 120)
n_tokenTidy %>%
filter(FROM == "tportal.hr") %>%
inner_join(CroSentilex_Gold,by="word") %>%
count(word, sentiment) %>%
top_n(200) %>%
mutate(sentiment = case_when(sentiment == 0 ~ "+/-",
sentiment == 1 ~ "-",
sentiment == 2 ~ "+")) %>%
acast(word ~ sentiment, value.var = "n", fill = 0) %>%
comparison.cloud(colors = c("firebrick3", "deepskyblue3","darkslategray"),
max.words = 120)
n_tokenTidy %>%
filter(FROM == "telegram.hr") %>%
inner_join(CroSentilex_Gold,by="word") %>%
count(word, sentiment) %>%
top_n(200) %>%
mutate(sentiment = case_when(sentiment == 0 ~ "+/-",
sentiment == 1 ~ "-",
sentiment == 2 ~ "+")) %>%
acast(word ~ sentiment, value.var = "n", fill = 0) %>%
comparison.cloud(colors = c("firebrick3", "deepskyblue3","darkslategray"),
max.words = 120)
n_tokenTidy %>%
filter(FROM == "index.hr") %>%
inner_join(CroSentilex_Gold,by="word") %>%
count(word, sentiment) %>%
top_n(200) %>%
mutate(sentiment = case_when(sentiment == 0 ~ "+/-",
sentiment == 1 ~ "-",
sentiment == 2 ~ "+")) %>%
acast(word ~ sentiment, value.var = "n", fill = 0) %>%
comparison.cloud(colors = c("firebrick3", "deepskyblue3","darkslategray"),
max.words = 120)
n_tokenTidy %>%
filter(FROM == "slobodnadalmacija.hr") %>%
inner_join(CroSentilex_Gold,by="word") %>%
count(word, sentiment) %>%
top_n(200) %>%
mutate(sentiment = case_when(sentiment == 0 ~ "+/-",
sentiment == 1 ~ "-",
sentiment == 2 ~ "+")) %>%
acast(word ~ sentiment, value.var = "n", fill = 0) %>%
comparison.cloud(colors = c("firebrick3", "deepskyblue3","darkslategray"),
max.words = 120)
## Udio riječi po domenama
domenaWords <- n_tokenTidy %>%
filter(FROM %in% c("vecernji.hr", "jutarnji.hr", "telegram.hr", "index.hr", "slobodnadalmacija.hr")) %>%
count(FROM, word, sort = T)
ukupnoWords <- domenaWords %>%
group_by(FROM) %>%
summarise(totWords = sum(n))
domenaWords <- left_join(domenaWords, ukupnoWords)
# domenaWords %>% head(15)
# domenaWords %>%
# ggplot(., aes(n/totWords, fill = domena)) +
#   geom_histogram(show.legend = FALSE) +
#   xlim(NA, 0.0009) +
#   facet_wrap(~domena, ncol = 2, scales = "free_y")
## Najbitnije riječi po domenma
idf <- domenaWords %>%
bind_tf_idf(word, FROM, n)
#idf %>% head(10)
# idf %>%
#   select(-totWords) %>%
#   arrange(desc(tf_idf))
idf %>%
arrange(desc(tf_idf)) %>%
mutate(word = factor(word, levels = rev(unique(word)))) %>%
mutate(FROM = factor(FROM)) %>%
group_by(FROM) %>%
top_n(20) %>%
ungroup() %>%
ggplot(aes(word, tf_idf, fill = FROM)) +
geom_col(show.legend = FALSE) +
labs(x = NULL, y = "tf-idf") +
facet_wrap(~FROM, ncol = 2, scales = "free") +
coord_flip() +
theme_economist()
fb_bigram <- dta %>%
unnest_tokens(bigram, FULL_TEXT, token = "ngrams", n = 2)
#fb_bigram %>% head(10)
# fb_bigram %>%
#   count(bigram, sort = T) %>%
#   head(25)
fb_bigram_sep <- fb_bigram %>%
separate(bigram, c("word1","word2"), sep = " ")
#fb_bigram %>% head(10)
# fb_bigram %>%
#   count(bigram, sort = T) %>%
#   head(25)
fb_bigram_sep <- fb_bigram %>%
separate(bigram, c("word1","word2"), sep = " ")
fb_bigram_tidy <- fb_bigram_sep %>%
filter(!word1 %in% stop_corpus$word) %>%
filter(!word2 %in% stop_corpus$word) %>%
mutate(word1 = gsub("\\d+", NA, word1)) %>%
mutate(word2 = gsub("\\d+", NA, word2)) %>%
mutate(word1 = gsub("^[a-zA-Z]$", NA, word1)) %>%
mutate(word2 = gsub("^[a-zA-Z]$", NA, word2))
fb_bigram_tidy_bigram_counts <- fb_bigram_tidy %>%
count(word1, word2, sort = TRUE)
bigrams_united <- fb_bigram_tidy %>%
unite(bigram, word1, word2, sep = " ") %>%
filter(., !grepl("NA",bigram))
#bigrams_united
bigrams_united %>%
count(FROM,bigram,sort = T) -> topicBigram
#bigrams_united
bigrams_united %>%
count(FROM,bigram,sort = T) -> topicBigram
bigrams_united %>%
count(bigram, sort = T) %>%
filter(n>10)
# Najvažniji bigrami po domenama
bigram_tf_idf <- bigrams_united %>%
#  filter (!is.na(bigram)) %>%
count(FROM, bigram) %>%
bind_tf_idf(bigram, FROM, n) %>%
arrange(desc(tf_idf))
bigram_tf_idf %>%
arrange(desc(tf_idf)) %>%
filter(tf_idf > 0.09) %>%
mutate(bigram = factor(bigram, levels = rev(unique(bigram)))) %>%
#  group_by(FROM) %>%
#  top_n(20) %>%
ungroup() %>%
ggplot(aes(bigram, tf_idf, fill = FROM)) +
geom_col(show.legend = FALSE) +
labs(x = NULL, y = "tf-idf") +
#  facet_wrap(~FROM, ncol = 2, scales = "free") +
coord_flip() +
theme_economist()
n_tokenTidy %>%
count(FROM, word, sort = TRUE) %>%
cast_dtm(FROM, word,n) -> dtm
fb_LDA <- LDA(dtm, k = 4,  control = list(seed = 1234))
fb_LDA <- LDA(dtm, k = 4,  control = list(seed = 1234))
fb_LDA_tidy <- tidy(fb_LDA, matrix = "beta")
#newsCOVID_LDA_tidy
insta_terms <- fb_LDA_tidy %>%
drop_na(.) %>%
group_by(topic) %>%
top_n(15, beta) %>%
ungroup() %>%
arrange(topic, -beta)
#newsCOVID_terms
insta_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(term, beta, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
coord_flip() +
scale_x_reordered() +
theme_economist()
fb_tokenTidy %>%
#  filter(datum > "2020-02-20") %>%
group_by(word) %>%
filter(n() > 200) %>%
filter(!is.na(word)) %>%
pairwise_cor(word,DATE, sort = T) -> corsWords
n_tokenTidy %>%
#  filter(datum > "2020-02-20") %>%
group_by(word) %>%
filter(n() > 200) %>%
filter(!is.na(word)) %>%
pairwise_cor(word,DATE, sort = T) -> corsWords
#corsWords %>%
#  filter(item1 == "oporavak")
corsWords %>%
filter(item1 %in% c("rizik", "problem", "bolest")) %>%
group_by(item1) %>%
top_n(10) %>%
ungroup() %>%
mutate(item2 = reorder(item2, correlation)) %>%
ggplot(aes(item2, correlation)) +
geom_bar(stat = "identity") +
facet_wrap(~ item1, scales = "free") +
coord_flip() +
theme_economist()
corsWords %>%
filter(item1 %in% c("rizik", "problem", "bolest")) %>%
group_by(item1) %>%
top_n(10)
corsWords
corsWords %>%
filter(item1 %in% c("rizik", "problem", "bolest"))
corsWords
#corsWords %>%
#  filter(item1 == "oporavak")
corsWords %>%
filter(item1 %in% c("rizik")) %>%
group_by(item1) %>%
top_n(10) %>%
ungroup() %>%
mutate(item2 = reorder(item2, correlation)) %>%
ggplot(aes(item2, correlation)) +
geom_bar(stat = "identity") +
facet_wrap(~ item1, scales = "free") +
coord_flip() +
theme_economist()
corsWords %>%
filter(item1 %in% c("rizik")) %>%
group_by(item1) %>%
top_n(10) %>%
ungroup() %>%
mutate(item2 = reorder(item2, correlation))
corsWords %>%
filter(item1 %in% c("rizik"))
corsWords
#corsWords %>%
#  filter(item1 == "oporavak")
corsWords %>%
filter(item1 %in% c("oglasa")) %>%
group_by(item1) %>%
top_n(10) %>%
ungroup() %>%
mutate(item2 = reorder(item2, correlation)) %>%
ggplot(aes(item2, correlation)) +
geom_bar(stat = "identity") +
facet_wrap(~ item1, scales = "free") +
coord_flip() +
theme_economist()
#corsWords %>%
#  filter(item1 == "oporavak")
corsWords %>%
filter(item1 %in% c("bolest")) %>%
group_by(item1) %>%
top_n(10) %>%
ungroup() %>%
mutate(item2 = reorder(item2, correlation)) %>%
ggplot(aes(item2, correlation)) +
geom_bar(stat = "identity") +
facet_wrap(~ item1, scales = "free") +
coord_flip() +
theme_economist()
n_tokenTidy %>%
#  filter(datum > "2020-02-20") %>%
group_by(word) %>%
filter(n() > 50) %>%
filter(!is.na(word)) %>%
pairwise_cor(word,DATE, sort = T) -> corsWords
#corsWords %>%
#  filter(item1 == "oporavak")
corsWords %>%
filter(item1 %in% c("bolest")) %>%
group_by(item1) %>%
top_n(10) %>%
ungroup() %>%
mutate(item2 = reorder(item2, correlation)) %>%
ggplot(aes(item2, correlation)) +
geom_bar(stat = "identity") +
facet_wrap(~ item1, scales = "free") +
coord_flip() +
theme_economist()
#corsWords %>%
#  filter(item1 == "oporavak")
corsWords %>%
filter(item1 %in% c("bolest", "rizik")) %>%
group_by(item1) %>%
top_n(10) %>%
ungroup() %>%
mutate(item2 = reorder(item2, correlation)) %>%
ggplot(aes(item2, correlation)) +
geom_bar(stat = "identity") +
facet_wrap(~ item1, scales = "free") +
coord_flip() +
theme_economist()
#corsWords %>%
#  filter(item1 == "oporavak")
corsWords %>%
filter(item1 %in% c("bolest", "rizik", "strah")) %>%
group_by(item1) %>%
top_n(10) %>%
ungroup() %>%
mutate(item2 = reorder(item2, correlation)) %>%
ggplot(aes(item2, correlation)) +
geom_bar(stat = "identity") +
facet_wrap(~ item1, scales = "free") +
coord_flip() +
theme_economist()
n_tokenTidy %>%
#  filter(datum > "2020-02-20") %>%
group_by(word) %>%
filter(n() > 20) %>%
filter(!is.na(word)) %>%
pairwise_cor(word,DATE, sort = T) -> corsWords
#corsWords %>%
#  filter(item1 == "oporavak")
corsWords %>%
filter(item1 %in% c("bolest", "rizik", "strah")) %>%
group_by(item1) %>%
top_n(10) %>%
ungroup() %>%
mutate(item2 = reorder(item2, correlation)) %>%
ggplot(aes(item2, correlation)) +
geom_bar(stat = "identity") +
facet_wrap(~ item1, scales = "free") +
coord_flip() +
theme_economist()
