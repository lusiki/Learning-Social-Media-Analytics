subtitle = "Cjelokupni medijski prostor u razdoblju 6 mj",
caption = "Izvor: Mediatoolkit | Izradio: Lukos") +
geom_bar(stat = "identity") +
facet_wrap(~SOURCE_TYPE, scales = "free") +
coord_flip() +
guides(fill=FALSE) +
theme_bw() + theme( strip.background  = element_blank(),
panel.grid.major = element_blank(),
panel.border = element_blank(),
axis.ticks = element_blank(),
panel.grid.minor.y = element_blank(),
panel.grid.major.y = element_blank(),
text=element_text(size=16,  family="serif")) +
theme(legend.position="bottom") +
scale_fill_brewer(palette="Set2")
ggplot(activePerDay, aes(x = INTERDAYTIME, y = AVG, fill = INTERDAYTIME, width=0.75)) +
labs(y = "Broj objava ", x = "", title = "Aktivnost na online društvenim medijima U RH",
subtitle = "Cjelokupni medijski prostor u razdoblju 6 mj",
caption = "Izvor: Mediatoolkit | Izradio: Lukos") +
geom_bar(stat = "identity") +
facet_wrap(~SOURCE_TYPE, scales = "free") +
coord_flip() +
guides(fill=FALSE) +
theme_bw() + theme( strip.background  = element_blank(),
panel.grid.major = element_blank(),
panel.border = element_blank(),
axis.ticks = element_blank(),
panel.grid.minor.y = element_blank(),
panel.grid.major.y = element_blank(),
text=element_text(size=16,  family="Roboto")) +
theme(legend.position="bottom") +
scale_fill_brewer(palette="Set2")
ggplot(activePerDay, aes(x = INTERDAYTIME, y = AVG, fill = INTERDAYTIME, width=0.75)) +
labs(y = "Broj objava ", x = "", title = "Aktivnost na online društvenim medijima U RH",
subtitle = "Cjelokupni medijski prostor u razdoblju 6 mj",
caption = "Izvor: Mediatoolkit | Izradio: Lukos") +
geom_bar(stat = "identity") +
facet_wrap(~SOURCE_TYPE, scales = "free") +
coord_flip() +
guides(fill=FALSE) +
theme_bw() + theme( strip.background  = element_blank(),
panel.grid.major = element_blank(),
panel.border = element_blank(),
axis.ticks = element_blank(),
panel.grid.minor.y = element_blank(),
panel.grid.major.y = element_blank(),
text=element_text(size=5,  family="Roboto")) +
theme(legend.position="bottom") +
scale_fill_brewer(palette="Set2")
ggplot(activePerDay, aes(x = INTERDAYTIME, y = AVG, fill = INTERDAYTIME, width=0.75)) +
labs(y = "Broj objava ", x = "", title = "Aktivnost na online društvenim medijima U RH",
subtitle = "Cjelokupni medijski prostor u razdoblju 6 mj",
caption = "Izvor: Mediatoolkit | Izradio: Lukos") +
geom_bar(stat = "identity") +
facet_wrap(~SOURCE_TYPE, scales = "free") +
coord_flip() +
guides(fill=FALSE) +
theme_bw() + theme( strip.background  = element_blank(),
panel.grid.major = element_blank(),
panel.border = element_blank(),
axis.ticks = element_blank(),
panel.grid.minor.y = element_blank(),
panel.grid.major.y = element_blank(),
text=element_text(size=9,  family="Roboto")) +
theme(legend.position="bottom") +
scale_fill_brewer(palette="Set2")
ggplot(activePerDay, aes(x = INTERDAYTIME, y = AVG, fill = INTERDAYTIME, width=0.75)) +
labs(y = "Broj objava ", x = "", title = "Aktivnost na online društvenim medijima U RH",
subtitle = "Cjelokupni medijski prostor u razdoblju 6 mj",
caption = "Izvor: Mediatoolkit | Izradio: Lukos") +
geom_bar(stat = "identity") +
facet_wrap(~SOURCE_TYPE, scales = "free") +
coord_flip() +
guides(fill=FALSE) +
theme_bw() + theme( strip.background  = element_blank(),
panel.grid.major = element_blank(),
panel.border = element_blank(),
axis.ticks = element_blank(),
panel.grid.minor.y = element_blank(),
panel.grid.major.y = element_blank(),
panel.grid.minor.x = element_blank(),
panel.grid.major.x = element_blank(),
text=element_text(size=9,  family="Roboto")) +
theme(legend.position="bottom") +
scale_fill_brewer(palette="Set2")
ggplot(activePerDay, aes(x = INTERDAYTIME, y = AVG, fill = INTERDAYTIME, width=0.75)) +
labs(y = "Broj objava ", x = "", title = "Aktivnost na online društvenim medijima U RH",
subtitle = "Cjelokupni medijski prostor u razdoblju 6 mj",
caption = "Izvor: Mediatoolkit | Izradio: Lukos") +
geom_bar(stat = "identity") +
facet_wrap(~SOURCE_TYPE, scales = "free") +
coord_flip() +
guides(fill=FALSE) +
theme_bw() + theme( strip.background  = element_blank(),
panel.grid.major = element_blank(),
panel.border = element_blank(),
axis.ticks = element_blank(),
panel.grid.minor.y = element_blank(),
panel.grid.major.y = element_blank(),
panel.grid.minor.x = element_blank(),
panel.grid.major.x = element_blank(),
text=element_text(size=9,  family="Roboto")) +
theme(legend.position="bottom") +
scale_fill_brewer(palette="Set2") +
scale_fill_grey(start=0,end =0.8)
ggplot(activePerDay, aes(x = INTERDAYTIME, y = AVG, fill = INTERDAYTIME, width=0.75)) +
labs(y = "Broj objava ", x = "", title = "Aktivnost na online društvenim medijima U RH",
subtitle = "Dnevni prosjek za cjelokupni medijski prostor u razdoblju 6 mj",
caption = "Izvor: Mediatoolkit | Izradio: Lukos") +
geom_bar(stat = "identity") +
facet_wrap(~SOURCE_TYPE, scales = "free") +
coord_flip() +
guides(fill=FALSE) +
theme_bw() + theme( strip.background  = element_blank(),
panel.grid.major = element_blank(),
panel.border = element_blank(),
axis.ticks = element_blank(),
panel.grid.minor.y = element_blank(),
panel.grid.major.y = element_blank(),
panel.grid.minor.x = element_blank(),
panel.grid.major.x = element_blank(),
text=element_text(size=9,  family="Roboto")) +
theme(legend.position="bottom") +
scale_fill_brewer(palette="Set2") +
scale_fill_grey(start=0,end =0.8)
library(gdeltr2)
devtools::install_github("abresler/gdeltr2")
library(gdeltr2)
df_gkg <-
get_gdelt_codebook_ft_api(code_book = "gkg")
df_gkg <-
get_gdelt_codebook_ft_api(code_book = "gkg")
df_gkg <-
gdeltr2::get_gdelt_codebook_ft_api(code_book = "gkg")
df_gkg <- gdeltr2::get_gdelt_codebook_ft_api(code_book = "gkg")
my_themes <-
c("ECON_WORLDCURRENCIES_CHINESE_YUAN", # stories about china's currency -- god way to find stories about china's economy
"ECON_BUBBLE", # articles about economic bubble
"TAX_FNCACT_BROKER", # articles about brokers of things
"ECON_HOUSING_PRICES", # articls about housing prices
"ECON_BITCOIN", # articles about bitcoin
"ELECTION_FRAUD", # articles about election fraud
"SOC_POINTSOFINTEREST_GOVERNMENT_BUILDINGS", # articles about government buildings
"WB_1277_BANKRUPTCY_AND_LIQUIDATION", # articles about bankruptcy
"WB_639_REPRODUCTIVE_MATERNAL_AND_CHILD_HEALTH", # articles about pregnancy and child health
"WB_2151_CHILD_DEVELOPMENT", # articles about child development
"TAX_FNCACT_BUILDER" # articles about builders
)
random_themes <-
df_gkg %>% pull(idGKGTheme) %>% sample(3)
df_imagetags <-
get_gdelt_codebook_ft_api(code_book = "imagetags")
df_countries <-
get_gdelt_codebook_ft_api(code_book = "countries")
knitr::opts_chunk$set(echo = T, message = F, warning = F)
library(tidyverse)
library(readxl)
library(here)
library(kableExtra)
library(DT)
library(data.table)
library(lubridate)
library(anytime)
library(tidytext)
library(grid)
library(wordcloud)
library(reshape2)
library(ggraph)
library(widyr)
library(topicmodels)
library(ggthemes)
library(reportMD)
library(anytime)
library(scales)
# read in data
path <- "D:/LUKA/Freelance/Mediatoolkit/FULLtxtDATA"
raw <- list.files(path = path , pattern="xlsx")
raw_path <- paste0(path, "/", raw)
all_raw <- map_df(raw_path, read_excel)
all <- as.data.table(all_raw)
all <- all[,DATE := as.Date(DATE,"%Y-%m-%d")][,DATETIME := anytime(paste(DATE,TIME))]
posts <- all[!duplicated(all),]
rm(all,all_raw)
knitr::opts_chunk$set(echo = T, message = F, warning = F)
# how much activity
posts[SOURCE_TYPE == "web", .N]
# how much activity
posts[SOURCE_TYPE == "web", .N]
# how many authors
posts[SOURCE_TYPE == "web", length(unique(posts$AUTHOR))]
# how many domains?
posts[SOURCE_TYPE == "web", length(unique(posts$FROM))]
# how many domains?
posts[SOURCE_TYPE == "web",
.(Number = length(unique(FROM)))]
# how many CRO domains?
posts[SOURCE_TYPE == "web" & grepl(".hr", unique(posts$FROM)),
.(Number = length(unique(FROM)))]
web <- posts[SOURCE_TYPE == "web",]
web[str_detect(web$FROM, ".hr"),.N,
FROM][order(-N),] %>%
datatable(., rownames = FALSE, options = list(pageLength = 5, scrollX=T))
knitr::opts_chunk$set(echo = T, message = F, warning = F)
library(tidyverse)
library(readxl)
library(here)
library(kableExtra)
library(DT)
library(data.table)
library(lubridate)
library(anytime)
library(tidytext)
library(grid)
library(wordcloud)
library(reshape2)
library(ggraph)
library(widyr)
library(topicmodels)
library(ggthemes)
library(reportMD)
library(anytime)
library(scales)
# read in data
path <- "D:/LUKA/Freelance/Mediatoolkit/FULLtxtDATA"
raw <- list.files(path = path , pattern="xlsx")
raw_path <- paste0(path, "/", raw)
all_raw <- map_df(raw_path, read_excel)
all <- as.data.table(all_raw)
all <- all[,DATE := as.Date(DATE,"%Y-%m-%d")][,DATETIME := anytime(paste(DATE,TIME))]
posts <- all[!duplicated(all),]
rm(all,all_raw)
# select media
forum <- posts[SOURCE_TYPE == "forum",]
posts <- as.data.table(posts)
posts %>%
group_by(SOURCE_TYPE) %>%
mutate(UkBrojObjava = n()) %>%
group_by(DATE, INTERDAYTIME, SOURCE_TYPE) %>%
mutate(PerDay = n()) %>%
ungroup() %>%
group_by(INTERDAYTIME,SOURCE_TYPE) %>%
summarise(AVG = mean(PerDay)) %>%
filter(SOURCE_TYPE != "comment") %>%
arrange(desc(AVG)) -> activePerDay
forum[,.N, TITLE][order(-N)] %>% head(50)
forum[,.N, TITLE][order(-N)] %>% head(50)
knitr::opts_chunk$set(echo = T, message = F, warning = F)
forum <- c("Zoran Milanović, predsjednik Republike Hrvatske vol. IV", "Andrej Plenković - predsjednik HDZ-a i predsjednik Vlade RH IV"
forum <- forum[TITLE %in% forum,]
forum <- forum[TITLE %in% forum]
forum[TITLE == "Zoran Milanović, predsjednik Republike Hrvatske vol. IV",]
zm <- forum[TITLE == "Zoran Milanović, predsjednik Republike Hrvatske vol. IV",]
ap <- forum[TITLE == "Andrej Plenković - predsjednik HDZ-a i predsjednik Vlade RH IV",]
write_csv2(zm, "D:/LUKA/Freelance/Mediatoolkit/forumZM.csv")
write_csv2(ap, "D:/LUKA/Freelance/Mediatoolkit/forumAP.csv")
knitr::opts_chunk$set(echo = F, message = F, warning = F)
# read data in (one day worth of data)
one_day_sample <- read_excel(here::here("data/Mediatoolkit/sample.xlsx"))
library(tidyverse)
library(readxl)
library(here)
library(kableExtra)
library(DT)
# read data in (one day worth of data)
one_day_sample <- read_excel(here::here("data/Mediatoolkit/sample.xlsx"))
# size of the data
dim(one_day_sample)
# sneek peak
glimpse(one_day_sample[sample(nrow(one_day_sample)),1:35])
install.packages("pandoc")
install.packages("Rtools")
library(installr)
library(installr)
install.packages("installr")
install.packages(devtools)
install.packages("devtools")
install.packages("Rtools")
install.packages("Rtools")
R.version
install.packages("devtools")
install.packages("pandoc")
rmarkdown::pandoc_version(); packageVersion("knitr")
options(htmltools.dir.version = FALSE)
# read data in (full data sample)
path <- "D:/LUKA/Freelance/Mediatoolkit/FULLDATA"
raw <- list.files(path = path , pattern="xlsx")
raw_path <- paste0(path, "/", raw)
all_raw <- map_df(raw_path, read_excel)
library(tidyverse)
library(readxl)
library(here)
library(kableExtra)
library(DT)
all_raw <- map_df(raw_path, read_excel)
library(purrr)
raw_files <- list.files(path = path , pattern="xlsx", full.names = TRUE)
all_raw <- map_dfr(raw_files, read_excel)
all_raw_ <- map_dfr(raw_files, fread)
library(data.table)
all_raw_ <- map_dfr(raw_files, fread)
names(all_raw)
all_raw[1:5,]
all_raw[1:5,] %>% View()
fullDtaNoTxt <- all_raw[,-c("MENTION_SNIPPET")]
fullDtaNoTxt <- all_raw[,-c(MENTION_SNIPPET)]
fullDtaNoTxt <- all_raw[,-MENTION_SNIPPET]
all_raw[1:5,] %>% View()
fullDtaNoTxt <- all_raw[,-17]
fullDtaNoTxtnot found[1:5,] %>% View()
fullDtaNoTxt[1:5,] %>% View()
write.csv2(fullDtaNoTxt, "D:/LUKA/Freelance/Mediatoolkit/FULLDATA_NOTXT")
fullDtaNoTxt <- as.data.table(fullDtaNoTxt)
dt_unique <- unique(fullDtaNoTxt)
write.csv2(dt_unique, "D:/LUKA/Freelance/Mediatoolkit/FULLDATA_NOTXT.csv")
fullDtaTxt <- as.data.table(all_raw)
dt_unique <- unique(fullDtaTxt)
dt_unique <- unique(fullDtaTxt)
write.csv2(dt_unique, "D:/LUKA/Freelance/Mediatoolkit/FULLDATA_NOTXT.csv
write.csv2(dt_unique, "D:/LUKA/Freelance/Mediatoolkit/FULLDATA_TXT.csv")
fullDta <- fread("D:/LUKA/Freelance/Mediatoolkit/FULLDATA_NOTXT.csv")
rm(list=ls())
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
library(here)
library(kableExtra)
library(DT)
library(purrr)
library(data.table)
fullDta <- fread("D:/LUKA/Freelance/Mediatoolkit/FULLDATA_NOTXT.csv")
View(fullDta)
fullDta[1:10,]
names(fullDta)
fullDtaTxt <- fread("D:/LUKA/Freelance/Mediatoolkit/FULLDATA_TXT.csv")
rm(fullDta)
library(tidytext)
install.packages()
install.packages("tidytext")
library(tidytext)
library(dplyr)
library(purrr)
small <- fullDtaTxt[1:100,]
names(small)
View(small)
fullDtaTxt[1,MENTION_SNIPPET]
fullDtaTxt[1,MENTION_SNIPPET]
small %>%
fullDtaTxt[1,MENTION_SNIPPET]
small %>%
unnest_tokens(MENTION_SNIPPET, input_col_name, token = "word")
small %>%
unnest_tokens(MENTION_SNIPPET, token = "words")
small %>%
unnest_tokens(word,MENTION_SNIPPET, token = "words")
fullDtaTxt[,MENTION_SNIPPET]
names(fullDtaTxt)
View(fullDtaTxt)
names(fullDtaTxt)
path <- "D:/LUKA/Freelance/Mediatoolkit/FULLtxtDATA"
raw <- list.files(path = path , pattern="xlsx")
raw_path <- paste0(path, "/", raw)
all_raw <- map_df(raw_path, fread)
all_raw <- map_df(raw_path, read_excel)
raw
raw_path <- paste0(path, "/", raw[1])
raw_path
all_raw <- map_df(raw_path, read_excel)
View(all_raw)
path <- "D:/LUKA/Freelance/Mediatoolkit/FULLtxtDATA"
raw <- list.files(path = path , pattern="xlsx")
raw_path <- paste0(path, "/", raw)
rm(list=ls())
path <- "D:/LUKA/Freelance/Mediatoolkit/FULLtxtDATA"
raw <- list.files(path = path , pattern="xlsx")
raw_path <- paste0(path, "/", raw)
all_raw <- map_df(raw_path, read_excel)
dt <- distinct(all_raw)
rm(all_raw)
write.csv(dt, file = "D:/LUKA/Freelance/Mediatoolkit/MktFULLtxt.csv", row.names = T)
chunk_size <- 100
chunks <- split(dt, ceiling(row_number(dt) / chunk_size))
chunks
tokenize_chunk <- function(chunk) {
chunk %>%
unnest_tokens(word, FULL_TEXT, token = "words")
}
tokenized_chunks <- map(chunks, tokenize_chunk)
ceiling(row_number(dt))
chunk_size <- 100
chunks <- split(dt, ceiling(row_number(dt) / chunk_size))
tokenize_chunk <- function(chunk) {
chunk %>%
unnest_tokens(word, FULL_TEXT, token = "words")
}
chunks
tokenize_chunk <- function(chunk) {
chunk %>%
unnest_tokens(word, FULL_TEXT, token = "words")
}
tokenized_chunks <- map(chunks, tokenize_chunk)
df_tokenized <- bind_rows(tokenized_chunks)
dt[1:100,]
dt[1:100,] %>%
unnest_tokens(word, FULL_TEXT, token = "words")
chunk_size <- 10
chunks <- split(dt[1:100,], ceiling(row_number(dt) / chunk_size))
chunks <- split(dt[1:100,], ceiling(row_number(dt[1:100,]) / chunk_size))
chunks <- split(dt[1:100,], ceiling(nrow(dt[1:100,]) / chunk_size))
tokenize_chunk <- function(chunk) {
chunk %>%
unnest_tokens(word, FULL_TEXT, token = "words")
}
tokenized_chunks <- map(chunks, tokenize_chunk)
df_tokenized <- bind_rows(tokenized_chunks)
chunks <- split(dt[1:1000,], ceiling(nrow(dt[1:1000,]) / chunk_size))
chunks <- split(dt[1:1000,], ceiling(nrow(dt[1:1000,]) / chunk_size))
tokenize_chunk <- function(chunk) {
chunk %>%
unnest_tokens(word, FULL_TEXT, token = "words")
}
tokenized_chunks <- map(chunks, tokenize_chunk)
View(tokenized_chunks)
View(tokenized_chunks[["100"]])
chunk_size <- 100
chunks <- split(dt, ceiling(nrow(dt) / chunk_size))
chunks <- split(dt, ceiling(nrow(dt) / chunk_size))
tokenize_chunk <- function(chunk) {
chunk %>%
unnest_tokens(word, FULL_TEXT, token = "words")
}
tokenized_chunks <- map(chunks, tokenize_chunk)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
library(here)
library(kableExtra)
library(DT)
library(purrr)
library(data.table)
library(tidytext)
library(dplyr)
library(purrr)
# fullDta <- fread("D:/LUKA/Freelance/Mediatoolkit/FULLDATA_NOTXT.csv")
# fullDtaTxt <- fread("D:/LUKA/Freelance/Mediatoolkit/FULLDATA_TXT.csv")
dt <- fread("D:/LUKA/Freelance/Mediatoolkit/MktFULLtxt.csv")
chunk_size <- 100
chunks <- split(dt, ceiling(nrow(dt) / chunk_size))
View(chunks)
df <- data.frame(
name = c("Alice", "Bob", "Charlie", "David", "Eva"),
gender = c("female", "male", "male", "male", "female"),
age = c(25, 30, 45, 27, 22)
)
split(df,df$gender)
chunks
chunks <- split(dt, 100)
chunks
rm(chunks)
rm(df)
str(dt)
dt[1:100,]
batch_size <- 1000
n_batches <- ceiling(nrow(data) / batch_size)
n_batches <- ceiling(nrow(dt) / batch_size)
tokenized_data <- map_dfr(seq_len(n_batches), function(batch) {
start_row <- (batch - 1) * batch_size + 1
end_row <- min(batch * batch_size, nrow(dt))
chunk <- dt[start_row:end_row, ]
tokenize_chunk(chunk)
})
tokenize_chunk <- function(chunk) {
chunk %>%
unnest_tokens(word, FULL_TEXT, token = "words")
}
tokenized_data <- map_dfr(seq_len(n_batches), function(batch) {
start_row <- (batch - 1) * batch_size + 1
end_row <- min(batch * batch_size, nrow(dt))
chunk <- dt[start_row:end_row, ]
tokenize_chunk(chunk)
})
proba <- dt[1:100000,] %>%
unnest_tokens(word, FULL_TEXT, token = "words")
proba <- dt[1:300000,] %>%
unnest_tokens(word, FULL_TEXT, token = "words")
rm(proba)
rm(dt)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
library(here)
library(kableExtra)
library(DT)
library(purrr)
library(data.table)
library(tidytext)
library(dplyr)
library(purrr)
n <- nrow(dt)
chunk_size <- n %/% 20
chunks <- split(dt, rep(1:20, each = chunk_size, length.out = n))
# fullDta <- fread("D:/LUKA/Freelance/Mediatoolkit/FULLDATA_NOTXT.csv")
# fullDtaTxt <- fread("D:/LUKA/Freelance/Mediatoolkit/FULLDATA_TXT.csv")
dt <- fread("D:/LUKA/Freelance/Mediatoolkit/MktFULLtxt.csv")
n <- nrow(dt)
chunk_size <- n %/% 20
chunks <- split(dt, rep(1:20, each = chunk_size, length.out = n))
for (i in 1:10) {
fwrite(chunks[[i]], file = paste0("D:/LUKA/Freelance/Mediatoolkit/chunk_", i, ".csv"))
}
for (i in 1:20) {
fwrite(chunks[[i]], file = paste0("D:/LUKA/Freelance/Mediatoolkit/chunk_", i, ".csv"))
}
