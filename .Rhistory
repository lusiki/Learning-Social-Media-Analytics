n_tokenTidy %>%
filter(FROM == "tportal.hr") %>%
inner_join(CroSentilex_Gold,by="word") %>%
count(word, sentiment) %>%
top_n(200) %>%
mutate(sentiment = case_when(sentiment == 0 ~ "+/-",
sentiment == 1 ~ "-",
sentiment == 2 ~ "+")) %>%
acast(word ~ sentiment, value.var = "n", fill = 0) %>%
comparison.cloud(colors = c("firebrick3", "deepskyblue3","darkslategray"),
max.words = 120)
## Negative profiles
wCount <- n_tokenTidy %>%
group_by(FROM) %>%
summarise(word = n())
CroSentilex_Gold_neg <- CroSentilex_Gold %>% filter(sentiment == 1)
CroSentilex_Gold_poz <- CroSentilex_Gold %>% filter(sentiment == 2)
n_tokenTidy %>%
semi_join(CroSentilex_Gold_neg, by= "word") %>%
group_by(FROM) %>%
summarise(negWords = n()) %>%
left_join(wCount, by = "FROM") %>%
mutate(negativnostIndex = (negWords/word)*100) %>%
arrange(desc(negativnostIndex)) %>%
select(FROM, negativnostIndex)  %>%
datatable(., options = list(scrollX = TRUE, scrollY = "500px"))
## Najpozitivniji portali
CroSentilex_Gold_poz <- CroSentilex_Gold %>% filter(sentiment == 2)
n_tokenTidy %>%
semi_join(CroSentilex_Gold_poz, by= "word") %>%
group_by(FROM) %>%
summarise(pozWords = n()) %>%
left_join(wCount, by = "FROM") %>%
mutate(pozitivnostIndex = (pozWords/word)*100) %>%
arrange(desc(pozitivnostIndex)) %>%
select(FROM, pozitivnostIndex)  %>%
datatable(., options = list(scrollX = TRUE, scrollY = "500px"))
## Udio riječi po domenama
domenaWords <- n_tokenTidy %>%
filter(FROM %in% c("vecernji.hr", "jutarnji.hr", "telegram.hr", "index.hr", "24sata.hr")) %>%
count(FROM, word, sort = T)
ukupnoWords <- domenaWords %>%
group_by(FROM) %>%
summarise(totWords = sum(n))
domenaWords <- left_join(domenaWords, ukupnoWords)
# domenaWords %>% head(15)
# domenaWords %>%
# ggplot(., aes(n/totWords, fill = domena)) +
#   geom_histogram(show.legend = FALSE) +
#   xlim(NA, 0.0009) +
#   facet_wrap(~domena, ncol = 2, scales = "free_y")
## Najbitnije riječi po domenma
idf <- domenaWords %>%
bind_tf_idf(word, FROM, n)
#idf %>% head(10)
# idf %>%
#   select(-totWords) %>%
#   arrange(desc(tf_idf))
idf %>%
arrange(desc(tf_idf)) %>%
mutate(word = factor(word, levels = rev(unique(word)))) %>%
mutate(FROM = factor(FROM)) %>%
group_by(FROM) %>%
top_n(20) %>%
ungroup() %>%
ggplot(aes(word, tf_idf, fill = FROM)) +
geom_col(show.legend = FALSE) +
labs(x = NULL, y = "tf-idf") +
facet_wrap(~FROM, ncol = 2, scales = "free") +
coord_flip() +
theme_economist()
fb_bigram <- dta %>%
unnest_tokens(bigram, FULL_TEXT, token = "ngrams", n = 2)
#fb_bigram %>% head(10)
# fb_bigram %>%
#   count(bigram, sort = T) %>%
#   head(25)
fb_bigram_sep <- fb_bigram %>%
separate(bigram, c("word1","word2"), sep = " ")
fb_bigram_tidy <- fb_bigram_sep %>%
filter(!word1 %in% stop_corpus$word) %>%
filter(!word2 %in% stop_corpus$word) %>%
mutate(word1 = gsub("\\d+", NA, word1)) %>%
mutate(word2 = gsub("\\d+", NA, word2)) %>%
mutate(word1 = gsub("^[a-zA-Z]$", NA, word1)) %>%
mutate(word2 = gsub("^[a-zA-Z]$", NA, word2))
fb_bigram_tidy_bigram_counts <- fb_bigram_tidy %>%
count(word1, word2, sort = TRUE)
bigrams_united <- fb_bigram_tidy %>%
unite(bigram, word1, word2, sep = " ") %>%
filter(., !grepl("NA",bigram))
#bigrams_united
bigrams_united %>%
count(FROM,bigram,sort = T) -> topicBigram
bigrams_united %>%
count(bigram, sort = T) %>%
head(45)
bigram_tf_idf %>%
arrange(desc(tf_idf)) %>%
filter(tf_idf > 0.09) %>%
mutate(bigram = factor(bigram, levels = rev(unique(bigram)))) %>%
#  group_by(FROM) %>%
#  top_n(20) %>%
ungroup() %>%
ggplot(aes(bigram, tf_idf, fill = FROM)) +
geom_col(show.legend = FALSE) +
labs(x = NULL, y = "tf-idf") +
#  facet_wrap(~FROM, ncol = 2, scales = "free") +
coord_flip() +
theme_economist()
# Najvažniji bigrami po domenama
bigram_tf_idf <- bigrams_united %>%
#  filter (!is.na(bigram)) %>%
count(FROM, bigram) %>%
bind_tf_idf(bigram, FROM, n) %>%
arrange(desc(tf_idf))
i
bigram_tf_idf %>%
arrange(desc(tf_idf)) %>%
filter(tf_idf > 0.09) %>%
mutate(bigram = factor(bigram, levels = rev(unique(bigram)))) %>%
#  group_by(FROM) %>%
#  top_n(20) %>%
ungroup() %>%
ggplot(aes(bigram, tf_idf, fill = FROM)) +
geom_col(show.legend = FALSE) +
labs(x = NULL, y = "tf-idf") +
#  facet_wrap(~FROM, ncol = 2, scales = "free") +
coord_flip() +
theme_economist()
bigram_tf_idf %>%
filter(FROM %in% c("vecenji.hr", "jutarnji.hr", "24sata.hr", "telegram.hr")) %>%
arrange(desc(tf_idf)) %>%
mutate(bigram = factor(bigram, levels = rev(unique(bigram)))) %>%
group_by(FROM) %>%
top_n(20) %>%
ungroup() %>%
ggplot(aes(bigram, tf_idf, fill = FROM)) +
geom_col(show.legend = FALSE) +
labs(x = NULL, y = "tf-idf") +
facet_wrap(~FROM, ncol = 2, scales = "free") +
coord_flip() +
theme_economist()
n_tokenTidy %>%
count(FROM, word, sort = TRUE) %>%
cast_dtm(FROM, word,n) -> dtm
fb_LDA <- LDA(dtm, k = 4,  control = list(seed = 1234))
fb_LDA_tidy <- tidy(fb_LDA, matrix = "beta")
#newsCOVID_LDA_tidy
insta_terms <- fb_LDA_tidy %>%
drop_na(.) %>%
group_by(topic) %>%
top_n(15, beta) %>%
ungroup() %>%
arrange(topic, -beta)
#newsCOVID_terms
insta_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(term, beta, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
coord_flip() +
scale_x_reordered() +
theme_economist()
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
library(xlsx)
library(here)
library(kableExtra)
library(DT)
library(purrr)
library(data.table)
library(tidytext)
library(dplyr)
library(lubridate)
library(anytime)
library(grid)
library(wordcloud)
library(reshape2)
library(ggraph)
library(widyr)
library(topicmodels)
library(ggthemes)
# fullDta <- fread("D:/LUKA/Freelance/Mediatoolkit/FULLDATA_NOTXT.csv")
# fullDtaTxt <- fread("D:/LUKA/Freelance/Mediatoolkit/FULLDATA_TXT.csv")
dt <- fread("D:/LUKA/Freelance/Mediatoolkit/MktFULLtxt.csv")
dt %>% filter(SOURCE_TYPE == "twitter") ->dp
write.csv2(df_filtered, file = "D:/LUKA/Freelance/Mediatoolkit/Dp.csv", row.names = T)
write.csv2(dp, file = "D:/LUKA/Freelance/Mediatoolkit/Dp.csv", row.names = T)
write.csv(slice(dp,1000), file = "D:/LUKA/Freelance/Mediatoolkit/Dp.csv", row.names = T)
write.xlsx(slice(dp,1000), file = "D:/LUKA/Freelance/Mediatoolkit/Dp.csv", row.names = T)
write.xlsx(slice(dp,1000), file = "D:/LUKA/Freelance/Mediatoolkit/Dp.xlsx", row.names = T)
write.csv2(slice(dp,1000), file = "D:/LUKA/Freelance/Mediatoolkit/Dp.csv", row.names = T)
slice(dp,1000) -> dp
slice(dt,1:1000) -> dp
write.csv2(dp, file = "D:/LUKA/Freelance/Mediatoolkit/Dp.csv", row.names = T)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
library(xlsx)
library(here)
library(kableExtra)
library(DT)
library(purrr)
library(data.table)
library(tidytext)
library(dplyr)
library(lubridate)
library(anytime)
library(grid)
library(wordcloud)
library(reshape2)
library(ggraph)
library(widyr)
library(topicmodels)
library(ggthemes)
# fullDta <- fread("D:/LUKA/Freelance/Mediatoolkit/FULLDATA_NOTXT.csv")
# fullDtaTxt <- fread("D:/LUKA/Freelance/Mediatoolkit/FULLDATA_TXT.csv")
dt <- fread("D:/LUKA/Freelance/Mediatoolkit/MktFULLtxt.csv")
dta <- dt %>%
filter(SOURCE_TYPE =="web")  %>%
filter(str_detect(AUTHOR,fixed("sponzorirani sadržaj",ignore_case = TRUE)))
dta <- dt[SOURCE_TYPE == "web" &
(str_detect(FULL_TEXT, fixed("sadržaj nastao",ignore_case = TRUE)) |
str_detect(AUTHOR, fixed("sponzor",ignore_case = TRUE)) |
str_detect(AUTHOR, fixed("native",ignore_case = TRUE)) |
str_detect(AUTHOR, fixed("tnative",ignore_case = TRUE)) |
str_detect(FULL_TEXT, fixed("tnative",ignore_case = TRUE)) |
str_detect(FULL_TEXT, fixed("sadržaj donosi", ignore_case = TRUE)) |
str_detect(FULL_TEXT, fixed("sponzorirani sadržaj", ignore_case = TRUE)) |
str_detect(AUTHOR, fixed("tnative",ignore_case = TRUE)))]
View(dta)
unique(dta$FROM)
dta %>% count(FROM)
dta %>% count(FROM) %>% arrange(desc(n))
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
library(xlsx)
library(here)
library(kableExtra)
library(DT)
library(purrr)
library(data.table)
library(tidytext)
library(dplyr)
library(lubridate)
library(anytime)
library(grid)
library(wordcloud)
library(reshape2)
library(ggraph)
library(widyr)
library(topicmodels)
library(ggthemes)
# fullDta <- fread("D:/LUKA/Freelance/Mediatoolkit/FULLDATA_NOTXT.csv")
# fullDtaTxt <- fread("D:/LUKA/Freelance/Mediatoolkit/FULLDATA_TXT.csv")
dt <- fread("D:/LUKA/Freelance/Mediatoolkit/MktFULLtxt.csv")
dta <- dt[SOURCE_TYPE == "web" &
(str_detect(FULL_TEXT, fixed("sadržaj nastao",ignore_case = TRUE)) |
str_detect(AUTHOR, fixed("sponzor",ignore_case = TRUE)) |
str_detect(AUTHOR, fixed("native",ignore_case = TRUE)) |
str_detect(AUTHOR, fixed("tnative",ignore_case = TRUE)) |
str_detect(FULL_TEXT, fixed("tnative",ignore_case = TRUE)) |
str_detect(FULL_TEXT, fixed("sadržaj donosi", ignore_case = TRUE)) |
str_detect(FULL_TEXT, fixed("sponzorirani sadržaj", ignore_case = TRUE)) |
str_detect(AUTHOR, fixed("tnative",ignore_case = TRUE)))]
dta <- dt[SOURCE_TYPE == "web" &
(str_detect(FULL_TEXT, fixed("sadržaj nastao",ignore_case = TRUE)) |
str_detect(AUTHOR, fixed("sponzor",ignore_case = TRUE)) |
str_detect(AUTHOR, fixed("native",ignore_case = TRUE)) |
str_detect(AUTHOR, fixed("tnative",ignore_case = TRUE)) |
str_detect(FULL_TEXT, fixed("tnative",ignore_case = TRUE)) |
str_detect(FULL_TEXT, fixed("sadržaj donosi", ignore_case = TRUE)) |
str_detect(FULL_TEXT, fixed("sponzorirani sadržaj", ignore_case = TRUE)) |
str_detect(AUTHOR, fixed("sponzorirani sadržaj", ignore_case = TRUE)) |
str_detect(AUTHOR, fixed("tnative",ignore_case = TRUE)))]
uniqe(dta$FROM)
unique(dta$FROM)
portali <- c("index.hr","24sata.hr", "jutarnji.hr", "net.hr", "tportal.hr", "vecernji.hr", "jutarnji.hr", "slobodnadalmacija.hr", "telegram.hr")
dta <- dt[SOURCE_TYPE == "web" &
FROM %in%  portali &
(str_detect(FULL_TEXT, fixed("sadržaj nastao",ignore_case = TRUE)) |
str_detect(AUTHOR, fixed("sponzor",ignore_case = TRUE)) |
str_detect(AUTHOR, fixed("native",ignore_case = TRUE)) |
str_detect(AUTHOR, fixed("tnative",ignore_case = TRUE)) |
str_detect(FULL_TEXT, fixed("tnative",ignore_case = TRUE)) |
str_detect(FULL_TEXT, fixed("sadržaj donosi", ignore_case = TRUE)) |
str_detect(FULL_TEXT, fixed("sponzorirani sadržaj", ignore_case = TRUE)) |
str_detect(AUTHOR, fixed("sponzorirani sadržaj", ignore_case = TRUE)) |
str_detect(AUTHOR, fixed("PR", ignore_case = TRUE)) |
str_detect(AUTHOR, fixed("tnative",ignore_case = TRUE)))]
write.csv2(dta, file = "D:/LUKA/Freelance/Mediatoolkit/native.csv", row.names = T)
write.csv(dta, file = "D:/LUKA/Freelance/Mediatoolkit/native.csv", row.names = T)
write.xlsx(dta, file = "D:/LUKA/Freelance/Mediatoolkit/native.xlsx", row.names = T)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
library(xlsx)
library(here)
library(kableExtra)
library(DT)
library(purrr)
library(data.table)
library(tidytext)
library(dplyr)
library(lubridate)
library(anytime)
library(grid)
library(wordcloud)
library(reshape2)
library(ggraph)
library(widyr)
library(topicmodels)
library(ggthemes)
# fullDta <- fread("D:/LUKA/Freelance/Mediatoolkit/FULLDATA_NOTXT.csv")
# fullDtaTxt <- fread("D:/LUKA/Freelance/Mediatoolkit/FULLDATA_TXT.csv")
dt <- fread("D:/LUKA/Freelance/Mediatoolkit/MktFULLtxt.csv")
tw <- dt[SOURCE_TYPE == "twitter"]
tw <- dt[SOURCE_TYPE == "twitter"] %>%
slice(1:2000)
write.xlsx(tw, file = "D:/LUKA/Freelance/Mediatoolkit/tw.xlsx", row.names = T)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
library(xlsx)
library(here)
library(kableExtra)
library(DT)
library(purrr)
library(data.table)
library(tidytext)
library(dplyr)
library(lubridate)
library(anytime)
library(grid)
library(wordcloud)
library(reshape2)
library(ggraph)
library(widyr)
library(topicmodels)
library(ggthemes)
# fullDta <- fread("D:/LUKA/Freelance/Mediatoolkit/FULLDATA_NOTXT.csv")
# fullDtaTxt <- fread("D:/LUKA/Freelance/Mediatoolkit/FULLDATA_TXT.csv")
dt <- fread("D:/LUKA/Freelance/Mediatoolkit/MktFULLtxt.csv")
search_pattern <- "rat|ukrajin|rus|izbjegl|Bosn|BiH|NATO|inflacij|eur|kun|plenk|zok|milan|horvat|tolusi|toluši|aladrovi|franciskovi|mari|dorh|uskok|pernar|remetin|INA|žalac|zalac|vreć|vrec|vreč|iseljen|migracij|emigracij|imigracij|mirovin|penzi|umirovlj|plin|naft|goriv|dizel|benzin|covid|coron|obuk|vojni|hrgovi|svjetsk|prvenstv|livakovi|modri|livaj|dali|lovren|periš|peris|potres|požar|nesreć|torcid|bbb|boys|stanovni|dron|raket|pokolj|obnov|Tomasevi|Tomaševi|možemo|mozemo|plać|plac|prihod|avion|projektil"
tw <- dt[SOURCE_TYPE == "twitter" &
(str_detect(FULL_TEXT, fixed(search_pattern,ignore_case = TRUE)))]
tw <- dt[,SOURCE_TYPE == "twitter"]
tw <- dt[SOURCE_TYPE == "twitter"]
tw_pek <- tw[str_detect(FULL_TEXT, fixed("rat|ukrajin",ignore_case = TRUE)))]
tw_pek <- tw[str_detect(FULL_TEXT, fixed("rat|ukrajin",ignore_case = TRUE))]
tw_pek <- tw[str_detect(FULL_TEXT, fixed("rat",ignore_case = TRUE))]
tw_pek <- tw[str_detect(FULL_TEXT, fixed("rat|ukrajin|rus",ignore_case = TRUE))]
tw_pek <- tw[str_detect(FULL_TEXT, fixed("rat",ignore_case = TRUE))]
View(tw_pek)
search_pattern <- "rat|ukrajin|rus|izbjegl|Bosn|BiH|NATO|inflacij|eur|kun|plenk|zok|milan|horvat|tolusi|toluši|aladrovi|franciskovi|mari|dorh|uskok|pernar|remetin|INA|žalac|zalac|vreć|vrec|vreč|iseljen|migracij|emigracij|imigracij|mirovin|penzi|umirovlj|plin|naft|goriv|dizel|benzin|covid|coron|obuk|vojni|hrgovi|svjetsk|prvenstv|livakovi|modri|livaj|dali|lovren|periš|peris|potres|požar|nesreć|torcid|bbb|boys|stanovni|dron|raket|pokolj|obnov|Tomasevi|Tomaševi|možemo|mozemo|plać|plac|prihod|avion|projektil"
filtered_df <- tw %>% filter(str_detect(FULL_TEXT, fixed(search_pattern, ignore_case = TRUE)))
tw <- dt[SOURCE_TYPE == "twitter"]
search_pattern <- "rat|ukrajin|rus"
filtered_df <- tw %>% filter(str_detect(FULL_TEXT, fixed(search_pattern, ignore_case = TRUE)))
filtered_df <- tw %>% filter(str_detect(FULL_TEXT, (search_pattern, ignore_case = TRUE)))
filtered_df <- tw %>% filter(str_detect(FULL_TEXT, search_pattern, ignore_case = TRUE))
filtered_df <- tw %>% filter(str_detect(FULL_TEXT, search_pattern)
search_pattern <- "rat"
search_pattern <- "rat"
filtered_df <- tw %>% filter(str_detect(FULL_TEXT, search_pattern)
filtered_dt <- tw[FULL_TEXT %like% search_pattern, ignore.case = TRUE]
search_pattern <- "rat|ukrajin|rus|izbjegl|Bosn|BiH|NATO|inflacij|eur|kun|plenk|zok|milan|horvat|tolusi|toluši|aladrovi|franciskovi|mari|dorh|uskok|pernar|remetin|INA|žalac|zalac|vreć|vrec|vreč|iseljen|migracij|emigracij|imigracij|mirovin|penzi|umirovlj|plin|naft|goriv|dizel|benzin|covid|coron|obuk|vojni|hrgovi|svjetsk|prvenstv|livakovi|modri|livaj|dali|lovren|periš|peris|potres|požar|nesreć|torcid|bbb|boys|stanovni|dron|raket|pokolj|obnov|Tomasevi|Tomaševi|možemo|mozemo|plać|plac|prihod|avion|projektil"
filtered_dt <- tw[FULL_TEXT %like% search_pattern, ignore.case = TRUE]
filtered_dt <- tw[FULL_TEXT %like% search_pattern]
View(filtered_dt)
write.xlsx(filtered_dt, file = "D:/LUKA/Freelance/Mediatoolkit/tw_pekec.xlsx", row.names = T)
write.xlsx(filtered_dt, file = "D:/LUKA/Freelance/Mediatoolkit/tw_pekec.xlsx", row.names = T)
View(filtered_dt)
write.csv2(filtered_dt, file = "D:/LUKA/Freelance/Mediatoolkit/tw_pekec.csv", row.names = T)
write.csv(filtered_dt, file = "D:/LUKA/Freelance/Mediatoolkit/tw_pekec.csv", row.names = T)
write.xlsx2(filtered_dt, file = "D:/LUKA/Freelance/Mediatoolkit/tw_pekec.xlsx", row.names = T)
write.xlsx(filtered_dt, file = "D:/LUKA/Freelance/Mediatoolkit/tw_pekec.xlsx", row.names = T)
write_csv2(filtered_dt, file = "D:/LUKA/Freelance/Mediatoolkit/tw_pekec.csv", row.names = T)
write.csv2(filtered_dt, file = "D:/LUKA/Freelance/Mediatoolkit/tw_pekec.csv", row.names = T)
portali <- c("index.hr","24sata.hr", "jutarnji.hr", "net.hr", "tportal.hr", "vecernji.hr", "jutarnji.hr", "slobodnadalmacija.hr", "telegram.hr")
dta <- dt[SOURCE_TYPE == "web" &
FROM %in%  portali &
(str_detect(FULL_TEXT, fixed("sadržaj nastao",ignore_case = TRUE)) |
str_detect(AUTHOR, fixed("sponzor",ignore_case = TRUE)) |
str_detect(AUTHOR, fixed("24ContentHaus",ignore_case = TRUE)) |
str_detect(AUTHOR, fixed("Native tim",ignore_case = TRUE)) |
str_detect(AUTHOR, fixed("sponzor",ignore_case = TRUE)) |
str_detect(AUTHOR, fixed("native",ignore_case = TRUE)) |
str_detect(AUTHOR, fixed("tnative",ignore_case = TRUE)) |
str_detect(FULL_TEXT, fixed("tnative",ignore_case = TRUE)) |
str_detect(FULL_TEXT, fixed("sadržaj donosi", ignore_case = TRUE)) |
str_detect(FULL_TEXT, fixed("sponzorirani sadržaj", ignore_case = TRUE)) |
str_detect(AUTHOR, fixed("sponzorirani sadržaj", ignore_case = TRUE)) |
str_detect(AUTHOR, fixed("PR", ignore_case = TRUE)) |
str_detect(AUTHOR, fixed("tnative",ignore_case = TRUE)))]
dta <- dt[SOURCE_TYPE == "web" &
FROM %in%  portali &
(str_detect(FULL_TEXT, fixed("sadržaj nastao",ignore_case = TRUE)) |
str_detect(AUTHOR, fixed("sponzor",ignore_case = TRUE)) |
str_detect(AUTHOR, fixed("24ContentHaus",ignore_case = TRUE)) |
str_detect(AUTHOR, fixed("Native tim",ignore_case = TRUE)) |
str_detect(AUTHOR, fixed("native",ignore_case = TRUE)) |
str_detect(AUTHOR, fixed("tnative",ignore_case = TRUE)) |
str_detect(FULL_TEXT, fixed("tnative",ignore_case = TRUE)) |
str_detect(FULL_TEXT, fixed("sadržaj donosi", ignore_case = TRUE)) |
str_detect(FULL_TEXT, fixed("sponzorirani sadržaj", ignore_case = TRUE)) |
str_detect(FULL_TEXT, fixed("24ContentHaus", ignore_case = TRUE)) |
str_detect(FULL_TEXT, fixed("Native tim", ignore_case = TRUE)) |
str_detect(AUTHOR, fixed("sponzorirani sadržaj", ignore_case = TRUE)) |
str_detect(AUTHOR, fixed("PR", ignore_case = TRUE)) |
str_detect(AUTHOR, fixed("tnative",ignore_case = TRUE)))]
write.xlsx(dta, file = "D:/LUKA/Freelance/Mediatoolkit/native.xlsx", row.names = T)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
library(xlsx)
library(here)
library(kableExtra)
library(DT)
library(purrr)
library(data.table)
library(tidytext)
library(dplyr)
library(lubridate)
library(anytime)
library(grid)
library(wordcloud)
library(reshape2)
library(ggraph)
library(widyr)
library(topicmodels)
library(ggthemes)
# fullDta <- fread("D:/LUKA/Freelance/Mediatoolkit/FULLDATA_NOTXT.csv")
# fullDtaTxt <- fread("D:/LUKA/Freelance/Mediatoolkit/FULLDATA_TXT.csv")
dt <- fread("D:/LUKA/Freelance/Mediatoolkit/MktFULLtxt.csv")
dta <- dt[SOURCE_TYPE == "web" &
FROM == "24sata.hr]
dta <- dt[,SOURCE_TYPE == "web" &
+               FROM == "24sata.hr]
dta <- dt %>%
filter(SOURCE_TYPE =="web")  %>%
dta <- dt %>%
filter(SOURCE_TYPE =="web")  %>%
filter(str_detect(FULL_TEXT,fixed("jedno slavensko ratničko pleme",ignore_case = TRUE)))
dta <- dt %>%
filter(SOURCE_TYPE =="web")  %>%
filter(FROM == "24sata.hr")
View(dta)
dta  %>% filter(str_detect(TITLE,fixed("Stopama hrvatskih legendi",ignore_case = TRUE)))
dch <-dta  %>% filter(str_detect(TITLE,fixed("Stopama hrvatskih legendi",ignore_case = TRUE)))
View(dch)
View(dta)
dta <- dt %>%
filter(SOURCE_TYPE =="web")  %>%
filter(FROM == "tportal")
dta <- dt %>%
filter(SOURCE_TYPE =="web")  %>%
filter(FROM == "tportal.hr")
dch <-dta  %>% filter(str_detect(TITLE,fixed("Kako snimiti najbolju",ignore_case = TRUE)))
dch <-dta  %>% filter(str_detect(FULL_TEXT,fixed("Doista pratimo trendove",ignore_case = TRUE)))
dch <- dta  %>% filter(str_detect(TITLE,fixed("Pitali smo našeg",ignore_case = TRUE)))
str(dta)
dta  %>% filter(DATE == "2022-18-02")
dta  %>% filter(DATE == "2022-02-18")
dch <- dta  %>% filter(DATE == "2022-02-18")
dch
dch
View(dch)
dch <- dta  %>% filter(str_detect(URL,fixed("native",ignore_case = TRUE)))
dch <- dt  %>% filter(str_detect(URL,fixed("native",ignore_case = TRUE)))
dch <- dt  %>% filter(str_detect(URL,fixed("promo",ignore_case = TRUE)))
dch %>% filter(FROM == "24sata.hr")
proba <-dch %>% filter(FROM == "24sata.hr")
View(proba)
proba  %>% filter(DATE == "2022-04-29")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
library(xlsx)
library(here)
library(kableExtra)
library(DT)
library(purrr)
library(data.table)
library(tidytext)
library(dplyr)
library(lubridate)
library(anytime)
library(grid)
library(wordcloud)
library(reshape2)
library(ggraph)
library(widyr)
library(topicmodels)
library(ggthemes)
# fullDta <- fread("D:/LUKA/Freelance/Mediatoolkit/FULLDATA_NOTXT.csv")
# fullDtaTxt <- fread("D:/LUKA/Freelance/Mediatoolkit/FULLDATA_TXT.csv")
dt <- fread("D:/LUKA/Freelance/Mediatoolkit/MktFULLtxt.csv")
dta <- dt %>%
filter(SOURCE_TYPE =="web")  %>%
filter(FROM == "24sata.hr")
filter(str_detect(URL,fixed("promo",ignore_case = TRUE)))
dta <- dt %>%
filter(SOURCE_TYPE =="web")  %>%
filter(FROM == "24sata.hr") %>%
filter(str_detect(URL,fixed("promo",ignore_case = TRUE)))
View(dta)
write.csv2(dta, file = "D:/LUKA/Freelance/Mediatoolkit/promo24h.csv", row.names = T)
write.xlsx(dta, file = "D:/LUKA/Freelance/Mediatoolkit/promo24h.xlsx", row.names = T)
