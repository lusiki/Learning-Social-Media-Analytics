summarise(FAVORITE = sum(FAVORITE_COUNT)) %>%
arrange(desc(FAVORITE)) %>% View()
# most appreciated
CTW %>%
group_by(FROM) %>%
summarise(RETWEET = sum(RETWEET_COUNT)) %>%
arrange(desc(RETWEET)) %>% View()
# most appreciated
CTW %>%
group_by(FROM) %>%
summarise(RETWEET = sum(RETWEET_COUNT)) %>%
arrange(desc(RETWEET)) %>% View()
# most popular
CTW %>%
select(FROM, FULL_TEXT, FOLLOWERS_COUNT,URL) %>%
arrange(desc(FOLLOWERS_COUNT)) %>% View()
# most influential
CTW %>%
select(FROM, FULL_TEXT, REACH,URL) %>%
arrange(desc(REACH)) %>% View()
# most influential II
CTW %>%
select(FROM, FULL_TEXT, INTERACTIONS,URL) %>%
arrange(desc(INTERACTIONS)) %>% View()
# most appreciated
CTW %>%
select(FROM, FULL_TEXT, FAVORITE_COUNT,URL) %>%
arrange(desc(FAVORITE_COUNT)) %>% View()
# most appreciated
CTW %>%
select(FROM, FULL_TEXT, RETWEET_COUNT,URL) %>%
arrange(desc(RETWEET_COUNT)) %>% View()
# most popular
tw %>%
group_by(FROM) %>%
summarise(FOLLOW = mean(FOLLOWERS_COUNT)) %>%
arrange(desc(FOLLOW)) %>%
head(40)
# most popular
CTW %>%
select(FROM, FULL_TEXT, FOLLOWERS_COUNT,URL) %>%
arrange(desc(FOLLOWERS_COUNT))  %>%
head(40)
# most popular
CTW %>%
group_by(FROM) %>%
summarise(FOLLOW = mean(FOLLOWERS_COUNT)) %>%
arrange(desc(FOLLOW))  %>%
head(40)
write.csv2(tw,"C:/Users/Lukas/OneDrive/Desktop/tw.csv")
yt <- read.csv2("C:/Users/Lukas/OneDrive/Desktop/tw.csv")
# select twitter
forum <- posts[SOURCE_TYPE == "forum",]
View(forum)
forum <- as.data.table(forum)
forum[,.N,TITLE][]
forum[,.N,TITLE][order(-N)]
forum[TITLE == "Ostati ili otići iz Hrvatske",][]
forum[,.N,TITLE][order(-N)]
forum[TITLE == Potraga za razlogom ili teorije zavjere vol. 9",][]
forum[TITLE == "Potraga za razlogom ili teorije zavjere vol. 9",][]
# select relevant CRO profiles
unique(tw[,.N,FROM][order(-N)]) %>%
filter(N > 5) %>%
pull(FROM) -> CRO_TW
tw[FROM %in% CRO_TW,] -> CTW
# most popular
CTW %>%
group_by(FROM) %>%
summarise(FOLLOW = mean(FOLLOWERS_COUNT)) %>%
arrange(desc(FOLLOW))  %>%
head(40)
CTW
# select relevant CRO profiles
unique(tw[,.N,FROM][order(-N)]) %>%
filter(N > 5) %>%
str_split(URL,"")
View(CTW)
tw[FROM %in% CRO_TW,]
tw[FROM %in% CRO_TW,] %>%
str_split(URL,"/") -> CTW
tw[FROM %in% CRO_TW,] %>%
str_split(URL,"/")
CTW %>%
str_split(URL,"/")
tw[FROM %in% CRO_TW,] -> CTW
CTW %>%
str_split(URL,"/")
CTW %>%
mutate(PROFILE = str_split(URL,"/"))
CTW %>%
mutate(PROFILE = str_split(URL,"/")) %>%
pull(PROFILE)
CTW %>%
mutate(PROFILE = str_split(URL,"/")[4])
CTW %>%
mutate(PROFILE = str_split(URL,"/")[[1]][4])
# most popular
CTW %>%
group_by(PROFILE) %>%
summarise(FOLLOW = mean(FOLLOWERS_COUNT)) %>%
arrange(desc(FOLLOW))  %>%
head(40)
CTW %>%
mutate(PROFILE = str_split(URL,"/")[[1]][4]) -> CTW
# most popular
CTW %>%
group_by(PROFILE) %>%
summarise(FOLLOW = mean(FOLLOWERS_COUNT)) %>%
arrange(desc(FOLLOW))  %>%
head(40)
CTW %>%
mutate(PROFILE = gsub("^.*\\.com/([^/]+).*", "\\1", URL)) -> CTW
# most popular
CTW %>%
group_by(PROFILE) %>%
summarise(FOLLOW = mean(FOLLOWERS_COUNT)) %>%
arrange(desc(FOLLOW))  %>%
head(40)
# most popular
CTW %>%
select(PROFILE, FULL_TEXT, FOLLOWERS_COUNT,URL) %>%
arrange(desc(FOLLOWERS_COUNT))  %>%
head(40)
CTW %>%
select(PROFILE, FULL_TEXT, FOLLOWERS_COUNT,URL) %>%
group_by(PROFILE) %>%
top_n(10) %>%
arrange(desc(FOLLOWERS_COUNT))
# most popular
CTW %>%
select(PROFILE, FULL_TEXT, FOLLOWERS_COUNT,URL) %>%
arrange(desc(FOLLOWERS_COUNT))  %>%
head(40)
tw <- tw %>%
mutate(PROFILE = gsub("^.*\\.com/([^/]+).*", "\\1", URL))
# most active profiles
unique(tw[,.N,PROFILE][order(-N)])
# most popular
tw %>%
group_by(PROFILE) %>%
summarise(FOLLOW = mean(FOLLOWERS_COUNT)) %>%
arrange(desc(FOLLOW)) %>%
head(40)
# most popular
tw %>%
group_by(PROFILE) %>%
summarise(FOLLOW = mean(FOLLOWERS_COUNT)) %>%
arrange(desc(FOLLOW)) %>%
head(40)
# most influential
tw %>%
group_by(PROFILE) %>%
summarise(REACH = sum(REACH)) %>%
arrange(desc(REACH))  %>%
head(40)
# most influential II
tw %>%
group_by(PROFILE) %>%
summarise(INTERACTIONS = sum(INTERACTIONS)) %>%
arrange(desc(INTERACTIONS)) %>%
head(40)
# most appreciated
tw %>%
group_by(PROFILE) %>%
summarise(FAVORITE = sum(FAVORITE_COUNT)) %>%
arrange(desc(FAVORITE)) %>%
head(40)
t
# most appreciated
tw %>%
group_by(PROFILE) %>%
summarise(RETWEET = sum(RETWEET_COUNT)) %>%
arrange(desc(RETWEET)) %>%
head(40)
# most popular
tw %>%
select(PROFILE, FULL_TEXT, FOLLOWERS_COUNT,URL) %>%
arrange(desc(FOLLOWERS_COUNT)) %>%
head(40)
# most influential
tw %>%
select(PROFILE, FULL_TEXT, REACH,URL) %>%
arrange(desc(REACH))  %>%
head(40)
# most influential II
tw %>%
select(PROFILE, FULL_TEXT, INTERACTIONS,URL) %>%
arrange(desc(INTERACTIONS))  %>%
head(40)
# most appreciated
tw %>%
select(PROFILE, FULL_TEXT, FAVORITE_COUNT,URL) %>%
arrange(desc(FAVORITE_COUNT)) %>%
head(40)
# most appreciated
tw %>%
select(PROFILE, FULL_TEXT, RETWEET_COUNT,URL) %>%
arrange(desc(RETWEET_COUNT))  %>%
head(40)
# select relevant CRO profiles
unique(tw[,.N,FROM][order(-N)]) %>%
filter(N > 5) %>%
pull(FROM) -> CRO_TW
tw[FROM %in% CRO_TW,] -> CTW
CTW %>%
mutate(PROFILE = gsub("^.*\\.com/([^/]+).*", "\\1", URL)) -> CTW
# most popular
CTW %>%
group_by(PROFILE) %>%
summarise(FOLLOW = mean(FOLLOWERS_COUNT)) %>%
arrange(desc(FOLLOW))  %>%
head(40)
# most popular
CTW %>%
group_by(PROFILE) %>%
summarise(FOLLOW = mean(FOLLOWERS_COUNT)) %>%
arrange(desc(FOLLOW))  %>%
head(40)
# most influential
CTW %>%
group_by(PROFILE) %>%
summarise(REACH = sum(REACH)) %>%
arrange(desc(REACH))  %>%
head(40)
# most influential
CTW %>%
group_by(PROFILE) %>%
summarise(REACH = mean(REACH)) %>%
arrange(desc(REACH))  %>%
head(40)
# most influential
CTW %>%
group_by(PROFILE) %>%
summarise(REACH = sum(REACH)) %>%
arrange(desc(REACH))  %>%
head(40)
# most influential II
CTW %>%
group_by(PROFILE) %>%
summarise(INTERACTIONS = sum(INTERACTIONS)) %>%
arrange(desc(INTERACTIONS))  %>%
head(40)
# most appreciated
CTW %>%
group_by(PROFILE) %>%
summarise(FAVORITE = sum(FAVORITE_COUNT)) %>%
arrange(desc(FAVORITE)) %>%
head(40)
# most appreciated
CTW %>%
group_by(PROFILE) %>%
summarise(RETWEET = sum(RETWEET_COUNT)) %>%
arrange(desc(RETWEET))  %>%
head(40)
# most popular
CTW %>%
select(PROFILE, FULL_TEXT, FOLLOWERS_COUNT,URL) %>%
arrange(desc(FOLLOWERS_COUNT))  %>%
head(40)
# most influential
CTW %>%
select(PROFILE, FULL_TEXT, REACH,URL) %>%
arrange(desc(REACH))  %>%
head(40)
# most influential II
CTW %>%
select(PROFILE, FULL_TEXT, INTERACTIONS,URL) %>%
arrange(desc(INTERACTIONS))  %>%
head(40)
# most appreciated
CTW %>%
select(PROFILE, FULL_TEXT, FAVORITE_COUNT,URL) %>%
arrange(desc(FAVORITE_COUNT))  %>%
head(40)
# most appreciated
CTW %>%
select(PROFILE, FULL_TEXT, RETWEET_COUNT,URL) %>%
arrange(desc(RETWEET_COUNT))  %>%
head(40)
# most popular
CTW %>%
select(PROFILE, FULL_TEXT, FOLLOWERS_COUNT,URL) %>%
arrange(desc(FOLLOWERS_COUNT))  %>%
head(40)
# most popular
CTW %>%
group_by(PROFILE) %>%
summarise(FOLLOW = mean(FOLLOWERS_COUNT)) %>%
arrange(desc(FOLLOW))  %>%
head(40)
# most popular
CTW %>%
group_by(PROFILE) %>%
summarise(FOLLOW = mean(FOLLOWERS_COUNT)) %>%
arrange(desc(FOLLOW))  %>%
head(100)
# most popular
CTW %>%
group_by(PROFILE) %>%
summarise(FOLLOW = mean(FOLLOWERS_COUNT)) %>%
arrange(desc(FOLLOW))  %>%
head(150)
write.csv2(forum, "C:/Users/Lukas/OneDrive/Desktop/forum.csv")
forum <- read.csv2(forum, "C:/Users/Lukas/OneDrive/Desktop/forum.csv")
forum <- read.csv2( "C:/Users/Lukas/OneDrive/Desktop/forum.csv")
forum[.N, TITLE][]
View(forum)
forum[,.N, TITLE][]
forum[,.N, "TITLE"][]
forum <- as.data.table(forum)
forum[,.N, TITLE][]
forum[,.N, TITLE][order(-N)]
forum[TITLE == "Zoran Milanović, predsjednik Republike Hrvatske vol. IV",][]
forum[TITLE == "Zoran Milanović, predsjednik Republike Hrvatske vol. IV",] %>% View()
forum[,.N, TITLE][order(-N)]
forum[,.N, TITLE][order(-N)] %>% head(40)
forum[,.N, TITLE][order(-N)] %>% head(50)
# most active profiles
unique(tw[,.N,PROFILE][order(-N)])
forum[TITLE == "Zoran Milanović, predsjednik Republike Hrvatske vol. IV",]
forum[,.N, TITLE][order(-N)] %>% head(50)
forum[TITLE == "Zoran Milanović, predsjednik Republike Hrvatske vol. IV",]
forum[TITLE == "Zoran Milanović, predsjednik Republike Hrvatske vol. IV",] %>%
unnest_tokens(word,FULL_TEXT) -> ZM_token
# read in lexicons
CroSentilex_n <- read.delim("C:/Users/Lukas/Dropbox/Mislav@Luka/crosentilex-negatives.txt",
header = FALSE,
sep = " ",
stringsAsFactors = FALSE,
fileEncoding = "UTF-8")  %>%
rename(word = "V1", sentiment = "V2" ) %>%
mutate(brija = "NEG")
CroSentilex_p  <- read.delim("C:/Users/Lukas/Dropbox/Mislav@Luka/crosentilex-positives.txt",
header = FALSE,
sep = " ",
stringsAsFactors = FALSE,
fileEncoding = "UTF-8") %>%
rename(word = "V1", sentiment = "V2" ) %>%
mutate(brija = "POZ")
Crosentilex_sve <- rbind(setDT(CroSentilex_n), setDT(CroSentilex_p))
# check lexicon data
head(sample_n(Crosentilex_sve,1000),15)
CroSentilex_Gold  <- read.delim2("C:/Users/Lukas/Dropbox/Mislav@Luka/gs-sentiment-annotations.txt",
header = FALSE,
sep = " ",
stringsAsFactors = FALSE) %>%
rename(word = "V1", sentiment = "V2" )
Encoding(CroSentilex_Gold$word) <- "UTF-8"
CroSentilex_Gold[1,1] <- "dati"
CroSentilex_Gold$sentiment <- str_replace(CroSentilex_Gold$sentiment , "-", "1")
CroSentilex_Gold$sentiment <- str_replace(CroSentilex_Gold$sentiment , "\\+", "2")
CroSentilex_Gold$sentiment <- as.numeric(unlist(CroSentilex_Gold$sentiment))
# check lexicon data
head(sample_n(CroSentilex_Gold,100),15)
# create stop words
stopwords_cro <- get_stopwords(language = "hr", source = "stopwords-iso")
# check stopwords data
head(sample_n(stopwords_cro,100),15)
# extend stop words
my_stop_words <- tibble(
word = c(
"jedan","mjera", "može", "možete", "mogu", "kad", "sada", "treba", "ima", "osoba",
"e","prvi", "dva","dvije","drugi",
"tri","treći","pet","kod",
"ove","ova",  "ovo","bez", "kod",
"evo","oko",  "om", "ek",
"mil","tko","šest", "sedam",
"osam",   "čim", "zbog",
"prema", "dok","zato", "koji",
"im", "čak","među", "tek",
"koliko", "tko","kod","poput",
"baš", "dakle", "osim", "svih",
"svoju", "odnosno", "gdje",
"kojoj", "ovi", "toga",
"ubera", "vozača", "hrvatskoj", "usluge", "godine", "više", "taksi", "taxi", "taksija", "taksija", "kaže", "rekao", "19"," aee", "ae","bit.ly", "https", "one", "the"
),
lexicon = "lux"
)
stop_corpus <- my_stop_words %>%
bind_rows(stopwords_cro)
# check stopwords data
head(sample_n(stop_corpus,100),15)
# remove stop words, numbers, single letters
ZM_token %>%
anti_join(stop_corpus, by = "word") %>%
mutate(word = gsub("\\d+", NA, word)) %>%
mutate(word = gsub("^[a-zA-Z]$", NA, word)) -> ZM_tokenTidy
# remove NA
ZM_tokenTidy %>%
filter(!is.na(word)) -> ZM_tokenTidy
# check
fb_tokenTidy  %>%
select(FROM, word, MENTION_SNIPPET ) %>%
sample_n(.,15)
# check
ZM_tokenTidy  %>%
select(FROM, word, MENTION_SNIPPET ) %>%
sample_n(.,15)
# check
ZM_tokenTidy  %>%
select(FROM, word ) %>%
sample_n(.,15)
ZM_tokenTidy[,.N,by = word][order(-N),]
forum[TITLE == "Zoran Milanović, predsjednik Republike Hrvatske vol. IV",] %>%
unnest_tokens(bigram,FULL_TEXT, token = "ngrams", n = 2) -> ZM_token
## Vizualize most common words
ZM_tokenTidy[,.N,by = word][N>100][order(-N),][,word := reorder(word,N)] %>%
ggplot(aes(word, N)) +
geom_col() +
xlab(NULL) +
coord_flip() +
theme_economist()
## Vizualize most common words
ZM_tokenTidy[,.N,by = word][N>500][order(-N),][,word := reorder(word,N)] %>%
ggplot(aes(word, N)) +
geom_col() +
xlab(NULL) +
coord_flip() +
theme_economist()
forum[,.N, TITLE][order(-N)] %>% head(50)
forum[TITLE == "Anksioznost - opća tema (Vol. V)",] %>%
unnest_tokens(word,FULL_TEXT) -> ZM_token
# tokenize
ZM_token %>%
unnest_tokens(word, FULL_TEXT) -> fb_token
# remove stop words, numbers, single letters
ZM_token %>%
anti_join(stop_corpus, by = "word") %>%
mutate(word = gsub("\\d+", NA, word)) %>%
mutate(word = gsub("^[a-zA-Z]$", NA, word)) -> ZM_tokenTidy
forum[TITLE == "Anksioznost - opća tema (Vol. V)",] %>%
unnest_tokens(word,FULL_TEXT) -> ZM_token
# tokenize
ZM_token %>%
unnest_tokens(word, FULL_TEXT) -> fb_token
# remove stop words, numbers, single letters
ZM_token %>%
anti_join(stop_corpus, by = "word") %>%
mutate(word = gsub("\\d+", NA, word)) %>%
mutate(word = gsub("^[a-zA-Z]$", NA, word)) -> ZM_tokenTidy
# remove NA
ZM_tokenTidy %>%
filter(!is.na(word)) -> ZM_tokenTidy
ZM_tokenTidy[,.N,by = word][order(-N),]
## Vizualize most common words
ZM_tokenTidy[,.N,by = word][N>500][order(-N),][,word := reorder(word,N)] %>%
ggplot(aes(word, N)) +
geom_col() +
xlab(NULL) +
coord_flip() +
theme_economist()
ZM_tokenTidy[,.N,by = word][order(-N),]
forum[TITLE == "Anksioznost - opća tema (Vol. V)",] %>%
unnest_tokens(word,FULL_TEXT) -> ZM_token
ZM_token
forum[TITLE == "Anksioznost - opća tema (Vol. V)",]
forum[,.N, TITLE][order(-N)] %>% head(50)
forum[TITLE == "Anksioznost - opća tema (Vol.V)",]
forum[,.N, TITLE][order(-N)] %>% head(50)
forum[TITLE == "Tomislav Tomašević, gradonačelnik Grada Zagreba III-pročitati uvodni post",]
forum[,.N, TITLE][order(-N)] %>% head(50)
forum[TITLE == "Zoran Milanović, predsjednik Republike Hrvatske vol. IV",]
forum[,.N, TITLE][order(-N)] %>% head(50)
forum[TITLE == "Potraga za razlogom ili teorije zavjere vol. 8",]
forum[TITLE == "Potraga za razlogom ili teorije zavjere vol. 8",] %>%
unnest_tokens(word,FULL_TEXT) -> ZM_token
# remove stop words, numbers, single letters
ZM_token %>%
anti_join(stop_corpus, by = "word") %>%
mutate(word = gsub("\\d+", NA, word)) %>%
mutate(word = gsub("^[a-zA-Z]$", NA, word)) -> ZM_tokenTidy
# remove NA
ZM_tokenTidy %>%
filter(!is.na(word)) -> ZM_tokenTidy
ZM_tokenTidy[,.N,by = word][order(-N),]
## Vizualize most common words
ZM_tokenTidy[,.N,by = word][N>500][order(-N),][,word := reorder(word,N)] %>%
ggplot(aes(word, N)) +
geom_col() +
xlab(NULL) +
coord_flip() +
theme_economist()
ZM_tokenTidy[,.N,by = word][order(-N),]
forum[,.N, TITLE][order(-N)] %>% head(50)
forum[TITLE == "Ruska invazija na Ukrajinu, 3. dio",] %>%
unnest_tokens(word,FULL_TEXT) -> ZM_token
# remove stop words, numbers, single letters
ZM_token %>%
anti_join(stop_corpus, by = "word") %>%
mutate(word = gsub("\\d+", NA, word)) %>%
mutate(word = gsub("^[a-zA-Z]$", NA, word)) -> ZM_tokenTidy
# remove NA
ZM_tokenTidy %>%
filter(!is.na(word)) -> ZM_tokenTidy
ZM_tokenTidy[,.N,by = word][order(-N),]
## Vizualize most common words
ZM_tokenTidy[,.N,by = word][N>500][order(-N),][,word := reorder(word,N)] %>%
ggplot(aes(word, N)) +
geom_col() +
xlab(NULL) +
coord_flip() +
theme_economist()
ZM_tokenTidy[,.N,by = word][order(-N),]
ZM_tokenTidy[,.N,by = word][order(-N),]
forum[,.N, TITLE][order(-N)] %>% head(50)
forum[TITLE == "Anksioznost - opća tema (Vol. V)",] %>%
unnest_tokens(word,FULL_TEXT) -> ZM_token
forum[TITLE == "Anksioznost - opća tema(Vol.V)",] %>%
unnest_tokens(word,FULL_TEXT) -> ZM_token
forum[TITLE == "Anksioznost - opća tema(Vol.V)",] %>%
unnest_tokens(word,FULL_TEXT) -> ZM_token
