comment = response.comment_count,
text = response.mention) %>%
arrange(desc(comment))
data %>%
filter(response.from == "vecernji.hr") %>%
select(title = response.title,
time = response.insert_time,
author = response.author,
url = response.url,
comment = response.comment_count,
text = response.mention) %>%
arrange(desc(comment)) %>%
head
data %>%
slice(1) %>%
select(title, text, url)
data %>%
slice(1) %>%
select(title = response.title,
text = response.mention,
url = response.url)
data %>%
slice(1) %>%
select(url = response.url)
data %>%
slice(1) %>%
select(text = response.mention)
knitr::opts_chunk$set(echo = T, message = F, warning = F)
library(tidyverse)
library(readxl)
library(here)
library(kableExtra)
library(DT)
library(rvest)
library(tidyverse)
library(httr)
# this is a private infor
source(here::here("Creds/api.R"))
# identify from your Mediatoolkit App
groups <- "182718"
keywords <- "6521533"
# select time period
from_time <- as.character(as.numeric(as.POSIXlt("2022-03-3", format="%Y-%m-%d")))
to_time <- as.character(as.numeric(as.POSIXlt("2022-03-14", format="%Y-%m-%d")))
# number of articles to retrieve
count <- 3000
# connect all parts into request string
requestString <- paste0("https://api.mediatoolkit.com/organizations/126686/groups/",groups,
"/keywords/",keywords,
"/mentions?access_token=",token,
"&from_time=",from_time,
"&to_time=",to_time,
"&count=",count,
"&sort=time&type=all&offset=0&ids_only=false")
# check the request string
requestString
# make GET request to Mediatoolkit server API
API_request <- httr::GET(requestString)
# parse the request into JSON object
jS_text <- httr::content(API_request, as = "text", type = "aplication/json", encoding = "UTF-8")
# make a list from JSON object
dataList <- jsonlite::fromJSON(jS_text, flatten = TRUE)
# make a data.frame from list
data <- data.frame(dataList$data)
# this is a private infor
source(here::here("Creds/api.R"))
# identify from your Mediatoolkit App
groups <- "182718"
keywords <- "6521533"
# select time period
from_time <- as.character(as.numeric(as.POSIXlt("2022-03-14", format="%Y-%m-%d")))
to_time <- as.character(as.numeric(as.POSIXlt("2022-03-15", format="%Y-%m-%d")))
# number of articles to retrieve
count <- 3000
# connect all parts into request string
requestString <- paste0("https://api.mediatoolkit.com/organizations/126686/groups/",groups,
"/keywords/",keywords,
"/mentions?access_token=",token,
"&from_time=",from_time,
"&to_time=",to_time,
"&count=",count,
"&sort=time&type=all&offset=0&ids_only=false")
# check the request string
requestString
# make GET request to Mediatoolkit server API
API_request <- httr::GET(requestString)
# check the API request object
API_request
# parse the request into JSON object
jS_text <- httr::content(API_request, as = "text", type = "aplication/json", encoding = "UTF-8")
# make a list from JSON object
dataList <- jsonlite::fromJSON(jS_text, flatten = TRUE)
# make a data.frame from list
data <- data.frame(dataList$data)
# this is a private infor
source(here::here("Creds/api.R"))
# identify from your Mediatoolkit App
groups <- "182718"
keywords <- "6521533"
# select time period
from_time <- as.character(as.numeric(as.POSIXlt("2022-03-13", format="%Y-%m-%d")))
to_time <- as.character(as.numeric(as.POSIXlt("2022-03-14", format="%Y-%m-%d")))
# number of articles to retrieve
count <- 3000
# connect all parts into request string
requestString <- paste0("https://api.mediatoolkit.com/organizations/126686/groups/",groups,
"/keywords/",keywords,
"/mentions?access_token=",token,
"&from_time=",from_time,
"&to_time=",to_time,
"&count=",count,
"&sort=time&type=all&offset=0&ids_only=false")
# check the request string
requestString
# make GET request to Mediatoolkit server API
API_request <- httr::GET(requestString)
# parse the request into JSON object
jS_text <- httr::content(API_request, as = "text", type = "aplication/json", encoding = "UTF-8")
# make a list from JSON object
dataList <- jsonlite::fromJSON(jS_text, flatten = TRUE)
# make a data.frame from list
data <- data.frame(dataList$data)
# size of the data
dim(data)
# variables and variable types
glimpse(data)
# check if there are articles from Večernji list
data %>%
group_by(response.from) %>%
count %>%
arrange(desc(n)) %>%
head()
data %>%
filter(response.from == "vecernji.hr") %>%
select(title = response.title,
time = response.insert_time,
author = response.author,
url = response.url,
comment = response.comment_count,
text = response.mention) %>%
arrange(desc(comment)) %>%
head
data %>%
slice(1) %>%
select(title = response.title)
data %>%
slice(1) %>%
select(text = response.mention)
data %>%
slice(1) %>%
select(url = response.url)
knitr::opts_chunk$set(echo = T, message = F, warning = F)
library(tidyverse)
library(readxl)
library(here)
library(kableExtra)
library(DT)
library(rvest)
library(tidyverse)
library(httr)
# this is a private infor
source(here::here("Creds/api.R"))
# identify from your Mediatoolkit App
groups <- "182718"
keywords <- "6521533"
# select time period
from_time <- as.character(as.numeric(as.POSIXlt("2022-03-13", format="%Y-%m-%d")))
to_time <- as.character(as.numeric(as.POSIXlt("2022-03-14", format="%Y-%m-%d")))
# number of articles to retrieve
count <- 3000
# connect all parts into request string
requestString <- paste0("https://api.mediatoolkit.com/organizations/126686/groups/",groups,
"/keywords/",keywords,
"/mentions?access_token=",token,
"&from_time=",from_time,
"&to_time=",to_time,
"&count=",count,
"&sort=time&type=all&offset=0&ids_only=false")
# check the request string
requestString
# make GET request to Mediatoolkit server API
API_request <- httr::GET(requestString)
# check the API request object
API_request
# parse the request into JSON object
jS_text <- httr::content(API_request, as = "text", type = "aplication/json", encoding = "UTF-8")
# make a list from JSON object
dataList <- jsonlite::fromJSON(jS_text, flatten = TRUE)
# make a data.frame from list
data <- data.frame(dataList$data)
# size of the data
dim(data)
# variables and variable types
glimpse(data)
# check if there are articles from Večernji list
data %>%
group_by(response.from) %>%
count %>%
arrange(desc(n)) %>%
head()
data %>%
filter(response.from == "vecernji.hr") %>%
select(title = response.title,
time = response.insert_time,
author = response.author,
url = response.url,
comment = response.comment_count,
text = response.mention) %>%
arrange(desc(comment)) %>%
head
data %>%
slice(1) %>%
select(title = response.title)
data %>%
slice(1) %>%
select(text = response.mention)
data %>%
slice(1) %>%
select(url = response.url)
data %>%
select(response.from) %>%
count()
data %>%
group_by(response.from) %>%
count()
data %>%
group_by(response.from) %>%
summarise(domains = n_distinct())
data %>%
# group_by(response.from) %>%
summarise(domains = n_distinct())
n_distinct(data$response.from)
data %>%
group_by(response.from) %>%
count %>%
arrange(desc(n))
data %>%
group_by(response.from) %>%
count %>%
arrange(desc(n)) %>%
slice(1:30)
data %>%
group_by(response.from) %>%
count %>%
arrange(desc(n))
data %>%
group_by(response.from) %>%
count %>%
arrange(desc(n)) %>%
head(30)
names(data)
# check uniqe domains
n_distinct(data$response.from)
data %>%
filter(response.type == "web")
data %>%
filter(response.type == "web") %>%
summarise(No = n())
# get the number of web articles/activity: FILTER
data %>%
filter(response.type == "web") %>%
summarise(No = n())
# get the number of web articles/activity: FILTER
data %>%
filter(response.type == "web") %>%
summarise(NumberOfArticles = n())
summarise(AverageViews = mean(response.view_count)
data %>%
data %>%
filter(response.type == "web") %>%
group_by(response.from) %>%
summarise(AverageViews = mean(response.view_count))
View(data)
data %>%
filter(response.type == "web") %>%
group_by(response.from) %>%
summarise(AverageReach = mean(response.reach))
data %>%
filter(response.type == "web") %>%
group_by(response.from) %>%
summarise(Reach = mean(response.reach),
Virality = mean(response.virality),
LikeCount = mean(response.like_count),
Commentount = mean(response.comment_count),
ShareCount = mean(response.share_count))
data %>%
filter(response.type == "web") %>%
group_by(response.from) %>%
summarise(Reach = mean(response.reach),
Virality = mean(response.virality),
LikeCount = mean(response.like_count),
Comment = mean(response.comment_count),
Share = mean(response.share_count)) %>%
arrange(desc(Share))
data %>%
filter(response.type == "web") %>%
group_by(response.from) %>%
summarise(Share = mean(response.share_count),
Reach = mean(response.reach),
Virality = mean(response.virality),
LikeCount = mean(response.like_count),
Comment = mean(response.comment_count)) %>%
arrange(desc(Share))
data %>%
filter(response.type == "web") %>%
group_by(response.from) %>%
summarise(Reach = mean(response.reach),
Share = mean(response.share_count),
Virality = mean(response.virality),
LikeCount = mean(response.like_count),
Comment = mean(response.comment_count)) %>%
arrange(desc(Reach))
data %>%
filter(response.type == "web") %>%
group_by(response.from) %>%
summarise(Comment = mean(response.comment_count)) %>%
arrange(desc(Comment))
# arrange by share
data %>%
filter(response.type == "web") %>%
group_by(response.from) %>%
summarise(Share = mean(response.share_count),
Reach = mean(response.reach),
Virality = mean(response.virality),
LikeCount = mean(response.like_count),
Comment = mean(response.comment_count)) %>%
arrange(desc(Share))
data %>%
select(response.from, response.title) %>%
filter(response.from == "platak.hr")
data %>%
select(response.from, response.title, response.mention) %>%
filter(response.from == "platak.hr")
data %>%
select(response.from, response.title, response.mention) %>%
filter(response.from == "geopolitika.news")
data %>%
select(response.from, response.title, response.mention) %>%
filter(response.from == "geopolitika.news")
data %>%
select(response.from, response.title, response.mention) %>%
filter(response.from == "geopolitika.news") %>%
select(response.title)
data %>%
select(response.from, response.mention) %>%
filter(response.from == "geopolitika.news")
# arrange by share
data %>%
filter(response.type == "web") %>%
group_by(response.from) %>%
summarise(Share = mean(response.share_count),
Reach = mean(response.reach),
Virality = mean(response.virality),
LikeCount = mean(response.like_count),
Comment = mean(response.comment_count)) %>%
arrange(desc(Share))
# arrange by reach
data %>%
filter(response.type == "web") %>%
group_by(response.from) %>%
summarise(Reach = mean(response.reach),
Share = mean(response.share_count),
Virality = mean(response.virality),
LikeCount = mean(response.like_count),
Comment = mean(response.comment_count)) %>%
arrange(desc(Reach))
# arrange by share
data %>%
filter(response.type == "web") %>%
group_by(response.from) %>%
summarise(Share = mean(response.share_count),
Reach = mean(response.reach),
Virality = mean(response.virality),
LikeCount = mean(response.like_count),
Comment = mean(response.comment_count)) %>%
arrange(desc(Share))
# arrange by reach
data %>%
filter(response.type == "web") %>%
group_by(response.from) %>%
summarise(Reach = mean(response.reach),
Share = mean(response.share_count),
Virality = mean(response.virality),
LikeCount = mean(response.like_count),
Comment = mean(response.comment_count)) %>%
arrange(desc(Reach))
data %>%
select(response.from, response.mention) %>%
filter(response.from == "index.hr") %>%
select(response.mention)
t
# arrange by reach
data %>%
filter(response.type == "web") %>%
group_by(response.from) %>%
summarise(Reach = mean(response.reach),
Share = mean(response.share_count),
Virality = mean(response.virality),
LikeCount = mean(response.like_count),
Comment = mean(response.comment_count)) %>%
arrange(desc(Reach))
data %>%
select(response.from, response.mention) %>%
filter(response.from == "priznajem.hr") %>%
select(response.mention)
data %>%
select(response.from, response.mention, response.title) %>%
filter(response.from == "priznajem.hr") %>%
select(response.mention)
data %>%
select(response.from, response.mention, response.title) %>%
filter(response.from == "priznajem.hr")
# arrange by comment
data %>%
filter(response.type == "web") %>%
group_by(response.from) %>%
summarise(Comment = mean(response.comment_count)) %>%
arrange(desc(Comment))
data %>%
select(response.from, response.title) %>%
filter(response.from == "sloboda.hr")
data %>%
select(response.from, response.title, response.mention) %>%
filter(response.from == "sloboda.hr")
data %>%
select(response.from, response.title, response.url) %>%
filter(response.from == "sloboda.hr")
data %>%
filter(response.type == "web") %>%
summarise(NumberOfArticles = n())
data %>%
filter(response.type == "web") %>%
group_by(response.from) %>%
summarise(Share = mean(response.share_count),
Reach = mean(response.reach),
Virality = mean(response.virality),
LikeCount = mean(response.like_count),
Comment = mean(response.comment_count)) %>%
arrange(desc(Share))
data %>%
filter(response.type == "web") %>%
group_by(response.from) %>%
count() %>%
arrange(desc(Share))
data %>%
filter(response.type == "web") %>%
group_by(response.from) %>%
count() %>%
arrange(desc(n))
data %>%
filter(response.type == "web") %>%
group_by(response.from) %>%
count() %>%
arrange(desc(n)) %>%
head(10)
data %>%
filter(response.type == "web") %>%
group_by(response.from) %>%
count() %>%
arrange(desc(n)) %>%
head(10) %>%
pull
data %>%
filter(response.type == "web") %>%
group_by(response.from) %>%
count() %>%
arrange(desc(n)) %>%
head(10)
data %>%
filter(response.type == "web") %>%
group_by(response.from) %>%
count() %>%
arrange(desc(n)) %>%
head(10) %>%
select(response.from) -> velikiPOrtali
velikiPOrtali
data %>%
filter(response.type == "web") %>%
group_by(response.from) %>%
count() %>%
arrange(desc(n)) %>%
head(10) %>%
select(response.from) %>% pull -> velikiPOrtali
velikiPOrtali
# select biggest portals
data %>%
filter(response.type == "web") %>%
group_by(response.from) %>%
count() %>%
arrange(desc(n)) %>%
head(10) %>%
select(response.from) %>%
pull -> largePortals
"notin" <- !
data %>%
filter(response.type == "web") %>%
mutate(PortalSize = case_when(response.from %in% largePortals ~ "Large",
response.from %!in% largePortals ~ "Small"))
`%!in%` <- Negate(`%in%`)
data %>%
filter(response.type == "web") %>%
mutate(PortalSize = case_when(response.from %in% largePortals ~ "Large",
response.from %!in% largePortals ~ "Small"))
data %>%
filter(response.type == "web") %>%
mutate(PortalSize = case_when(response.from %in% largePortals ~ "Large",
response.from %!in% largePortals ~ "Small")) %>%
group_by(PortalSize) %>%
count
data %>%
filter(response.type == "web") %>%
summarise(NumberOfArticles = n())
