---
title: "Korupus native tekstova"
author: "Lux"
date: "2023-03-25"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r echo=F, eval=T, message=F , warning= FALSE, message=F}
library(tidyverse)
library(readxl)
library(xlsx)
library(here)
library(kableExtra)
library(DT)
library(purrr)
library(data.table)
library(tidytext)
library(dplyr)
library(lubridate)
library(anytime)
library(grid)
library(wordcloud)
library(reshape2)
library(ggraph)
library(widyr)
library(topicmodels)
library(ggthemes)
library(xlsx)

```


```{r echo=F, eval=F, message=F , warning= FALSE}
# fullDta <- fread("D:/LUKA/Freelance/Mediatoolkit/FULLDATA_NOTXT.csv")
# fullDtaTxt <- fread("D:/LUKA/Freelance/Mediatoolkit/FULLDATA_TXT.csv")
dt <- fread("D:/LUKA/Freelance/Mediatoolkit/MktFULLtxt.csv")


dt <- dt %>% filter(SOURCE_TYPE == "web")



```

```{r echo=F, eval=F, message=F , warning= FALSE}
n <- nrow(dt)
chunk_size <- n %/% 20

chunks <- split(dt, rep(1:20, each = chunk_size, length.out = n))

for (i in 1:20) {
  fwrite(chunks[[i]], file = paste0("D:/LUKA/Freelance/Mediatoolkit/chunk_", i, ".csv"))
}

```

```{r echo=F, eval=F, message=F , warning= FALSE}

path <- "D:/LUKA/Freelance/Mediatoolkit"
files <- list.files(path)
chunk_files <- files[grep("chunk", files)]
filepath <- file.path(path, chunk_files)



tokenize_chunk <- function(filepath) {
 filepath %>%
    read.csv() %>%
    unnest_tokens(word, FULL_TEXT, token = "words") %>%
    filter(str_detect(word, "humanitar")) %>%
    distinct(TITLE, URL, .keep_all = F) 
}


tokenized_chunks <- map(filepath, tokenize_chunk)

tokenized_chunks_df <- bind_rows(tokenized_chunks)



```

```{r echo=F, eval=F, message=F , warning= FALSE}


df_filtered <- dt %>% 
  filter(URL %in% tokenized_chunks_df$URL)

#write.csv2(df_filtered, file = "D:/LUKA/Freelance/Mediatoolkit/Humanitar.csv", row.names = T)


```

```{r echo=F, eval=F, message=F , warning= FALSE}
dta <- dt %>%
  filter(SOURCE_TYPE =="web")  %>%
  filter(str_detect(AUTHOR,fixed("Content",ignore_case = TRUE))) 

dta <- dt %>%
  filter(SOURCE_TYPE =="web")  %>%
  filter(str_detect(AUTHOR,fixed("Native tim",ignore_case = TRUE)))


dta <- dt %>%
  filter(SOURCE_TYPE =="web")  %>%
  filter(str_detect(AUTHOR,fixed("Native",ignore_case = TRUE)))

dta <- dt %>%
  filter(SOURCE_TYPE =="web")  %>%
  filter(str_detect(FULL_TEXT,fixed("24Content",ignore_case = TRUE)))

dta <- dt %>%
  filter(SOURCE_TYPE =="web") %>%
  filter(str_detect(FULL_TEXT,fixed("Sponzorirani sadržaj",ignore_case = TRUE)))

# sadržaj donosi (txt) == 205

# sadržaj nastao (txt) == 801

# prilog je napravljen (txt) == 5

# nativ (title) == 11

# Native tim (txt) == 142

# Sponzorirani sadržaj == 439

# 24Content ==




dta <- dta[,-1]
```

```{r echo=F, eval=F, message=F , warning= FALSE}

# 24h kod autorstva ima 24ContentHaus i u tekstu formulaciju sadržaj donosi

dta1 <- dt %>%
#  filter(SOURCE_TYPE =="web")  %>%
  filter(FROM == "tportal.hr") %>% 
  filter(str_detect(FULL,fixed("24Content",ignore_case = TRUE)))

dta <- dt %>%
  filter(SOURCE_TYPE =="web")  %>%
  filter(str_detect(FULL_TEXT,fixed("Sadržaj nastao",ignore_case = TRUE)))

#### promo u URL-u

test <- dt %>%
#  filter(SOURCE_TYPE =="web")  %>%
#  filter(FROM == "24sata.hr") %>%
  filter(str_detect(URL,fixed("836688",ignore_case = TRUE)))



write.xlsx(dta1, file = "D:/LUKA/Freelance/Mediatoolkit/powered_by_24h.xlsx", row.names = T)





dchour <- dt %>%
  filter(SOURCE_TYPE =="web")  %>%
  filter(FROM == "24sata.hr") %>%
  filter(DATE== "2022-05-19") %>%
  filter(str_detect(URL, fixed("native",ignore_case = TRUE)))

dta1 <- dchour %>%
  filter(str_detect(FULL_TEXT,fixed("Powered by",ignore_case = TRUE)))











activity <- dta %>%
  group_by(FROM) %>%
  summarise(count = n()) %>%
  mutate(percent = round(count / sum(count) * 100,2)) %>% 
  arrange(desc(count))

datatable(activity, options = list(scrollX = TRUE, scrollY = "500px"))

dta %>% 
  select(DATE,TIME,TITLE,FROM,AUTHOR,URL, FULL_TEXT) %>%
  datatable(., options = list(scrollX = TRUE, scrollY = "500px"))
  

```

```{r echo=F, eval=F, message=F , warning= FALSE}

# 24h kod autorstva ima 24ContentHaus i u tekstu formulaciju sadržaj donosi


dta <- dt %>%
  filter(SOURCE_TYPE =="web")  %>%
  filter(str_detect(FULL_TEXT,fixed("sadržaj nastao",ignore_case = TRUE)))


activity <- dta %>%
  group_by(FROM) %>%
  summarise(count = n()) %>%
  mutate(percent = round(count / sum(count) * 100,2)) %>% 
  arrange(desc(count))

datatable(activity, options = list(scrollX = TRUE, scrollY = "500px"))


dta %>% 
  select(DATE,TIME,TITLE,FROM,AUTHOR,URL, FULL_TEXT) %>%
  datatable(., options = list(scrollX = TRUE, scrollY = "500px"))


```

```{r echo=F, eval=F, message=F , warning= FALSE}

# 24h kod autorstva ima 24ContentHaus i u tekstu formulaciju sadržaj donosi


dta <- dt %>%
  filter(SOURCE_TYPE =="web")  %>%
  filter(str_detect(AUTHOR,fixed("tnative",ignore_case = TRUE)))

dta <- dt %>%
  filter(SOURCE_TYPE =="web")  %>%
  filter(str_detect(URL,fixed("836688",ignore_case = TRUE)))


activity <- dta %>%
  group_by(FROM) %>%
  summarise(count = n()) %>%
  mutate(percent = round(count / sum(count) * 100,2)) %>% 
  arrange(desc(count))

datatable(activity, options = list(scrollX = TRUE, scrollY = "500px"))


dta %>% 
  select(DATE,TIME,TITLE,FROM,AUTHOR,URL, FULL_TEXT) %>%
  datatable(., options = list(scrollX = TRUE, scrollY = "500px"))

```

```{r echo=F, eval=F, message=F , warning= FALSE}

# 24h kod autorstva ima 24ContentHaus i u tekstu formulaciju sadržaj donosi


dta <- dt %>%
  filter(SOURCE_TYPE =="web")  %>%
  filter(str_detect(AUTHOR,fixed("Native",ignore_case = TRUE)))

# dta <- dt %>%
#   filter(SOURCE_TYPE =="web")  %>%
#   filter(str_detect(FULL_TEXT,fixed("prilog je napravljen",ignore_case = TRUE)))


activity <- dta %>%
  group_by(FROM) %>%
  summarise(count = n()) %>%
  mutate(percent = round(count / sum(count) * 100,2)) %>% 
  arrange(desc(count))

datatable(activity, options = list(scrollX = TRUE, scrollY = "500px"))


dta %>% 
  select(DATE,TIME,TITLE,FROM,AUTHOR,URL, FULL_TEXT) %>%
  datatable(., options = list(scrollX = TRUE, scrollY = "500px"))

```

```{r echo=F, eval=F, message=F , warning= FALSE}

# 24h kod autorstva ima 24ContentHaus i u tekstu formulaciju sadržaj donosi


dta <- dt %>%
  filter(SOURCE_TYPE =="web")  %>%
  filter(str_detect(AUTHOR,fixed("Sponzorirani sadržaj",ignore_case = TRUE)))

activity <- dta %>%
  group_by(FROM) %>%
  summarise(count = n()) %>%
  mutate(percent = round(count / sum(count) * 100,2)) %>% 
  arrange(desc(count))

datatable(activity, options = list(scrollX = TRUE, scrollY = "500px"))

dta %>% 
  select(DATE,TIME,TITLE,FROM,AUTHOR,URL, FULL_TEXT) %>%
  datatable(., options = list(scrollX = TRUE, scrollY = "500px"))

dta <- dt %>%
  filter(SOURCE_TYPE =="web")  %>%
  filter(str_detect(FULL_TEXT,fixed("Sponzorirani sadržaj",ignore_case = TRUE)))


activity <- dta %>%
  group_by(FROM) %>%
  summarise(count = n()) %>%
  mutate(percent = round(count / sum(count) * 100,2)) %>% 
  arrange(desc(count))

datatable(activity, options = list(scrollX = TRUE, scrollY = "500px"))

dta %>% 
  select(DATE,TIME,TITLE,FROM,AUTHOR,URL, FULL_TEXT) %>%
  datatable(., options = list(scrollX = TRUE, scrollY = "500px"))

```

```{r  echo=F, eval=F, message=F , warning= FALS}
library(rvest)
library(purrr)

# Function to check for specific text in a specific HTML field of a webpage
# Function to check for specific text in a specific HTML field of a webpage
check_text_in_page <- function(url, xpath_field, text_to_check) {
  page <- read_html(url)
  
  # Use XPath to locate the HTML field
  text_field <- html_text(html_nodes(page, xpath = xpath_field))
  
  # Check if the specific text exists in the field
  if (text_to_check %in% text_field) {
    return(TRUE)
  } else {
    return(FALSE)
  }
}

# XPath for the HTML field
xpath_field <- "/html/body/div[2]/div/div[2]/section/article/div[1]/div[1]/div[1]/header/div/div/div/span/span[1]/a"


24ContentHaus
<a href="/autori/24contenthaus-46917" class="article__authors_link">24ContentHaus</a>

# Text to look for
text_to_check <- "24ContentHaus"

# URL to scrape
promo24 <- read.xlsx("C:/Users/Lukas/OneDrive/Desktop/promo24h.xlsx",sheetIndex = 1)
url  <- "https://www.24sata.hr/promo-sadrzaj/od-padobrana-do-elektricne-energije-genijalne-ideje-kojima-smo-nadahnuli-ostatak-svijeta-825451"
  
  promo24$URL[2]
# Call the function
result <- check_text_in_page(url, xpath_field, text_to_check)

# Print the result
print(result)


```

```{r  echo=F, eval=F, message=F , warning= FALS}
library(rvest)
library(tidyverse)
library(stringr)

# List of URLs to check
urls <- promo24$URL[400:916]

# Function to check for the presence of specific text in the HTML of a URL


check_text_presence <- function(url) {
  message("Checking URL: ", url)
  
  # Initialize the result as NA
  any_author_matches <- NA
  
  # Try block to catch errors
  try({
    # Read the HTML content from the URL
    html_content <- read_html(url)
  
    # Extract the text of all "a" tags with the class "article__authors_link"
    author_tags <- html_content %>% html_nodes("a.article__authors_link") %>% html_text()
  
    # Check if '24ContentHaus' is present
    any_author_matches <- any(str_detect(author_tags, fixed("24ContentHaus")))
  }, silent = TRUE)
  
  return(any_author_matches)
}


# Check each URL and store the results in a data frame
results1 <- tibble(
  url = urls,
  contains_text = map_lgl(urls, check_text_presence)
)

results2 <- tibble(
  url = urls,
  contains_text = map_lgl(urls, check_text_presence)
)

results3 <- tibble(
  url = urls,
  contains_text = map_lgl(urls, check_text_presence)
)

results4 <- tibble(
  url = urls,
  contains_text = map_lgl(urls, check_text_presence)
)

results4 %>% filter(contains_text == TRUE)

results <- rbind(results,results2, results3,results4)

results <- results %>% filter(contains_text == TRUE)

# Print results
print(results)


ch24 <- promo24 %>% filter(URL %in% results$url)

write.xlsx(ch24, file = "D:/LUKA/Freelance/Mediatoolkit/ch24.xlsx", row.names = T)

```


# Read In 
```{r echo=F, eval=T, message=F , warning= FALSE}
original <- read.xlsx("D:/LUKA/Freelance/Mediatoolkit/native1.xlsx", sheetIndex = 1)
variables <- read.xlsx("C:/Users/Lukas/OneDrive/Desktop/Native.xlsx", sheetIndex = 1)
variables <- variables[,-c(23,24,25)] %>% drop_na()
original <- original %>% filter(V1 %in% variables$V1)
dta <- merge(original, variables, by = "V1", all.x = TRUE)
dta$DATE <- as.Date(dta$DATE)
```


```{r echo=F, eval=F, message=F , warning= FALSE}

# 
# dta <- dt %>%
#   filter(SOURCE_TYPE =="web") %>%
#   filter(str_detect(FULL_TEXT,fixed("sadržaj nastao",ignore_case = TRUE)) |
#            str_detect(AUTHOR,fixed("sponzor",ignore_case = TRUE))|
#            str_detect(AUTHOR,fixed("native",ignore_case = TRUE))|
#            str_detect(AUTHOR,fixed("tnative",ignore_case = TRUE))|
#            str_detect(FULL_TEXT,fixed("tnative",ignore_case = TRUE))|
#            str_detect(AUTHOR,fixed("tnative",ignore_case = TRUE)))
  



dta <- dt[SOURCE_TYPE == "web" &
          (str_detect(FULL_TEXT, fixed("sadržaj nastao",ignore_case = TRUE)) |
           str_detect(AUTHOR, fixed("sponzor",ignore_case = TRUE)) |
           str_detect(AUTHOR, fixed("native",ignore_case = TRUE)) |
           str_detect(AUTHOR, fixed("tnative",ignore_case = TRUE)) |
           str_detect(FULL_TEXT, fixed("tnative",ignore_case = TRUE)) |
           str_detect(FULL_TEXT, fixed("sadržaj donosi", ignore_case = TRUE)) |
           str_detect(FULL_TEXT, fixed("sponzorirani sadržaj", ignore_case = TRUE)) | 
           str_detect(AUTHOR, fixed("tnative",ignore_case = TRUE)))]



```


# Basic descriptives


```{r echo=F, eval=T, message=F , warning= FALSE}
# date range
range(dta$DATE)
```


```{r echo=F, eval=F, message=F , warning= FALSE}
# number of articles
nrow(dta)

```


#### Deskriptiva na dnevnoj razini
```{r echo=F, eval=T, message=F , warning= FALSE}
# articles over time
daily_counts <- dta %>%
  group_by(DATE) %>%
  summarise(count = n())

# descriptives 
summ <- daily_counts %>% 
  summarize(min = min(count), max = max(count), 
            mean = mean(count), q1= quantile(count, probs = 0.25), 
            median = median(count), q3= quantile(count, probs = 0.75),
            sd = sd(count)) %>%
  mutate_if(is.numeric, round, digits=2) 

summ
```

#### Broj objava po danima  
```{r echo=F, eval=T, message=F , warning= FALSE}
# create plot of articles over time
ggplot(data = daily_counts, aes(x = DATE, y = count)) +
  geom_line() +
  labs(x = "Date", y = "Number of Articles")
 

```


#### Broj objava po izvoru 
```{r echo=F, eval=T, message=F , warning= FALSE}
# Portals by activity
activity <- dta %>%
  group_by(FROM) %>%
  summarise(count = n()) %>%
  mutate(percent = round(count / sum(count) * 100,2)) %>% 
  arrange(desc(count))

datatable(activity, options = list(scrollX = TRUE, scrollY = "500px"))
```


#### Doseg objava po izvoru 
```{r echo=F, eval=F, message=F , warning= FALSE}
# Portals by reach
reach <- dta %>%
  group_by(FROM) %>%
  summarise(reach = sum(REACH)) %>%
  arrange(desc(reach))

datatable(reach, options = list(scrollX = TRUE, scrollY = "500px"))
```

#### Like-ovi objava po izvoru 

```{r echo=F, eval=F, message=F , warning= FALSE}
# Portals by likes
like <- dta %>%
  group_by(FROM) %>%
  summarise(like = sum(LIKE_COUNT, na.rm = T)) %>%
  mutate(percent = round(like / sum(like) * 100,2)) %>% 
  arrange(desc(like))

datatable(like, options = list(scrollX = TRUE, scrollY = "500px"))
```


#### Komentari objava po izvoru 
```{r echo=F, eval=F, message=F , warning= FALSE}
# Portals by comments
comment <- dta %>%
  group_by(FROM) %>%
  summarise(comment = sum(COMMENT_COUNT, na.rm = T)) %>%
  mutate(percent = round(comment / sum(comment) * 100,2)) %>% 
  arrange(desc(comment))

datatable(comment, options = list(scrollX = TRUE, scrollY = "500px"))
```


#### Share-ovi objava po izvoru 
```{r echo=F, eval=F, message=F , warning= FALSE}
# Portals by shares
shares <- dta %>%
  group_by(FROM) %>%
  summarise(shares = sum(SHARE_COUNT, na.rm = T)) %>%
  mutate(percent = round(shares / sum(shares) * 100,2)) %>% 
  arrange(desc(shares))

datatable(shares, options = list(scrollX = TRUE, scrollY = "500px"))
```


#### Text analysis 

```{r echo=F, eval=T, message=F , warning= FALSE}
# read in lexicons
CroSentilex_n <- read.delim("C:/Users/Lukas/Dropbox/Mislav@Luka/crosentilex-negatives.txt",
                                   header = FALSE,
                                   sep = " ",
                                   stringsAsFactors = FALSE,
                                   fileEncoding = "UTF-8")  %>%
                   rename(word = "V1", sentiment = "V2" ) %>%
                   mutate(brija = "NEG")
 
CroSentilex_p  <- read.delim("C:/Users/Lukas/Dropbox/Mislav@Luka/crosentilex-positives.txt",
                                   header = FALSE,
                                   sep = " ",
                                   stringsAsFactors = FALSE,
                                   fileEncoding = "UTF-8") %>%
                    rename(word = "V1", sentiment = "V2" ) %>%
                    mutate(brija = "POZ")
 
Crosentilex_sve <- rbind(setDT(CroSentilex_n), setDT(CroSentilex_p))
# check lexicon data 
#head(sample_n(Crosentilex_sve,1000),15)

 
CroSentilex_Gold  <- read.delim2("C:/Users/Lukas/Dropbox/Mislav@Luka/gs-sentiment-annotations.txt",
                                 header = FALSE,
                                 sep = " ",
                                 stringsAsFactors = FALSE) %>%
                    rename(word = "V1", sentiment = "V2" ) 
 Encoding(CroSentilex_Gold$word) <- "UTF-8"
 CroSentilex_Gold[1,1] <- "dati"
 CroSentilex_Gold$sentiment <- str_replace(CroSentilex_Gold$sentiment , "-", "1")
 CroSentilex_Gold$sentiment <- str_replace(CroSentilex_Gold$sentiment , "\\+", "2")
 CroSentilex_Gold$sentiment <- as.numeric(unlist(CroSentilex_Gold$sentiment))
# check lexicon data 
#head(sample_n(CroSentilex_Gold,100),15)
 
# create stop words
stopwords_cro <- get_stopwords(language = "hr", source = "stopwords-iso")
# check stopwords data
#head(sample_n(stopwords_cro,100),15)
# extend stop words
my_stop_words <- tibble(
  word = c(
    "jedan","mjera", "može", "možete", "mogu", "kad", "sada", "treba", "ima", "osoba",
    "e","prvi", "dva","dvije","drugi",
    "tri","treći","pet","kod",
    "ove","ova",  "ovo","bez", "kod",
    "evo","oko",  "om", "ek",
    "mil","tko","šest", "sedam",
    "osam",   "čim", "zbog",
    "prema", "dok","zato", "koji", 
    "im", "čak","među", "tek",
    "koliko", "tko","kod","poput", 
    "baš", "dakle", "osim", "svih", 
    "svoju", "odnosno", "gdje",
    "kojoj", "ovi", "toga",
     "ubera", "vozača", "hrvatskoj", "usluge", "godine", "više", "taksi", "taxi", "taksija", "taksija", "kaže", "rekao", "19"," aee", "ae","bit.ly", "https", "one", "the"
  ),
  lexicon = "lux"
)
stop_corpus <- my_stop_words %>%
  bind_rows(stopwords_cro)
# check stopwords data
#head(sample_n(stop_corpus,100),15)
```




#### Tokenizirani tekst prije i nakon čišćenja (broj riječi)

```{r echo=F, eval=T, message=F , warning= FALSE}
# dim before tokenize
#dim(dta)

# tokenize
dta %>% 
  unnest_tokens(word, FULL_TEXT) -> n_token

# dim after tokenize
#dim(n_token)

# check
# fb_token %>% 
#   select(FROM, word, MENTION_SNIPPET ) %>%
#     sample_n(.,100)

# remove stop words, numbers, single letters
n_token %>% 
  anti_join(stop_corpus, by = "word") %>%
  mutate(word = gsub("\\d+", NA, word)) %>%
  mutate(word = gsub("^[a-zA-Z]$", NA, word)) -> n_tokenTidy
# remove NA
n_tokenTidy %>%
  filter(!is.na(word)) -> n_tokenTidy

# check
# fb_tokenTidy  %>% 
#   select(FROM, word, MENTION_SNIPPET ) %>%
#   sample_n(.,100)

# dim after clean
#dim(n_tokenTidy)

```


#### Najčešće riječi (>50)

```{r echo=F, eval=T, message=F , warning= FALSE, fig.height=25}
# ## Most common words
# n_tokenTidy[,.N,by = word][order(-N),] %>%
#   datatable(., options = list(scrollX = TRUE, scrollY = "500px"))

n_tokenTidy %>%
  group_by(word) %>%
  summarise(N = n()) %>%
  arrange(desc(N)) %>%
  filter(N > 50) %>%
  datatable(., options = list(scrollX = TRUE, scrollY = "500px"))


#unique(an_tokenTidy$FROM)


# an_tokenTidy <- n_tokenTidy %>%
#   group_by(word, FROM) %>%
#   summarise(N = n()) %>%
#   arrange(desc(N)) %>%
#   filter(N > 70) 




  
# ggplot(an_tokenTidy, aes(reorder(word, N), N, fill = FROM)) +
#   geom_col(show.legend = FALSE) +
#   ggtitle( "") +
#   labs( x = "Riječ", y = "Number of words") +
#   facet_wrap(~ FROM, scales = "free_y") +
#   coord_flip() +
#   theme_economist()






  
## Vizualize most common words
# fb_tokenTidy[,.N,by = word][N>10000][order(-N),][,word := reorder(word,N)] %>%
#   ggplot(aes(word, N)) +
#   geom_col() +
#   xlab(NULL) +
#   coord_flip() +
#   theme_economist()
# 
# ## Vizualize most common words over time
# fb_tokenTidy[,DAY:=floor_date(DATE,"day")][,N:=.N,by=DAY][,gn:=sum(N)][
#   word %in% c("ukrajini", "pomoć", "humanitarnu", "udruga", "prava"),] %>%
#   ggplot(., aes(DAY,  N / gn)) + 
#    geom_point() +
#    ggtitle("Učestalost korištenja riječi") +
#    ylab("% ukupnih riječi") +
#    geom_smooth() +
#    facet_wrap(~ word, scales = "free_y") +
#    scale_y_continuous(labels = scales::percent_format())+
#    theme_economist()

```

#### jutarnji.hr
```{r echo=F, eval=T, message=F , warning= FALSE, fig.height=25}
n_tokenTidy %>%
  filter(FROM == "jutarnji.hr") %>%
  group_by(word) %>%
  summarise(N = n()) %>%
  arrange(desc(N))   %>%
  filter(N > 10) %>%
  datatable(., options = list(scrollX = TRUE, scrollY = "500px"))
```


#### telegram.hr
```{r echo=F, eval=T, message=F , warning= FALSE, fig.height=25}
n_tokenTidy %>%
  filter(FROM == "telegram.hr") %>%
  group_by(word) %>%
  summarise(N = n()) %>%
  arrange(desc(N))   %>%
  filter(N > 10) %>%
  datatable(., options = list(scrollX = TRUE, scrollY = "500px"))
```


#### vecernji.hr
```{r echo=F, eval=T, message=F , warning= FALSE, fig.height=25}
n_tokenTidy %>%
  filter(FROM == "vecernji.hr") %>%
  group_by(word) %>%
  summarise(N = n()) %>%
  arrange(desc(N))   %>%
  filter(N > 10) %>%
  datatable(., options = list(scrollX = TRUE, scrollY = "500px"))
```


#### index.hr
```{r echo=F, eval=T, message=F , warning= FALSE, fig.height=25}
n_tokenTidy %>%
  filter(FROM == "index.hr") %>%
  group_by(word) %>%
  summarise(N = n()) %>%
  arrange(desc(N))   %>%
  filter(N > 10) %>%
  datatable(., options = list(scrollX = TRUE, scrollY = "500px"))
```




```{r echo=F, eval=T, message=F , warning= FALSE}
## WordCloud(vulgaris)
n_tokenTidy %>%
  anti_join(CroSentilex_Gold,by="word") %>% 
  count(word) %>% 
  arrange(desc(n)) %>%
  top_n(200) %>%
  with(wordcloud(word, n, max.words = 80)) 
```


#### Sentiment

```{r echo=F, eval=F, message=F , warning= FALSE}
## Sentiment over time
vizualiziraj_sentiment <- function(dataset, frq = "week") {
dataset %>%
  inner_join( Crosentilex_sve, by = "word") %>%
  filter(!is.na(word)) %>%
  select(word, brija, DATE, sentiment) %>% 
  unique() %>%
  spread(. , brija, sentiment) %>%
  mutate(sentiment = POZ - NEG) %>%
  select(word, DATE, sentiment) %>% 
  group_by(word) %>% 
  mutate(count = n()) %>%
  arrange(desc(count)) %>%
  mutate( score = sentiment*count) %>%
  ungroup() %>%
  group_by(DATE) %>%
  arrange(desc(DATE)) -> sm
 
sm %>%
  select(DATE, score) %>%
  group_by(DATE = floor_date(DATE, frq)) %>%
  summarise(Dnevni_sent = sum(score, na.rm = TRUE)) %>%
  ggplot(., aes(DATE, Dnevni_sent)) +
  geom_bar(stat = "identity") + 
  ggtitle(paste0("Sentiment over time;freqency:", frq)) +
  ylab("SentimentScore") +
  theme_economist()-> gg_sentiment_kroz_vrijeme_qv
gg_sentiment_kroz_vrijeme_qv
}
vizualiziraj_sentiment(fb_tokenTidy,"week")
```

```{r echo=F, eval=T, message=F , warning= FALSE, fig.width=12}
## Sentiment 
doprinos_sentimentu <- function(dataset, no = n) {
dataset %>%
  inner_join(CroSentilex_Gold, by = "word") %>% 
  count(word, sentiment,sort = TRUE) %>% 
  group_by(sentiment) %>%
  top_n(no) %>%
  ungroup() %>%
  mutate(sentiment = case_when(sentiment == 0 ~ "NEUTRAL",
                                 sentiment == 1 ~ "NEGATIVE",
                                 sentiment == 2 ~ "POSITIVE")) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  ggtitle( "Sentiment") +
  labs( x = "Riječ", y = "Number of words") +
  facet_wrap(~ sentiment, scales = "free_y") +
  coord_flip() +
  theme_economist() -> gg_doprinos_sentimentu
  
 gg_doprinos_sentimentu
 
}
doprinos_sentimentu(n_tokenTidy,30)
```

##### svi
```{r echo=F, eval=T, message=F , warning= FALSE}
## ComparisonCloud
n_tokenTidy %>%
  inner_join(CroSentilex_Gold,by="word") %>% 
  count(word, sentiment) %>% 
  top_n(200) %>%
  mutate(sentiment = case_when(sentiment == 0 ~ "+/-",
                                 sentiment == 1 ~ "-",
                                 sentiment == 2 ~ "+")) %>%
  acast(word ~ sentiment, value.var = "n", fill = 0) %>%
  comparison.cloud(colors = c("firebrick3", "deepskyblue3","darkslategray"),
                   max.words = 120)

```

##### vecernji
```{r echo=F, eval=T, message=F , warning= FALSE}

n_tokenTidy %>%
  filter(FROM == "vecernji.hr") %>%
  inner_join(CroSentilex_Gold,by="word") %>% 
  count(word, sentiment) %>% 
  top_n(200) %>%
  mutate(sentiment = case_when(sentiment == 0 ~ "+/-",
                                 sentiment == 1 ~ "-",
                                 sentiment == 2 ~ "+")) %>%
  acast(word ~ sentiment, value.var = "n", fill = 0) %>%
  comparison.cloud(colors = c("firebrick3", "deepskyblue3","darkslategray"),
                   max.words = 120)

```

##### index
```{r echo=F, eval=T, message=F , warning= FALSE}
n_tokenTidy %>%
  filter(FROM == "index.hr") %>%
  inner_join(CroSentilex_Gold,by="word") %>% 
  count(word, sentiment) %>% 
  top_n(200) %>%
  mutate(sentiment = case_when(sentiment == 0 ~ "+/-",
                                 sentiment == 1 ~ "-",
                                 sentiment == 2 ~ "+")) %>%
  acast(word ~ sentiment, value.var = "n", fill = 0) %>%
  comparison.cloud(colors = c("firebrick3", "deepskyblue3","darkslategray"),
                   max.words = 120)

```

##### index
```{r echo=F, eval=F, message=F , warning= FALSE}
n_tokenTidy %>%
  filter(FROM == "index.hr") %>%
  inner_join(CroSentilex_Gold,by="word") %>% 
  count(word, sentiment) %>% 
  top_n(200) %>%
  mutate(sentiment = case_when(sentiment == 0 ~ "+/-",
                                 sentiment == 1 ~ "-",
                                 sentiment == 2 ~ "+")) %>%
  acast(word ~ sentiment, value.var = "n", fill = 0) %>%
  comparison.cloud(colors = c("firebrick3", "deepskyblue3","darkslategray"),
                   max.words = 120)

```

##### 24h
```{r echo=F, eval=F, message=F , warning= FALSE}
n_tokenTidy %>%
  filter(FROM == "slobodnadalmacija.hr") %>%
  inner_join(CroSentilex_Gold,by="word") %>% 
  count(word, sentiment) %>% 
  top_n(200) %>%
  mutate(sentiment = case_when(sentiment == 0 ~ "+/-",
                                 sentiment == 1 ~ "-",
                                 sentiment == 2 ~ "+")) %>%
  acast(word ~ sentiment, value.var = "n", fill = 0) %>%
  comparison.cloud(colors = c("firebrick3", "deepskyblue3","darkslategray"),
                   max.words = 120)

```




```{r echo=F, eval=F, message=F , warning= FALSE}
## Negative profiles
wCount <- n_tokenTidy %>% 
  group_by(FROM) %>%
  summarise(word = n())
CroSentilex_Gold_neg <- CroSentilex_Gold %>% filter(sentiment == 1)
CroSentilex_Gold_poz <- CroSentilex_Gold %>% filter(sentiment == 2)
n_tokenTidy %>% 
  semi_join(CroSentilex_Gold_neg, by= "word") %>%
  group_by(FROM) %>% 
  summarise(negWords = n()) %>%
  left_join(wCount, by = "FROM") %>%
  mutate(negativnostIndex = (negWords/word)*100) %>%
  arrange(desc(negativnostIndex)) %>%
  select(FROM, negativnostIndex)  %>%
  datatable(., options = list(scrollX = TRUE, scrollY = "500px"))
```

```{r echo=F, eval=F, message=F , warning= FALSE}
## Najpozitivniji portali
CroSentilex_Gold_poz <- CroSentilex_Gold %>% filter(sentiment == 2)
n_tokenTidy %>% 
  semi_join(CroSentilex_Gold_poz, by= "word") %>%
  group_by(FROM) %>% 
  summarise(pozWords = n()) %>%
  left_join(wCount, by = "FROM") %>%
  mutate(pozitivnostIndex = (pozWords/word)*100) %>%
  arrange(desc(pozitivnostIndex)) %>%
  select(FROM, pozitivnostIndex)  %>%
  datatable(., options = list(scrollX = TRUE, scrollY = "500px"))
```



```{r echo=F, eval=F, message=F , warning= FALSE, fig.width=12}
# Select postes with +5k likes
dta[order(-LIKE_COUNT)][LIKE_COUNT >= 500] -> fb_TopLike
# check
dim(fb_TopLike)
# influencer activity
fb_TopLike[,.N,FROM][order(-N)]
# influencer by like
fb_TopLike[,.(FROM, LIKE_COUNT)][,LIKES := sum(LIKE_COUNT),FROM][,.(FROM,LIKES)][order(-LIKES)] %>% unique()

# tokenize
fb_TopLike %>% 
  unnest_tokens(word, FULL_TEXT) -> fb_token_TopLike

# dim after tokenize
dim(fb_token_TopLike)

# remove stop words, numbers, single letters
fb_token_TopLike %>% 
  anti_join(stop_corpus, by = "word") %>%
  mutate(word = gsub("\\d+", NA, word)) %>%
  mutate(word = gsub("^[a-zA-Z]$", NA, word)) -> fb_tokenTidy_TopLike
# remove NA
fb_tokenTidy_TopLike %>%
  filter(!is.na(word)) -> fb_tokenTidy_TopLike


## most common words
fb_tokenTidy_TopLike[,.N,by = word][order(-N),]
## word cloud
# fb_tokenTidy_TopLike %>%
#   anti_join(CroSentilex_Gold,by="word") %>% 
#   count(word) %>% 
#   arrange(desc(n)) %>%
#   top_n(100) %>%
#   with(wordcloud(word, n, max.words = 120)) 

```

#### Term importance (najbitnije riječi po portalima)

```{r frekvencija, eval = T, echo = F, message=F, warning=F, fig.height=10, fig.width=12}
## Udio riječi po domenama
domenaWords <- n_tokenTidy %>%
  filter(FROM %in% c("vecernji.hr", "jutarnji.hr", "telegram.hr", "index.hr", "slobodnadalmacija.hr")) %>% 
  count(FROM, word, sort = T)
  
ukupnoWords <- domenaWords %>%
  group_by(FROM) %>%
  summarise(totWords = sum(n))
domenaWords <- left_join(domenaWords, ukupnoWords)
# domenaWords %>% head(15)
# domenaWords %>% 
# ggplot(., aes(n/totWords, fill = domena)) +
#   geom_histogram(show.legend = FALSE) +
#   xlim(NA, 0.0009) +
#   facet_wrap(~domena, ncol = 2, scales = "free_y")
## Najbitnije riječi po domenma
idf <- domenaWords %>%
  bind_tf_idf(word, FROM, n)
#idf %>% head(10)
# idf %>% 
#   select(-totWords) %>%
#   arrange(desc(tf_idf))
idf %>%
  arrange(desc(tf_idf)) %>%
  mutate(word = factor(word, levels = rev(unique(word)))) %>% 
  mutate(FROM = factor(FROM)) %>%
  group_by(FROM) %>% 
  top_n(20) %>% 
  ungroup() %>%
  ggplot(aes(word, tf_idf, fill = FROM)) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = "tf-idf") +
  facet_wrap(~FROM, ncol = 2, scales = "free") +
  coord_flip() +
  theme_economist()
```


#### Phrases

```{r eval = T, echo = F, message=F, warning=F, fig.height=15, fig.width=15}
fb_bigram <- dta %>%
  unnest_tokens(bigram, FULL_TEXT, token = "ngrams", n = 2)
#fb_bigram %>% head(10)
# fb_bigram %>%
#   count(bigram, sort = T) %>%
#   head(25) 
fb_bigram_sep <- fb_bigram %>%
  separate(bigram, c("word1","word2"), sep = " ")
fb_bigram_tidy <- fb_bigram_sep %>%
  filter(!word1 %in% stop_corpus$word) %>%
  filter(!word2 %in% stop_corpus$word) %>%
  mutate(word1 = gsub("\\d+", NA, word1)) %>%
  mutate(word2 = gsub("\\d+", NA, word2)) %>%
  mutate(word1 = gsub("^[a-zA-Z]$", NA, word1)) %>%
  mutate(word2 = gsub("^[a-zA-Z]$", NA, word2)) 
fb_bigram_tidy_bigram_counts <- fb_bigram_tidy %>% 
  count(word1, word2, sort = TRUE)

bigrams_united <- fb_bigram_tidy %>%
  unite(bigram, word1, word2, sep = " ") %>%
  filter(., !grepl("NA",bigram))
#bigrams_united
bigrams_united %>% 
  count(FROM,bigram,sort = T) -> topicBigram

bigrams_united %>%
  count(bigram, sort = T) %>%
  filter(n>10)
```


##### Skupno
```{r eval = T, echo = F, message=F, warning=F, fig.height=15, fig.width=15}


# Najvažniji bigrami po domenama
 bigram_tf_idf <- bigrams_united %>% 
#  filter (!is.na(bigram)) %>%
  count(FROM, bigram) %>%
  bind_tf_idf(bigram, FROM, n) %>%
  arrange(desc(tf_idf))

bigram_tf_idf %>%
  arrange(desc(tf_idf)) %>%
  filter(tf_idf > 0.09) %>%
  mutate(bigram = factor(bigram, levels = rev(unique(bigram)))) %>% 
#  group_by(FROM) %>% 
#  top_n(20) %>% 
  ungroup() %>%
  ggplot(aes(bigram, tf_idf, fill = FROM)) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = "tf-idf") +
#  facet_wrap(~FROM, ncol = 2, scales = "free") +
  coord_flip() + 
  theme_economist()

```

#### Domene

```{r eval = T, echo = F, message=F, warning=F, fig.height=15, fig.width=15}

bigram_tf_idf %>%
  filter(FROM %in% c("vecenji.hr", "jutarnji.hr", "24sata.hr", "telegram.hr")) %>%
  arrange(desc(tf_idf)) %>%
  mutate(bigram = factor(bigram, levels = rev(unique(bigram)))) %>% 
  group_by(FROM) %>% 
  top_n(10) %>% 
  ungroup() %>%
  ggplot(aes(bigram, tf_idf, fill = FROM)) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = "tf-idf") +
  facet_wrap(~FROM, ncol = 2, scales = "free") +
  coord_flip() + 
  theme_economist()

```

#### PHRASES CORRELATION

```{r echo=F, eval = F,message=F, warning=F, fig.height=12, fig.width=12}

n_tokenTidy %>% 
#  filter(datum > "2020-02-20") %>%
  group_by(word) %>%
  filter(n() > 20) %>%
  filter(!is.na(word)) %>%
  pairwise_cor(word,DATE, sort = T) -> corsWords
#corsWords %>%
#  filter(item1 == "oporavak")
corsWords %>%
  filter(item1 %in% c("bolest", "rizik", "strah")) %>%
  group_by(item1) %>%
  top_n(10) %>%
  ungroup() %>%
  mutate(item2 = reorder(item2, correlation)) %>%
  ggplot(aes(item2, correlation)) +
  geom_bar(stat = "identity") +
  facet_wrap(~ item1, scales = "free") +
  coord_flip() + 
  theme_economist()

```


### TEMATIC ANALYSIS (moguće napraviti i po portalima)


```{r echo=F, eval=T, message=F , warning= FALSE, fig.height=12, fig.width=12}
n_tokenTidy %>%
  count(FROM, word, sort = TRUE) %>%
  cast_dtm(FROM, word,n) -> dtm
fb_LDA <- LDA(dtm, k = 3,  control = list(seed = 1234))
fb_LDA_tidy <- tidy(fb_LDA, matrix = "beta")
#newsCOVID_LDA_tidy
insta_terms <- fb_LDA_tidy %>%
  drop_na(.) %>%
  group_by(topic) %>%
  top_n(15, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)
#newsCOVID_terms
insta_terms %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip() +
  scale_x_reordered() + 
  theme_economist()
```


```{r echo=F, eval=F, message=F , warning= FALSE}
bitokens <- dta %>%
  unnest_tokens(bigram, FULL_TEXT, token = "ngrams", n = 2)


bitokens %>% head(10)

bitokens %>%
  count(bigram, sort = T) %>%
  head(15)


bitokens_sep <- bitokens %>%
  separate(bigram, c("word1","word2"), sep = " ")


bitokens_sep_tidy <- bitokens_sep %>%
  filter(!word1 %in% stop_corpus$word) %>%
  filter(!word2 %in% stop_corpus$word) %>%
  mutate(word1 = gsub("\\d+", NA, word1)) %>%
  mutate(word2 = gsub("\\d+", NA, word2)) %>%
  mutate(word1 = gsub("^[a-zA-Z]$", NA, word1)) %>%
  mutate(word2 = gsub("^[a-zA-Z]$", NA, word2)) %>%
  filter(!is.na(word1)) %>%
  filter(!is.na(word2))




bitokens_sep_counts <- bitokens_sep_tidy %>% 
  count(word1, word2, sort = TRUE)

bigrams_united <- bitokens_sep_counts %>%
  unite(bigram, word1, word2, sep = " ")
#bigrams_united


bigrams_united %>% 
  count(FROM,bigram,sort = T) -> topicBigram
# Najvažniji bigrami po domenama
 bigram_tf_idf <- bigrams_united %>%
  count(FROM, bigram) %>%
  bind_tf_idf(bigram, FROM, n) %>%
  arrange(desc(tf_idf))
bigram_tf_idf %>%
  filter(FROM %in% c("elladvornik", "imerovic_sandi_budivelik", "elaajerkovic" )) %>%
  arrange(desc(tf_idf)) %>%
  mutate(bigram = factor(bigram, levels = rev(unique(bigram)))) %>% 
  group_by(FROM) %>% 
  top_n(7) %>% 
  ungroup() %>%
  ggplot(aes(bigram, tf_idf, fill = FROM)) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = "tf-idf") +
  facet_wrap(~FROM, ncol = 2, scales = "free") +
  coord_flip() + 
  theme_economist()
```




## Pregled varijabli prema DD


### Industrija
```{r  echo=F, eval=T, message=F , warning= FALSE}

industry_list <- data.frame(
  id = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28),
  category = c(
    "Financijska industrija",
    "Građevinska industrija",
    "Moda i ljepota",
    "Politička institucija",
    "Sportska industrija",
    "Zdravlje",
    "Obrazovanje i znanost",
    "Tehnologija",
    "Auto-moto industrija",
    "ICT",
    "Kultura i umjetnost",
    "Turizam, odmor, putovanja, ugostiteljstvo",
    "Energetska industrija",
    "Prehrambena industrija",
    "Industrija bezalkoholnih pića",
    "Alkoholna pića",
    "Nekretninska industrija",
    "Maloprodajna trgovina",
    "Igre na sreću",
    "Medijske kuće i marketinške, digitalne agencije",
    "Namještaj, saloni namještaja, kućanske potrepštine, kućanski uređaji, sredstva za čišćenje",
    "Trgovački / shopping centri",
    "Glazbena industrija",
    "Filmska industrija",
    "Brodogradnja",
    "Pošta / distribucija pošiljki",
    "Komunalne usluge"
  )
)




# Create a histogram of the 'price' variable in the 'diamonds' dataset
ggplot(data = dta, aes(x = INDUSTRIJA)) +
  geom_histogram(binwidth = 1, fill = "blue", alpha = 0.7) +
  ggtitle("Industrija") +
  xlab("Industrija") +
  ylab("Frequency") +
  scale_x_continuous(breaks = seq(from = min(dta$INDUSTRIJA), to =  max(dta$INDUSTRIJA), by = 1))







```




### Porijeklo

```{r echo=F, eval=T, message=F , warning= FALSE}



ggplot(data = dta, aes(x = HRV.IL.STRANI.BREND)) +
  geom_histogram(binwidth = 0.5, fill = "blue", alpha = 0.7) +
  ggtitle("Porijeklo") +
  xlab("Industrija") +
  ylab("Frequency") +
  scale_x_continuous(breaks = seq(from = min(dta$HRV.IL.STRANI.BREND), to =  max(dta$HRV.IL.STRANI.BREND), by = 1))



```



### Brend

```{r echo=F, eval=T, message=F , warning= FALSE}

dta %>% 
  group_by(NAZIV.BRENDA) %>%
  summarise(BrojObjava = n()) %>% 
  arrange(desc(BrojObjava)) %>%
  datatable(., options = list(scrollX = TRUE, scrollY = "500px"))



```



### Premium

```{r echo=F, eval=T, message=F , warning= FALSE}



ggplot(data = dta, aes(x = PREMIUM.ČLANAK)) +
  geom_histogram(binwidth = 0.5, fill = "blue", alpha = 0.7) +
  ggtitle("Porijeklo") +
  xlab("Industrija") +
  ylab("Frequency") +
  scale_x_continuous(breaks = seq(from = min(dta$PREMIUM.ČLANAK), to =  max(dta$PREMIUM.ČLANAK), by = 1))




```

### Autorstvo

```{r echo=F, eval=T, message=F , warning= FALSE}


autorstvo <- data.frame(
  number = c(1, 2, 3, 4, 5, 6, 7, 8),
  text = c(
    "Redakcija / redakcijski izvještaj",
    "Inicijali novinara",
    "Autor, puno ime i prezime",
    "Sponzorirani sadržaj / PR / PR sadržaj",
    "Native team / studio",
    "Ime i prezime autora / sponzorirani sadržaj",
    "Nije naveden autor",
    "Organizacija / udruga / tvrtka / zajednica"
  )
)

dta %>% 
  group_by(AUTORSTVO) %>%
  summarise(BrojObjava = n()) %>% 
  arrange(desc(BrojObjava)) %>%
  left_join(autorstvo, by = c("AUTORSTVO" = "number")) %>%
  datatable(., options = list(scrollX = TRUE, scrollY = "500px"))
```


### Rubrika



```{r echo=F, eval=T, message=F , warning= FALSE}




rubrika <- data.frame(
  number = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18),
  text = c(
    "Native",
    "Partneri",
    "Promo",
    "Vijesti",
    "Vanjska politika",
    "Unutarnja politika",
    "Magazin / mozaik / zabava",
    "Financije / novac / biznis / poduzetnički savjetnik",
    "Dom i dizajn",
    "Lifestyle / estrada / celebrity / scena / showbiz",
    "Auto-moto",
    "Sport",
    "Tehnologija / znanost (tech-sci)",
    "Putovanja",
    "Prehrana / gastro / dobra hrana",
    "Lokalna rubrika (Zagreb, Dalmacija)",
    "Zdravlje, zdrav život",
    "Openspace (Telegram.hr)"
  )
)

dta %>% 
  group_by(RUBRIKA) %>%
  summarise(BrojObjava = n()) %>% 
  arrange(desc(BrojObjava)) %>%
  left_join(rubrika, by = c("RUBRIKA" = "number")) %>%
  datatable(., options = list(scrollX = TRUE, scrollY = "500px"))

rubr <- dta %>% 
  group_by(RUBRIKA) %>%
  summarise(BrojObjava = n()) %>% 
  arrange(desc(BrojObjava)) %>%
  left_join(rubrika, by = c("RUBRIKA" = "number"))


rubr

ggplot(data = dta, aes(x = RUBRIKA)) +
  geom_histogram(binwidth = 1, fill = "blue", alpha = 0.7) +
  ggtitle("Rubrika") +
  xlab("Rubrika") +
  ylab("Frequency") +
  scale_x_continuous(breaks = seq(from = min(dta$RUBRIKA), to =  max(dta$RUBRIKA), by = 1))
```


### Clickbait


```{r echo=F, eval=T, message=F , warning= FALSE}

clickbait <- data.frame(
  number = c(1, 2, 3, 4, 5, 6, 7),
  text = c("Nedefinirane zamjenice", "Neizvjesnost", "Stil obrnutog narativa",
           "Naglašavanje emocija", "Korištenje brojkama", "Više kombinacija",
           "Nije clickbait naslov")
)
dta %>% 
  group_by(CLICKBAIT) %>%
  summarise(BrojObjava = n()) %>% 
  arrange(desc(BrojObjava)) %>%
  left_join(clickbait, by = c("CLICKBAIT" = "number")) %>%
  datatable(., options = list(scrollX = TRUE, scrollY = "500px"))





```




### Brend u naslovu

```{r}
ggplot(data = dta, aes(x = ZASTUPLJENOST.BRENDA)) +
  geom_histogram(binwidth = 0.5, fill = "blue", alpha = 0.7) +
  ggtitle("Brend u naslovu") +
  xlab("Brend u naslovu") +
  ylab("Frequency")+
  scale_x_continuous(breaks = seq(from = min(dta$ZASTUPLJENOST.BRENDA), to =  max(dta$ZASTUPLJENOST.BRENDA), by = 1))
```


### Vrsta rečenice naslovu

```{r}

df_sentence_type <- data.frame(
  number = c(1, 2, 3),
  text = c("Izjavna", "Upitna", "Usklična")
)


ggplot(data = dta, aes(x = VRSTA.REČENICE)) +
  geom_histogram(binwidth = 0.5, fill = "blue", alpha = 0.7) +
  ggtitle("Vrsta rečenice naslovu") +
  xlab("Rečenica u naslovu") +
  ylab("Frequency")+
  scale_x_continuous(breaks = seq(from = min(dta$VRSTA.REČENICE), to =  max(dta$VRSTA.REČENICE), by = 1))
```




### Oprema


```{r echo=F, eval=T, message=F , warning= FALSE}

oprema <- data.frame(
  number = c(1, 2, 3, 4, 5, 6, 7, 8),
  text = c(
    "Foto-sadržaj",
    "Video-sadržaj",
    "Grafika ili infografika (ne uključuje logo)",
    "Foto i video sadržaj",
    "Foto i grafički sadržaj",
    "Video i grafički sadržaj",
    "Foto, video i grafički sadržaj",
    "Članak nema nikakvu opremu"
  )
)

dta %>% 
  group_by(OPREMA) %>%
  summarise(BrojObjava = n()) %>% 
  arrange(desc(BrojObjava)) %>%
  left_join(oprema, by = c("OPREMA" = "number")) %>%
  datatable(., options = list(scrollX = TRUE, scrollY = "500px"))





```




### Vizualni identitet

```{r echo=F, eval=T, message=F , warning= FALSE}
ggplot(data = dta, aes(x = VIZUALNI.IDENTITET)) +
  geom_histogram(binwidth = 0.5, fill = "blue", alpha = 0.7) +
  ggtitle("Vizualni identitet") +
  xlab("Vizualni identitet") +
  ylab("Frequency")+
  scale_x_continuous(breaks = seq(from = min(dta$VIZUALNI.IDENTITET), to =  max(dta$VIZUALNI.IDENTITET), by = 1))
```


### Poveznice


```{r echo=F, eval=T, message=F , warning= FALSE}

poveznice <- data.frame(
  number = c(1, 2, 3, 4, 5, 6),
  text = c(
    "Društvene mreže",
    "Službena internetska stranica brenda",
    "Neka druga poveznica (druga web stranica)",
    "Članak ne sadrži poveznice na kanale brenda / oglašivača",
    "Kolaboracija (Oglašivač + neki drugi brend)",
    "Više kombinacija"
  )
)
dta %>% 
  group_by(POVEZNICE.KANALI) %>%
  summarise(BrojObjava = n()) %>% 
  arrange(desc(BrojObjava)) %>%
  left_join(poveznice, by = c("POVEZNICE.KANALI" = "number")) %>%
  datatable(., options = list(scrollX = TRUE, scrollY = "500px"))





```



### Izvori

```{r echo=F, eval=T, message=F , warning= FALSE}


izvori <- data.frame(
  number = c(1, 2, 3, 4, 5, 6, 7),
  text = c(
    "Nema izvora / izjave",
    "Izvor iz organizacije / tvrtke",
    "Brend ambasador",
    "Influencer, celebrity, slavna / poznata osoba",
    "Korisnik proizvoda ili usluge (poduzetnik, Marica iz Benkovca)",
    "Više izvora",
    "Izvor nepovezan s proizvodom ili uslugom koja se promovira"
  )
)

dta %>% 
  group_by(IZVORI...IZJAVE) %>%
  summarise(BrojObjava = n()) %>% 
  arrange(desc(BrojObjava)) %>%
  left_join(izvori, by = c("IZVORI...IZJAVE" = "number")) %>%
  datatable(., options = list(scrollX = TRUE, scrollY = "500px"))







```



### Formulacija uz izvor
####(možemo napraviti analizu teksta ako smatrate da ćemo naći nešto)

```{r  echo=F, eval=T, message=F , warning= FALSE}
dta %>% 
  group_by(FORMULACIJA.UZ.IZVOR) %>%
  summarise(BrojObjava = n()) %>% 
  arrange(desc(BrojObjava))%>%
  datatable(., options = list(scrollX = TRUE, scrollY = "500px"))
```


### Sentiment

```{r echo=F, eval=T, message=F , warning= FALSE}


sentiment <- data.frame(
  number = c(1, 2, 3),
  text = c("Pozitivan", "Neutralan", "Negativan")
)


ggplot(data = dta, aes(x = SENTIMENT)) +
  geom_histogram(binwidth = 0.5, fill = "blue", alpha = 0.7) +
  ggtitle("Sentiment") +
  xlab("Sentiment") +
  ylab("Frequency")+
  scale_x_continuous(breaks = seq(from = min(dta$SENTIMENT), to =  max(dta$SENTIMENT), by = 1))
```





### Doseg
####( ne razumijem odakle ste vadili doseg)
```{r echo=F, eval=T, message=F , warning= FALSE}


doseg <- data.frame(
  number = c(1, 2, 3, 4, 5, 6, 7),
  text = c(
    "0 - 2 000",
    "2 000 - 5 000",
    "5 000 - 10 000",
    "10 000 - 20 000",
    "20 000 - 50 000",
    "50 000 - 100 000",
    "100 000 - 200 000"
  )
)

dta %>% 
  group_by(DOSEG.PUBLIKE) %>%
  summarise(BrojObjava = n()) %>% 
  arrange(desc(BrojObjava)) %>%
  left_join(doseg, by = c("DOSEG.PUBLIKE" = "number")) %>%
  datatable(., options = list(scrollX = TRUE, scrollY = "500px"))


dta %>%
  filter(DOSEG.PUBLIKE == 6) %>%
  select(URL)

```




### Lajkovi


####( ne razumijem odakle ste vadili doseg)
```{r echo=F, eval=T, message=F , warning= FALSE}


lajkovi <- data.frame(
  number = c(1, 2, 3, 4, 5, 6, 7),
  text = c(
    "0 - 20",
    "20 - 50",
    "50 - 100",
    "100 - 200",
    "200 - 500",
    "500 - 1000",
    "1 000 - 2000"
  )
)

dta %>% 
  group_by(BROJ.LAJKOVA) %>%
  summarise(BrojObjava = n()) %>% 
  arrange(desc(BrojObjava)) %>%
  left_join(lajkovi, by = c("BROJ.LAJKOVA" = "number")) %>%
  datatable(., options = list(scrollX = TRUE, scrollY = "500px"))

dta %>%
  filter(BROJ.LAJKOVA == 6 ) %>%
  select(URL)

dta %>%
  filter(BROJ.LAJKOVA == 7 ) %>%
  select(URL)
```


### Komentari

```{r echo=F, eval=T, message=F , warning= FALSE}
komentari <- data.frame(
  number = c(1, 2, 3, 4, 5, 6, 7, 8),
  text = c(
    "0 - 2",
    "2 - 5",
    "5 - 10",
    "10 - 20",
    "20 - 50",
    "50 - 100",
    "100 - 200",
    "200 - 500"
  )
)


dta %>% 
  group_by(BROJ.KOMENTARA) %>%
  summarise(BrojObjava = n()) %>% 
  arrange(desc(BrojObjava)) %>%
  left_join(komentari, by = c("BROJ.KOMENTARA" = "number")) %>%
  datatable(., options = list(scrollX = TRUE, scrollY = "500px"))

dta %>%
  filter(BROJ.KOMENTARA == 7 ) %>%
  select(URL)

dta %>%
  filter(BROJ.KOMENTARA == 8 ) %>%
  select(URL)









```



### Interakcije

```{r echo=F, eval=T, message=F , warning= FALSE}
interakcije <- data.frame(
  number = c(1, 2, 3, 4, 5, 6, 7, 8),
  text = c(
    "0 - 20",
    "20 - 50",
    "50 - 100",
    "100 - 200",
    "200 - 500",
    "500 - 1000",
    "1 000 - 2000",
    "2 000 - 5 000"
  )
)


dta %>% 
  group_by(BROJ.INTERAKCIJA) %>%
  summarise(BrojObjava = n()) %>% 
  arrange(desc(BrojObjava)) %>%
  left_join(interakcije, by = c("BROJ.INTERAKCIJA" = "number")) %>%
  datatable(., options = list(scrollX = TRUE, scrollY = "500px"))

dta %>%
  filter(BROJ.INTERAKCIJA == 7 ) %>%
  select(URL)

dta %>%
  filter(BROJ.INTERAKCIJA == 8 ) %>%
  select(URL)


```






