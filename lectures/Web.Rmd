---
title: "Untitled"
author: "Lux"
date: "2023-04-25"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Library

```{r echo=FALSE, message=FALSE , warning= FALSE}
# Load only necessary libraries, remove redundant imports
library(tidyverse)  # Includes ggplot2, dplyr, tidyr, purrr, readr
library(readxl)     # For reading excel files
library(kableExtra) # For better table outputs
library(DT)         # For interactive tables
library(data.table) # For high-performance data manipulation
library(lubridate)  # For date handling
library(RMySQL)     # For MySQL connection
library(DBI)
library(RMySQL)
```

## Data


```{r echo=FALSE, message=FALSE, warning= FALSE}

# Connect to the database
conn <- dbConnect(
  RMySQL::MySQL(),
  dbname = "determ_all",
  host = "127.0.0.1",
  user = "Lux",
  password = "Theanswer0207",
  local_infile = TRUE
)

# Define the columns of interest
columns_of_interest <- c(
  "DATE", "TIME", "TITLE", "FROM_SITE", "AUTHOR", "URL", "URL_PHOTO", 
  "SOURCE_TYPE", "GROUP_NAME", "KEYWORD_NAME", "FOUND_KEYWORDS", 
  "LANGUAGES", "LOCATIONS", "TAGS", "MANUAL_SENTIMENT", "AUTO_SENTIMENT", 
  "MENTION_SNIPPET", "REACH", "VIRALITY", "ENGAGEMENT_RATE", "INTERACTIONS"
)

# Convert columns list to a string for SQL query
columns_string <- paste(columns_of_interest, collapse = ", ")

# Define the years to query and the corresponding tables
years <- 2021:2024
tables <- paste0("media_space_", years)

# Query data for each year and combine row-wise
data_list <- lapply(tables, function(table) {
  query <- sprintf("SELECT %s FROM %s WHERE SOURCE_TYPE = 'web'", columns_string, table)
  dbGetQuery(conn, query)
})

# Combine all dataframes row-wise
merged_df <- bind_rows(data_list)

# Disconnect from the database
dbDisconnect(conn)

# View the merged dataframe
print(merged_df)



```

## Basic descriptives

```{r echo=FALSE, message=FALSE , warning= FALSE, fig.width=15, fig.height=15}

# Use combined data for analysis
dta <- merged_df

# Date range
date_range <- range(dta$DATE)
print(date_range)

# Number of articles
num_articles <- nrow(dta)
# print with points for milions
print(num_articles, big.mark = ",")

# Articles over time
daily_counts <- dta %>%
  #group by day
  group_by(DATE) %>%
  #count number of articles
  summarise(count = n())
  
# Descriptive statistics
summ <- daily_counts %>% 
  summarize(
    min = min(count), max = max(count), 
    mean = mean(count), q1 = quantile(count, probs = 0.25), 
    median = median(count), q3 = quantile(count, probs = 0.75),
    sd = sd(count)
  ) %>%
  mutate_if(is.numeric, round, digits = 2)

print(summ)

# # Create plot of articles over time but first change DATE to date type
# 
# daily_counts$DATE <- as.Date(daily_counts$DATE)
# 
# # Plot the number of articles over time in bart chart
# ggplot(daily_counts, aes(x = DATE, y = count)) +
#   geom_bar(stat = "identity", fill = "skyblue") +
#   labs(title = "Number of articles over time", x = "Date", y = "Number of articles") +
#   theme_minimal() +
#   theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

## Portals Analysis

```{r echo=FALSE, message=FALSE , warning=FALSE}
# Portals by activity
activity <- dta %>%
  group_by(FROM_SITE) %>%
  summarise(count = n()) %>%
  mutate(percent = round(count / sum(count) * 100, 2)) %>% 
  arrange(desc(count))

datatable(activity, options = list(scrollX = TRUE, scrollY = "500px"))
```

## Portals Metrics

```{r echo=FALSE, message=FALSE , warning=FALSE}
# Function to summarize metrics by portals
summarize_portal_metrics <- function(metric_column, metric_name) {
  dta %>%
    group_by(FROM_SITE) %>%
    summarise(metric = sum({{ metric_column }}, na.rm = TRUE)) %>%
    mutate(percent = round(metric / sum(metric) * 100, 2)) %>% 
    arrange(desc(metric)) %>%
    rename(!!metric_name := metric)
}

# Portals by reach
reach <- summarize_portal_metrics(REACH, "reach")
datatable(reach, options = list(scrollX = TRUE, scrollY = "500px"))

# Portals by likes
virality <- summarize_portal_metrics(VIRALITY, "virality")
datatable(virality, options = list(scrollX = TRUE, scrollY = "500px"))

# Portals by comments
engage <- summarize_portal_metrics(ENGAGEMENT_RATE, "engagement_rate")
datatable(engage, options = list(scrollX = TRUE, scrollY = "500px"))

# Portals by shares
interaction <- summarize_portal_metrics(INTERACTIONS, "interactions")
datatable(interaction, options = list(scrollX = TRUE, scrollY = "500px"))
```

## Authors Analysis

```{r echo=FALSE, message=FALSE , warning=FALSE}
# Authors by activity
authors <- dta %>%
  group_by(AUTHOR) %>%
  summarise(count = n()) %>%
  mutate(percent = round(count / sum(count) * 100, 2)) %>% 
  arrange(desc(count))

datatable(authors, options = list(scrollX = TRUE, scrollY = "500px"))

# Authors by reach
authors_reach <- dta %>%
  group_by(AUTHOR) %>%
  summarise(reach = sum(REACH)) %>%
  arrange(desc(reach))

datatable(authors_reach, options = list(scrollX = TRUE, scrollY = "500px"))
```

## Articles Analysis

```{r echo=FALSE, message=FALSE , warning=FALSE, eval=TRUE}
# Articles by reach
articles_reach <- dta %>%
  group_by(TITLE) %>%
  summarise(reach = sum(REACH)) %>%
  arrange(desc(reach)) %>%
  slice(1:1000)

datatable(articles_reach, options = list(scrollX = TRUE, scrollY = "500px"))
```


## Articles

```{r echo=FALSE, message=FALSE , warning= FALSE, eval=FALSE}
# Articles by activity
articles <-  dta %>%
  group_by(TITLE) %>%
  summarise(count = n()) %>% 
  arrange(desc(count))

datatable(articles, options = list(scrollX = TRUE, scrollY = "500px"))

```

```{r echo=FALSE, message=FALSE , warning= FALSE, eval=T}
# Articles by reach
reach <- dta %>%
  group_by(TITLE) %>%
  summarise(reach = sum(REACH)) %>%
  arrange(desc(reach)) %>%
  slice(1:1000)

datatable(reach, options = list(scrollX = TRUE, scrollY = "500px"))
```


```{r echo=FALSE, message=FALSE , warning= FALSE, eval=T}
# Articles by likes
like <- dta %>%
  group_by(TITLE) %>%
  summarise(like = sum(LIKE_COUNT, na.rm = T)) %>%
  mutate(percent = round(like / sum(like) * 100,2)) %>% 
  arrange(desc(like)) %>%
  slice(1:1000)

datatable(like, options = list(scrollX = TRUE, scrollY = "500px"))
```

```{r echo=FALSE, message=FALSE , warning= FALSE, eval=T}
# Articles by comments
comment <- dta %>%
  group_by(TITLE) %>%
  summarise(comment = sum(COMMENT_COUNT, na.rm = T)) %>%
  mutate(percent = round(comment / sum(comment) * 100,2)) %>% 
  arrange(desc(comment)) %>%
  slice(1:1000)

datatable(comment, options = list(scrollX = TRUE, scrollY = "500px"))
```

```{r echo=FALSE, message=FALSE , warning= FALSE, eval=T}
# Arcicles by shares
shares <- dta %>%
  group_by(TITLE) %>%
  summarise(shares = sum(SHARE_COUNT, na.rm = T)) %>%
  mutate(percent = round(shares / sum(shares) * 100,2)) %>% 
  arrange(desc(shares)) %>%
  slice(1:1000)

datatable(shares, options = list(scrollX = TRUE, scrollY = "500px"))

```

## Humanitarne akcije

```{r echo=FALSE, message=FALSE , warning= FALSE, eval=T}

dt <- fread("D:/LUKA/Freelance/Mediatoolkit/Humanitar.csv") %>%
  select(-V1)

daily_counts <- dt %>%
  group_by(DATE) %>%
  summarise(count = n())

# descriptives 
summ <- daily_counts %>% 
  summarize(min = min(count), max = max(count), 
            mean = mean(count), q1= quantile(count, probs = 0.25), 
            median = median(count), q3= quantile(count, probs = 0.75),
            sd = sd(count)) %>%
  mutate_if(is.numeric, round, digits=2) 

summ

# create plot
ggplot(data = daily_counts, aes(x = DATE, y = count)) +
  geom_line() +
  labs(x = "Date", y = "Number of Articles")
 
```




```{r echo=FALSE, message=FALSE , warning= FALSE, eval=T}
activity <- dt %>%
  group_by(SOURCE_TYPE) %>%
  summarise(count = n()) %>%
  mutate(percent = round(count / sum(count) * 100,2)) %>% 
  arrange(desc(count))


datatable(activity, options = list(scrollX = TRUE, scrollY = "500px"))


```


## Web

```{r echo=FALSE, message=FALSE , warning= FALSE, eval=T}
# Portals by activity
activity <- dt %>%
  filter(SOURCE_TYPE == "web") %>%
  group_by(FROM) %>%
  summarise(count = n()) %>%
  mutate(percent = round(count / sum(count) * 100,2)) %>% 
  arrange(desc(count))

datatable(activity, options = list(scrollX = TRUE, scrollY = "500px"))
```

```{r echo=FALSE, message=FALSE , warning= FALSE, eval=T}
# Portals by reach
reach <- dt %>%
  filter(SOURCE_TYPE == "web") %>%
  group_by(FROM) %>%
  summarise(reach = sum(REACH)) %>%
  arrange(desc(reach))

datatable(reach, options = list(scrollX = TRUE, scrollY = "500px"))
```

```{r echo=FALSE, message=FALSE , warning= FALSE, eval=T}
# Portals by likes
like <- dt %>%
  filter(SOURCE_TYPE == "web") %>%
  group_by(FROM) %>%
  summarise(like = sum(LIKE_COUNT, na.rm = T)) %>%
  mutate(percent = round(like / sum(like) * 100,2)) %>% 
  arrange(desc(like))

datatable(like, options = list(scrollX = TRUE, scrollY = "500px"))
```

```{r echo=FALSE, message=FALSE , warning= FALSE, eval=T}
# Portals by comments
comment <- dt %>%
  filter(SOURCE_TYPE == "web") %>%
  group_by(FROM) %>%
  summarise(comment = sum(COMMENT_COUNT, na.rm = T)) %>%
  mutate(percent = round(comment / sum(comment) * 100,2)) %>% 
  arrange(desc(comment))

datatable(comment, options = list(scrollX = TRUE, scrollY = "500px"))
```

```{r echo=FALSE, message=FALSE , warning= FALSE, eval=T}
# Portals by shares
shares <- dt %>%
  filter(SOURCE_TYPE == "web") %>%
  group_by(FROM) %>%
  summarise(shares = sum(SHARE_COUNT, na.rm = T)) %>%
  mutate(percent = round(shares / sum(shares) * 100,2)) %>% 
  arrange(desc(shares))

datatable(shares, options = list(scrollX = TRUE, scrollY = "500px"))
```


```{r echo=FALSE, message=FALSE , warning= FALSE, eval=F}
dt %>%
  filter(SOURCE_TYPE == "web") %>%
  group_by(TITLE) %>%
  summarise(shares = sum(SHARE_COUNT, na.rm = T),
            likes = sum(LIKE_COUNT, na.rm = T),
            comments = sum(COMMENT_COUNT, na.rm = T),
            reach = sum(REACH_COUNT, na.rm = T)) %>%
 # mutate(percent = round(shares / sum(shares) * 100,2)) %>% 
  arrange(desc(reach)) %>%
  slice(1:200) %>%
  datatable(., options = list(scrollX = TRUE, scrollY = "500px"))

```



```{r echo=FALSE, message=FALSE , warning= FALSE, eval=T}
dt %>%
  filter(SOURCE_TYPE == "web") %>%
  group_by(TITLE) %>%
  summarise(shares = sum(REACH, na.rm = T),
            likes = sum(LIKE_COUNT, na.rm = T),
            comments = sum(COMMENT_COUNT, na.rm = T),
            shares = sum(SHARE_COUNT, na.rm = T),
            across(URL)) %>%
 # mutate(percent = round(shares / sum(shares) * 100,2)) %>% 
  arrange(desc(likes)) %>%
  slice(1:200) %>%
  datatable(., options = list(scrollX = TRUE, scrollY = "500px"))
```

```{r echo=FALSE, message=FALSE , warning= FALSE, eval=T}
dt %>%
  filter(SOURCE_TYPE == "web") %>%
  group_by(TITLE) %>%
  summarise(shares = sum(REACH, na.rm = T),
            likes = sum(LIKE_COUNT, na.rm = T),
            comments = sum(COMMENT_COUNT, na.rm = T),
            shares = sum(SHARE_COUNT, na.rm = T)) %>%
 # mutate(percent = round(shares / sum(shares) * 100,2)) %>% 
  arrange(desc(comments)) %>%
  slice(1:200) %>%
  datatable(., options = list(scrollX = TRUE, scrollY = "500px"))
```



```{r leksikoni, echo=FALSE, message=FALSE , warning= FALSE, eval=F}
# read in lexicons
CroSentilex_n <- read.delim("C:/Users/Lukas/Dropbox/Mislav@Luka/crosentilex-negatives.txt",
                                   header = FALSE,
                                   sep = " ",
                                   stringsAsFactors = FALSE,
                                   fileEncoding = "UTF-8")  %>%
                   rename(word = "V1", sentiment = "V2" ) %>%
                   mutate(brija = "NEG")
 
CroSentilex_p  <- read.delim("C:/Users/Lukas/Dropbox/Mislav@Luka/crosentilex-positives.txt",
                                   header = FALSE,
                                   sep = " ",
                                   stringsAsFactors = FALSE,
                                   fileEncoding = "UTF-8") %>%
                    rename(word = "V1", sentiment = "V2" ) %>%
                    mutate(brija = "POZ")
 
Crosentilex_sve <- rbind(setDT(CroSentilex_n), setDT(CroSentilex_p))
# check lexicon data 
head(sample_n(Crosentilex_sve,1000),15)

 
CroSentilex_Gold  <- read.delim2("C:/Users/Lukas/Dropbox/Mislav@Luka/gs-sentiment-annotations.txt",
                                 header = FALSE,
                                 sep = " ",
                                 stringsAsFactors = FALSE) %>%
                    rename(word = "V1", sentiment = "V2" ) 
 Encoding(CroSentilex_Gold$word) <- "UTF-8"
 CroSentilex_Gold[1,1] <- "dati"
 CroSentilex_Gold$sentiment <- str_replace(CroSentilex_Gold$sentiment , "-", "1")
 CroSentilex_Gold$sentiment <- str_replace(CroSentilex_Gold$sentiment , "\\+", "2")
 CroSentilex_Gold$sentiment <- as.numeric(unlist(CroSentilex_Gold$sentiment))
# check lexicon data 
head(sample_n(CroSentilex_Gold,100),15)
 
# create stop words
stopwords_cro <- get_stopwords(language = "hr", source = "stopwords-iso")
# check stopwords data
head(sample_n(stopwords_cro,100),15)
# extend stop words
my_stop_words <- tibble(
  word = c(
    "jedan","mjera", "može", "mogu", "kad", "sada", "treba", "ima", "osoba",
    "e","prvi", "dva","dvije","drugi",
    "tri","treći","pet","kod",
    "ove","ova",  "ovo","bez", "kod",
    "evo","oko",  "om", "ek",
    "mil","tko","šest", "sedam",
    "osam",   "čim", "zbog",
    "prema", "dok","zato", "koji", 
    "im", "čak","među", "tek",
    "koliko", "tko","kod","poput", 
    "baš", "dakle", "osim", "svih", 
    "svoju", "odnosno", "gdje",
    "kojoj", "ovi", "toga",
     "ubera", "vozača", "hrvatskoj", "usluge", "godine", "više", "taksi", "taxi", "taksija", "taksija", "kaže", "rekao", "19"," aee", "ae"
  ),
  lexicon = "lux"
)
stop_corpus <- my_stop_words %>%
  bind_rows(stopwords_cro)
# check stopwords data
head(sample_n(stop_corpus,100),15)

```



```{r echo=FALSE, message=FALSE , warning= FALSE, eval=F}

token_dt <- dt %>%
  filter(SOURCE_TYPE == "web") %>%
  unnest_tokens(word, FULL_TEXT, "words")

token_dt %>% 
  anti_join(stop_corpus, by = "word") %>%
  mutate(word = gsub("\\d+", NA, word)) %>%
  mutate(word = gsub("^[a-zA-Z]$", NA, word)) -> tokenTidy

tokenTidy %>%
  filter(!is.na(word)) -> tokenTidy


# check
tokenTidy %>%
  sample_n(.,15) %>%
  datatable(., rownames = FALSE, options = list(pageLength = 5, scrollX=T))


```



```{r echo=FALSE, message=FALSE , warning= FALSE, eval=F}
tokenTidy[,.N,by = word][order(-N),][N > 1500]

## Vizualize most common words
tokenTidy[,.N,by = word][N>5000][order(-N),][,word := reorder(word,N)][]
tokenTidy[,.N,by = word][N>20000][order(-N),][,word := reorder(word,N)] %>%
  ggplot(aes(word, N)) +
  geom_col() +
  xlab(NULL) +
  coord_flip() +
  theme_economist()
```





























