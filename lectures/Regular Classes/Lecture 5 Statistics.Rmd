---
title: "Learning Social Media Analytics"
# subtitle: "<html><div style='float:left'></div><hr color='#EB811B' size=1px width=796px></html>"
subtitle: "Lecture 5: Statistics"
author: "Luka Sikic, PhD <br> Faculty of Croatian Studies | [LSMA](https://lusiki.github.io/Learning-Social-Media-Analytics/)"
output:
  html_document:
    code_folding: show
    theme: flatly
    highlight: haddock
    toc: yes
    toc_depth: 4
    toc_float: yes
    keep_md: yes
  pdf_document:
    toc: yes
    toc_depth: '4'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, message = F, warning = F)
```


```{r libs, include=TRUE, echo=TRUE,message=FALSE, warning=FALSE}
library(tidyverse)
library(readxl)
library(here)
library(kableExtra)
library(DT)
library(data.table)
```


# OUTLINE

1. DESCRIPTIVE STATISTICS

2. COMPARING MEANS

3. CATEGORICAL ANALYSIS

4. ANOVA

5. LINEAR REGRESSION



# DESCRIPTIVE STATISTICS




```{r, echo=FALSE, eval = T}
# FULL SAMPLE
path <- "D:/LUKA/Freelance/Mediatoolkit/FULLDATA"
raw <- list.files(path = path , pattern="xlsx")
raw_path <- paste0(path, "/", raw)
all_raw <- map_df(raw_path, read_excel) %>% data.table()
#all_raw <- all_raw  %>%  mutate(DATE = as.Date(DATE,"%Y-%m-%d" ))
```

```{r}
# sneek peak
glimpse(all_raw[sample(nrow(all_raw)),1:8])
# size of the data
dim(all_raw)
# time rage
range(all_raw$DATE)
```





```{r}
# how much activity
all_raw[SOURCE_TYPE == "web", .N]
# how many authors
all_raw[SOURCE_TYPE == "web", length(unique(all_raw$AUTHOR))]
# how many domains?
all_raw[SOURCE_TYPE == "web", length(unique(all_raw$FROM))]
# how many domains?
all_raw[SOURCE_TYPE == "web",
        .(Number = length(unique(FROM)))]
# how many CRO domains?
all_raw[SOURCE_TYPE == "web" & grepl(".hr", unique(all_raw$FROM)),
        .(Number = length(unique(FROM)))]

```

```{r, echo = FALSE}
web <- all_raw[SOURCE_TYPE == "web",]
```



```{r}
# some domains?
web[,.(UniqueDomains = unique(FROM))] %>% sample_n(5)
# some CRO domains?
web[str_detect(web$FROM, "hr"),.(UniqueDomains = unique(FROM))] %>% sample_n(5)
```



```{r}
# check all domains
web[str_detect(web$FROM, ".hr"),.N,
        FROM][order(-N),] %>%
  datatable(., rownames = FALSE, options = list(pageLength = 5, scrollX=T))
```



```{r}
web[str_detect(web$FROM, ".hr"),.N,FROM][N >= 50,][order(-N),] %>%
  ggplot(., aes(N)) +
  geom_histogram(bins = 10, color = "#000000", fill = "#0099F8") + 
  geom_vline(aes(xintercept = mean(N)), color = "#000000", size = 1.25) +
  geom_vline(aes(xintercept = mean(N) + sd(N)), color = "#000000", size = 1, linetype = "dashed") +
  geom_vline(aes(xintercept = mean(N) - sd(N)), color = "#000000", size = 1, linetype = "dashed") +
  labs(
    title = "Histogram of portal activity in Croatia",
    subtitle = "Made by LSMA",
    caption = "Source: Mediatoolkit dataset",
    x = "Number of articles",
    y = "Count"
  ) +
  theme_classic() +
  theme(
    plot.title = element_text(color = "#0099F8", size = 16, face = "bold"),
    plot.subtitle = element_text(size = 10, face = "bold"),
    plot.caption = element_text(face = "italic")
  ) -> gg1
```




```{r , echo=FALSE}
gg1
```




```{r, echo= FALSE}
# just another view
web[str_detect(web$FROM, ".hr"),.N,FROM][, All := sum(N)][, avg := (N / All)*100][order(-N),] 
```




```{r}

# check overall descriptives (number of articles)
web[str_detect(web$FROM, ".hr"),.N,FROM][,.(mean = mean(N),stdev = sd(N), total = sum(N))]

# check ranking by No. of articles
web[str_detect(web$FROM, ".hr"),
          .(.N,REACH = sum(REACH, na.rm = T),
          VIRALITY = sum(VIRALITY, na.rm = T),
          LIKE = sum(LIKE_COUNT, na.rm = T),
          COMMENT = sum(COMMENT_COUNT, na.rm = T)), 
          FROM][order(-N),] %>%
  datatable(., rownames = FALSE, options = list(pageLength = 5, scrollX=T) )


# check overall descriptives (number of comments)
web[str_detect(web$FROM, ".hr"),
    .(COMMENT = sum(COMMENT_COUNT, na.rm = T)),FROM][,.(mean = mean(COMMENT),
                                                        stdev = sd(COMMENT),
                                                        total = sum(COMMENT))]

# check ranking by No. of comments
web[str_detect(web$FROM, ".hr"),
          .(.N,REACH = sum(REACH, na.rm = T),
          VIRALITY = sum(VIRALITY, na.rm = T),
          LIKE = sum(LIKE_COUNT, na.rm = T),
          COMMENT = sum(COMMENT_COUNT, na.rm = T)), 
          FROM][order(-COMMENT),] %>%
  datatable(., rownames = FALSE, options = list(pageLength = 5, scrollX=T) )


# check overall descriptives (number of likes)
web[str_detect(web$FROM, ".hr"),
    .(LIKE = sum(LIKE_COUNT, na.rm = T)),FROM][,.(mean = mean(LIKE),
                                                        stdev = sd(LIKE),
                                                        total = sum(LIKE))]
# check ranking by No. of likes
web[str_detect(web$FROM, ".hr"),
          .(.N,REACH = sum(REACH, na.rm = T),
          VIRALITY = sum(VIRALITY, na.rm = T),
          LIKE = sum(LIKE_COUNT, na.rm = T),
          COMMENT = sum(COMMENT_COUNT, na.rm = T)), 
          FROM][order(-LIKE),] %>%
  datatable(., rownames = FALSE, options = list(pageLength = 5, scrollX=T) )

```


















# Thank you for your attention!





















