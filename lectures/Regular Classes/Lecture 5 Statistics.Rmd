---
title: "Learning Social Media Analytics"
# subtitle: "<html><div style='float:left'></div><hr color='#EB811B' size=1px width=796px></html>"
subtitle: "Lecture 5: Statistics"
author: "Luka Sikic, PhD <br> Faculty of Croatian Studies | [LSMA](https://lusiki.github.io/Learning-Social-Media-Analytics/"
output:
  xaringan::moon_reader:
    css: [default, metropolis, metropolis-fonts] 
    lib_dir: libs
    nature:
      highlightStyle: googlecode
      highlightLines: true
      countIncrementalSlides: false
---



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, message = F, warning = F)
```


```{r libs, include=TRUE, echo=TRUE,message=FALSE, warning=FALSE}
library(tidyverse)
library(readxl)
library(here)
library(kableExtra)
library(DT)
library(data.table)
```


# STRUCTURE
<br>
<br>
- DESCRIPTIVE STATISTICS
<br>
<br>
- COMPARING MEANS
<br>
<br>
- CATEGORICAL ANALYSIS
<br>
<br>
- ANOVA
<br>
<br>
- LINEAR REGRESSION
<br>
<br>

---
layout: true
# DESCRIPTIVE STATISTICS
---

#### Check your data first

```{r, echo=FALSE, eval = T}
# FULL SAMPLE
path <- "D:/LUKA/Freelance/Mediatoolkit/FULLDATA"
raw <- list.files(path = path , pattern="xlsx")
raw_path <- paste0(path, "/", raw)
all_raw <- map_df(raw_path, read_excel) %>% data.table()
#all_raw <- all_raw  %>%  mutate(DATE = as.Date(DATE,"%Y-%m-%d" ))
```

```{r}
# sneek peak
glimpse(all_raw[sample(nrow(all_raw)),1:8])
# size of the data
dim(all_raw)
# time rage
range(all_raw$DATE)
```

---

#### Dig deeper into web

```{r}
# how much activity
all_raw[SOURCE_TYPE == "web", .N]
# how many authors
all_raw[SOURCE_TYPE == "web", length(unique(all_raw$AUTHOR))]
# how many domains?
all_raw[SOURCE_TYPE == "web", length(unique(all_raw$FROM))]
# how many domains?
all_raw[SOURCE_TYPE == "web" & grepl(".", unique(all_raw$FROM)),
        .(Number =length(unique(FROM)))]
# how many CRO domains?
all_raw[SOURCE_TYPE == "web" & grepl(".hr", unique(all_raw$FROM)),
        .(Number =unique(FROM))]
```

---

#### Dig deeper into web

```{r}
# how many domains?
all_raw[SOURCE_TYPE == "web" & grepl(".", unique(all_raw$FROM)),
        .(unique(FROM))] %>% sample_n(5)
# how many CRO domains?
all_raw[SOURCE_TYPE == "web" & grepl(".hr", unique(all_raw$FROM)),
        .(unique(FROM))] %>% sample_n(5)
```

---

#### Dig deeper into web

```{r}
# check all domains
all_raw[SOURCE_TYPE == "web" & grepl(".hr", unique(all_raw$FROM)),
        .N,
        FROM][order(-N),] %>%
  datatable(., rownames = FALSE, options = list(pageLength = 3, scrollX=T) )
```

---

#### Dig deeper into web

```{r}
all_raw[SOURCE_TYPE == "web" & grepl(".hr", unique(all_raw$FROM)),.N,FROM][N >= 100,][order(-N),]%>%
  ggplot(., aes(N)) +
  geom_histogram(bins = 10, color = "#000000", fill = "#0099F8") + 
  geom_vline(aes(xintercept = mean(N)), color = "#000000", size = 1.25) +
  geom_vline(aes(xintercept = mean(N) + sd(N)), color = "#000000", size = 1, linetype = "dashed") +
  geom_vline(aes(xintercept = mean(N) - sd(N)), color = "#000000", size = 1, linetype = "dashed") +
  labs(
    title = "Histogram of portal activity in Croatia",
    subtitle = "Made by LSMA",
    caption = "Source: Mediatoolkit dataset",
    x = "Number of articles",
    y = "Count"
  ) +
  theme_classic() +
  theme(
    plot.title = element_text(color = "#0099F8", size = 16, face = "bold"),
    plot.subtitle = element_text(size = 10, face = "bold"),
    plot.caption = element_text(face = "italic")
  ) -> gg1
```

---

#### Dig deeper into web

```{r, echo= FALSE}
gg1
```

---

#### Dig deeper into web

```{r}
# check overall descriptives (number of articles)
all_raw[SOURCE_TYPE == "web" & grepl(".hr", unique(all_raw$FROM)),.N,FROM][,.(mean = mean(N),
                                                                              stdev = sd(N),
                                                                              total = sum(N))]
# check overall descriptives (number of Views)
all_raw[SOURCE_TYPE == "web" & grepl(".hr", unique(all_raw$FROM)),
        .(.N,REACH = sum(REACH),
          VIRALITY = sum(VIRALITY),
          LIKE = sum(LIKE_COUNT),
          COMMENT = sum(COMMENT_COUNT)),FROM][N > 10,][order(-REACH),][,.(mean = mean(N),
                                                                              stdev = sd(N),
                                                                              total = sum(N))]

all_raw[SOURCE_TYPE == "web" & grepl(".hr", unique(all_raw$FROM)),
        .(.N,REACH = mean(REACH, na.rm = T),
          VIRALITY = mean(VIRALITY, na.rm = T),
          LIKE = mean(LIKE_COUNT, na.rm = T),
          COMMENT = mean(COMMENT_COUNT, na.rm = T))]



[N > 10,][order(-REACH),][,.(mean = mean(N),
                                                                              stdev = sd(N),
                                                                              total = sum(N))]







# check overall descriptives
all_raw[SOURCE_TYPE == "web" & grepl(".hr", unique(all_raw$FROM)),.N,FROM][N > 50 & N < 150][,.(mean = mean(N),
                                                                              stdev = sd(N),
                                                                              total = sum(N),
                                                                              count = .N)]
# check overall descriptives
all_raw[SOURCE_TYPE == "web" & grepl(".hr", unique(all_raw$FROM)),.N,FROM][N > 150 & N < 450][,.(mean = mean(N),
                                                                              stdev = sd(N),
                                                                              total = sum(N),
                                                                              count = .N)]
# check overall descriptives
all_raw[SOURCE_TYPE == "web" & grepl(".hr", unique(all_raw$FROM)),.N,FROM][N > 1500][,.(mean = mean(N),
                                                                              stdev = sd(N),
                                                                              total = sum(N),
                                                                              count = .N)]
```

















  
---
<br>
#### Resources
<br>
<br>
- Check the data.table package and tutorial
<br>
<br>
- Refresh your stats with this textbook
<br>
<br>
- Try your own skills with MT datasample

---
class: inverse, middle
layout:false
# Thank you for your attention!





















